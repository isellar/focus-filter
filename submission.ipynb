{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this for Kaggle setup with the Google API Key in the secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GOOGLE_API_KEY found in environment variables\n",
      "âœ… Setup complete - GOOGLE_API_KEY is set (length: 39)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load API key from multiple sources\n",
    "api_key_loaded = False\n",
    "\n",
    "# Method 1: Check if already set in environment\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    print(\"âœ… GOOGLE_API_KEY found in environment variables\")\n",
    "    api_key_loaded = True\n",
    "\n",
    "# Method 2: Try Kaggle secrets (if running in Kaggle)\n",
    "if not api_key_loaded:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "        print(\"âœ… Loaded GOOGLE_API_KEY from Kaggle secrets\")\n",
    "        api_key_loaded = True\n",
    "    except ImportError:\n",
    "        pass  # Not in Kaggle environment\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not load from Kaggle secrets: {e}\")\n",
    "\n",
    "# Method 3: Try .env file (for local development)\n",
    "if not api_key_loaded:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        env_path = Path('.') / '.env'\n",
    "        if env_path.exists():\n",
    "            load_dotenv(env_path)\n",
    "            if \"GOOGLE_API_KEY\" in os.environ:\n",
    "                print(\"âœ… Loaded GOOGLE_API_KEY from .env file\")\n",
    "                api_key_loaded = True\n",
    "            else:\n",
    "                print(\"âš ï¸  .env file exists but GOOGLE_API_KEY not found in it\")\n",
    "        else:\n",
    "            print(\"âš ï¸  .env file not found\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  python-dotenv not installed (optional for local development)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error loading .env: {e}\")\n",
    "\n",
    "# Final check\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    key_length = len(os.environ['GOOGLE_API_KEY'])\n",
    "    print(f\"âœ… Setup complete - GOOGLE_API_KEY is set (length: {key_length})\")\n",
    "else:\n",
    "    print(\"âŒ GOOGLE_API_KEY is required but not found.\")\n",
    "    print(\"   Please set it using one of these methods:\")\n",
    "    print(\"   1. Kaggle: Add 'GOOGLE_API_KEY' to your Kaggle secrets\")\n",
    "    print(\"   2. Local: Create a .env file with: GOOGLE_API_KEY=your_key_here\")\n",
    "    print(\"   3. Environment: Set GOOGLE_API_KEY as an environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n",
      "âœ… Async support enabled for Jupyter notebooks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.agents.remote_a2a_agent import (\n",
    "    RemoteA2aAgent,\n",
    "    AGENT_CARD_WELL_KNOWN_PATH,\n",
    ")\n",
    "\n",
    "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# Hide additional warnings in the notebook\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable nested event loops for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")\n",
    "print(\"âœ… Async support enabled for Jupyter notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus Filter - Intelligent Notification Filtering Agent\n",
    "\n",
    "This notebook implements a **multi-agent system** that intelligently filters and manages notifications by:\n",
    "- Classifying notifications as urgent, irrelevant, or less urgent\n",
    "- Taking appropriate actions (pass through, block, or store in memory)\n",
    "- Learning from patterns to improve over time\n",
    "\n",
    "## Contest Track: Concierge\n",
    "## Key Concepts Demonstrated:\n",
    "1. **Multi-agent system** (sequential agents: Classification â†’ Action â†’ Memory)\n",
    "2. **Custom tools** for notification management\n",
    "3. **Sessions & Memory** (long-term memory storage)\n",
    "4. **Observability** (logging and tracing)\n",
    "5. **Agent evaluation** (LLM-as-judge)\n",
    "\n",
    "## Multi-Agent Architecture\n",
    "\n",
    "This implementation uses a **sequential multi-agent system** with three specialized agents:\n",
    "\n",
    "1. **Classification Agent**: Analyzes notifications and determines urgency category\n",
    "2. **Action Agent**: Executes appropriate actions based on classification results\n",
    "3. **Memory Agent**: Handles memory extraction, consolidation, and storage\n",
    "\n",
    "The agents work sequentially: Classification â†’ Action â†’ Memory (when needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Notification and Memory classes initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Notification Data Structure and Memory Management\n",
    "# ============================================================================\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Notification:\n",
    "    \"\"\"Represents a notification from an app or service\"\"\"\n",
    "    id: str\n",
    "    app: str\n",
    "    title: str\n",
    "    body: str\n",
    "    timestamp: str\n",
    "    category: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"app\": self.app,\n",
    "            \"title\": self.title,\n",
    "            \"body\": self.body,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"category\": self.category\n",
    "        }\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"[{self.app}] {self.title}: {self.body}\"\n",
    "\n",
    "# Simple in-memory storage for demonstration\n",
    "class NotificationMemory:\n",
    "    \"\"\"Simple memory store for less urgent notifications\"\"\"\n",
    "    def __init__(self):\n",
    "        self.memories: List[Dict] = []\n",
    "    \n",
    "    def store(self, notification: Notification, extracted_fact: str):\n",
    "        \"\"\"Store a notification fact in memory\"\"\"\n",
    "        memory = {\n",
    "            \"notification_id\": notification.id,\n",
    "            \"app\": notification.app,\n",
    "            \"extracted_fact\": extracted_fact,\n",
    "            \"timestamp\": notification.timestamp,\n",
    "            \"stored_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.memories.append(memory)\n",
    "        print(f\"ðŸ’¾ Stored memory: {extracted_fact}\")\n",
    "        return memory\n",
    "    \n",
    "    def get_all(self) -> List[Dict]:\n",
    "        \"\"\"Retrieve all stored memories\"\"\"\n",
    "        return self.memories\n",
    "    \n",
    "    def search(self, query: str) -> List[Dict]:\n",
    "        \"\"\"Simple keyword search (would use vector DB in production)\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        return [\n",
    "            m for m in self.memories\n",
    "            if query_lower in m[\"extracted_fact\"].lower() or \n",
    "               query_lower in m[\"app\"].lower()\n",
    "        ]\n",
    "\n",
    "# Initialize memory store\n",
    "memory_store = NotificationMemory()\n",
    "print(\"âœ… Notification and Memory classes initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced memory management initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3 & 4: Enhanced Memory Management\n",
    "# ============================================================================\n",
    "# This cell enhances the NotificationMemory class with advanced features:\n",
    "# - User preferences\n",
    "# - Memory consolidation\n",
    "# - Context compaction\n",
    "# - Pattern learning\n",
    "\n",
    "# Initialize enhanced attributes on the memory store\n",
    "memory_store.user_preferences = {\n",
    "    \"always_urgent_apps\": [],\n",
    "    \"always_block_apps\": [],\n",
    "    \"preferred_categories\": [],\n",
    "    \"blocked_keywords\": []\n",
    "}\n",
    "memory_store.consolidation_threshold = 0.8\n",
    "\n",
    "# Add enhanced methods to NotificationMemory\n",
    "def _find_similar_memory(self, fact: str) -> Optional[Dict]:\n",
    "    \"\"\"Find similar memories to avoid duplicates\"\"\"\n",
    "    fact_lower = fact.lower()\n",
    "    fact_words = set(fact_lower.split())\n",
    "    \n",
    "    for memory in self.memories:\n",
    "        existing_fact = memory[\"extracted_fact\"].lower()\n",
    "        existing_words = set(existing_fact.split())\n",
    "        \n",
    "        # Calculate simple similarity (Jaccard similarity)\n",
    "        intersection = len(fact_words & existing_words)\n",
    "        union = len(fact_words | existing_words)\n",
    "        similarity = intersection / union if union > 0 else 0\n",
    "        \n",
    "        if similarity >= self.consolidation_threshold:\n",
    "            return memory\n",
    "    \n",
    "    return None\n",
    "\n",
    "def _merge_memories(self, memories: List[Dict]) -> Dict:\n",
    "    \"\"\"Merge multiple similar memories into one\"\"\"\n",
    "    base = max(memories, key=lambda m: datetime.fromisoformat(m.get(\"last_updated\", m[\"stored_at\"])))\n",
    "    total_count = sum(m.get(\"occurrence_count\", 1) for m in memories)\n",
    "    base[\"occurrence_count\"] = total_count\n",
    "    base[\"merged_from\"] = len(memories)\n",
    "    return base\n",
    "\n",
    "def consolidate_memories(self):\n",
    "    \"\"\"Consolidate and merge similar memories\"\"\"\n",
    "    consolidated = []\n",
    "    processed = set()\n",
    "    \n",
    "    for i, memory in enumerate(self.memories):\n",
    "        if i in processed:\n",
    "            continue\n",
    "        \n",
    "        similar_group = [memory]\n",
    "        for j, other_memory in enumerate(self.memories[i+1:], start=i+1):\n",
    "            if j in processed:\n",
    "                continue\n",
    "            if self._find_similar_memory(other_memory[\"extracted_fact\"]) == memory:\n",
    "                similar_group.append(other_memory)\n",
    "                processed.add(j)\n",
    "        \n",
    "        if len(similar_group) > 1:\n",
    "            merged = self._merge_memories(similar_group)\n",
    "            consolidated.append(merged)\n",
    "            print(f\"ðŸ”— Consolidated {len(similar_group)} similar memories\")\n",
    "        else:\n",
    "            consolidated.append(memory)\n",
    "        \n",
    "        processed.add(i)\n",
    "    \n",
    "    self.memories = consolidated\n",
    "    return len(consolidated)\n",
    "\n",
    "def get_user_preferences(self) -> Dict:\n",
    "    \"\"\"Get user preferences for notification filtering\"\"\"\n",
    "    return self.user_preferences.copy()\n",
    "\n",
    "def update_preference(self, preference_type: str, value: str, action: str = \"add\"):\n",
    "    \"\"\"Update user preferences (add or remove)\"\"\"\n",
    "    if preference_type not in self.user_preferences:\n",
    "        return {\"status\": \"error\", \"message\": f\"Unknown preference type: {preference_type}\"}\n",
    "    \n",
    "    if action == \"add\":\n",
    "        if value not in self.user_preferences[preference_type]:\n",
    "            self.user_preferences[preference_type].append(value)\n",
    "            print(f\"âœ… Added preference: {preference_type} = {value}\")\n",
    "    elif action == \"remove\":\n",
    "        if value in self.user_preferences[preference_type]:\n",
    "            self.user_preferences[preference_type].remove(value)\n",
    "            print(f\"âœ… Removed preference: {preference_type} = {value}\")\n",
    "    \n",
    "    return {\"status\": \"success\", \"preferences\": self.user_preferences.copy()}\n",
    "\n",
    "def learn_from_patterns(self, classification_history: List[Dict]):\n",
    "    \"\"\"Learn user preferences from classification patterns\"\"\"\n",
    "    app_classifications = {}\n",
    "    \n",
    "    for entry in classification_history:\n",
    "        app = entry.get(\"app\", \"\")\n",
    "        classification = entry.get(\"classification\", \"\")\n",
    "        \n",
    "        if app not in app_classifications:\n",
    "            app_classifications[app] = {\"URGENT\": 0, \"IRRELEVANT\": 0, \"LESS_URGENT\": 0}\n",
    "        \n",
    "        app_classifications[app][classification] = app_classifications[app].get(classification, 0) + 1\n",
    "    \n",
    "    # Auto-update preferences based on patterns\n",
    "    for app, counts in app_classifications.items():\n",
    "        total = sum(counts.values())\n",
    "        if total >= 3:\n",
    "            urgent_ratio = counts[\"URGENT\"] / total\n",
    "            irrelevant_ratio = counts[\"IRRELEVANT\"] / total\n",
    "            \n",
    "            if urgent_ratio >= 0.8 and app not in self.user_preferences[\"always_urgent_apps\"]:\n",
    "                self.update_preference(\"always_urgent_apps\", app, \"add\")\n",
    "            elif irrelevant_ratio >= 0.8 and app not in self.user_preferences[\"always_block_apps\"]:\n",
    "                self.update_preference(\"always_block_apps\", app, \"add\")\n",
    "\n",
    "def compact_context(self, max_memories: int = 10) -> List[Dict]:\n",
    "    \"\"\"Compact context by returning most relevant memories\"\"\"\n",
    "    sorted_memories = sorted(\n",
    "        self.memories,\n",
    "        key=lambda m: (\n",
    "            datetime.fromisoformat(m.get(\"last_updated\", m[\"stored_at\"])),\n",
    "            m.get(\"occurrence_count\", 1)\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "    return sorted_memories[:max_memories]\n",
    "\n",
    "# Add methods to NotificationMemory class\n",
    "NotificationMemory._find_similar_memory = _find_similar_memory\n",
    "NotificationMemory._merge_memories = _merge_memories\n",
    "NotificationMemory.consolidate_memories = consolidate_memories\n",
    "NotificationMemory.get_user_preferences = get_user_preferences\n",
    "NotificationMemory.update_preference = update_preference\n",
    "NotificationMemory.learn_from_patterns = learn_from_patterns\n",
    "NotificationMemory.compact_context = compact_context\n",
    "\n",
    "# Enhanced store method with deduplication\n",
    "original_store = NotificationMemory.store\n",
    "def enhanced_store(self, notification: Notification, extracted_fact: str):\n",
    "    \"\"\"Store with deduplication\"\"\"\n",
    "    similar_memory = self._find_similar_memory(extracted_fact)\n",
    "    \n",
    "    if similar_memory:\n",
    "        similar_memory[\"last_updated\"] = datetime.now().isoformat()\n",
    "        similar_memory[\"occurrence_count\"] = similar_memory.get(\"occurrence_count\", 1) + 1\n",
    "        print(f\"ðŸ’¾ Updated existing memory: {extracted_fact} (count: {similar_memory['occurrence_count']})\")\n",
    "        return similar_memory\n",
    "    \n",
    "    memory = original_store(self, notification, extracted_fact)\n",
    "    memory[\"last_updated\"] = datetime.now().isoformat()\n",
    "    memory[\"occurrence_count\"] = 1\n",
    "    return memory\n",
    "\n",
    "NotificationMemory.store = enhanced_store\n",
    "\n",
    "print(\"âœ… Enhanced memory management initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced tools ready:\n",
      "   â€¢ retrieve_user_preferences() - Access user preferences\n",
      "   â€¢ Tool validation framework available\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Enhanced Tools - retrieve_user_preferences and Validation\n",
    "# ============================================================================\n",
    "\n",
    "def retrieve_user_preferences() -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve user preferences for notification filtering.\n",
    "    This tool allows agents to access learned user preferences to make better decisions.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with user preferences including:\n",
    "        - always_urgent_apps: Apps that should always be treated as urgent\n",
    "        - always_block_apps: Apps that should always be blocked\n",
    "        - preferred_categories: Categories the user cares about\n",
    "        - blocked_keywords: Keywords that indicate blocking\n",
    "        \n",
    "        Success: {\"status\": \"success\", \"preferences\": {...}}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preferences = memory_store.get_user_preferences()\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"preferences\": preferences,\n",
    "            \"message\": \"User preferences retrieved successfully\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": f\"Failed to retrieve preferences: {e}\"\n",
    "        }\n",
    "\n",
    "# Enhanced tool validation wrapper\n",
    "def validate_tool_input(func):\n",
    "    \"\"\"Decorator to validate tool inputs and handle errors\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            # Basic validation\n",
    "            if not args and not kwargs:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error_message\": \"No arguments provided\"\n",
    "                }\n",
    "            \n",
    "            # Call the original function\n",
    "            result = func(*args, **kwargs)\n",
    "            \n",
    "            # Validate result format\n",
    "            if not isinstance(result, dict):\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error_message\": \"Tool did not return a dictionary\"\n",
    "                }\n",
    "            \n",
    "            if \"status\" not in result:\n",
    "                result[\"status\"] = \"success\"\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except TypeError as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Invalid arguments: {e}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Tool execution error: {e}\"\n",
    "            }\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "# Apply validation to existing tools (optional - for demonstration)\n",
    "# In production, you'd wrap the tools before passing to agents\n",
    "\n",
    "print(\"âœ… Enhanced tools ready:\")\n",
    "print(\"   â€¢ retrieve_user_preferences() - Access user preferences\")\n",
    "print(\"   â€¢ Tool validation framework available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Custom tools defined\n"
     ]
    }
   ],
   "source": [
    "# Custom Tools for Notification Management\n",
    "\n",
    "def display_urgent_notification(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Display an urgent notification to the user immediately.\n",
    "    This tool is called when a notification requires immediate attention.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Notification displayed\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸš¨ URGENT NOTIFICATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"App: {app}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Body: {body}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    return {\"status\": \"success\", \"message\": f\"Urgent notification from {app} displayed to user\"}\n",
    "\n",
    "def block_notification(app: str, title: str, reason: str) -> dict:\n",
    "    \"\"\"\n",
    "    Block/suppress an irrelevant notification.\n",
    "    This tool is called when a notification is determined to be noise.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        reason: The reason for blocking (e.g., \"social media noise\", \"promotional content\")\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Notification blocked\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    print(f\"ðŸš« Blocked: [{app}] {title} - {reason}\")\n",
    "    return {\"status\": \"success\", \"message\": f\"Notification from {app} blocked: {reason}\"}\n",
    "\n",
    "def save_notification_memory(app: str, title: str, body: str, extracted_fact: str) -> dict:\n",
    "    \"\"\"\n",
    "    Save a less urgent notification as a memory for later review.\n",
    "    This tool extracts key information and stores it for future reference.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        extracted_fact: The key fact or information extracted from the notification\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Memory stored\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    # Create a temporary notification object for storage\n",
    "    temp_notification = Notification(\n",
    "        id=str(uuid.uuid4()),\n",
    "        app=app,\n",
    "        title=title,\n",
    "        body=body,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )\n",
    "    memory_store.store(temp_notification, extracted_fact)\n",
    "    return {\"status\": \"success\", \"message\": f\"Memory stored: {extracted_fact}\"}\n",
    "\n",
    "print(\"âœ… Custom tools defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent system created:\n",
      "  â€¢ Classification Agent - Analyzes and classifies notifications\n",
      "  â€¢ Action Agent - Executes actions based on classification\n",
      "  â€¢ Memory Agent - Handles memory extraction and consolidation\n",
      "âœ… Agents updated with enhanced tools\n",
      "   â€¢ Classification Agent can now check user preferences\n",
      "   â€¢ Action Agent can now check user preferences\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT ARCHITECTURE: Sequential Agent System\n",
    "# ============================================================================\n",
    "# This demonstrates a multi-agent system with three specialized agents:\n",
    "# 1. Classification Agent: Analyzes and classifies notifications\n",
    "# 2. Action Agent: Executes actions based on classification\n",
    "# 3. Memory Agent: Handles memory extraction and storage\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 1: Classification Agent\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent's sole responsibility is to analyze notifications and determine\n",
    "# their urgency category. It does NOT take actions, only classifies.\n",
    "\n",
    "def classify_notification(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Classify a notification into one of three categories: URGENT, IRRELEVANT, or LESS_URGENT.\n",
    "    This tool is used by the Classification Agent to output its decision.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with classification result.\n",
    "    \"\"\"\n",
    "    # This is a tool that the classification agent will call to output its decision\n",
    "    # The actual classification logic is in the agent's reasoning\n",
    "    pass  # Placeholder - agent will call this with classification result\n",
    "\n",
    "classification_agent = LlmAgent(\n",
    "    name=\"classification_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a Classification Agent in the Focus Filter system.\n",
    "\n",
    "Your ONLY job is to analyze notifications and classify them into one of three categories:\n",
    "\n",
    "1. **URGENT**: Requires immediate attention or action\n",
    "   - Security alerts (bank, account access)\n",
    "   - Critical deadlines or time-sensitive tasks\n",
    "   - Emergency communications\n",
    "   - Important personal messages requiring immediate response\n",
    "\n",
    "2. **IRRELEVANT**: Noise that should be blocked\n",
    "   - Social media likes, follows, generic updates\n",
    "   - Marketing/promotional content\n",
    "   - Low-value informational updates\n",
    "   - Spam or unwanted notifications\n",
    "\n",
    "3. **LESS_URGENT**: Important but not immediate - should be stored in memory\n",
    "   - Project updates, deadline changes\n",
    "   - Informational updates worth remembering\n",
    "   - Non-critical but useful information\n",
    "   - Things the user might want to reference later\n",
    "\n",
    "When you receive a notification, analyze the app, title, and body text, then respond with:\n",
    "- The classification (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- A brief reasoning for your decision\n",
    "- If LESS_URGENT, also provide the key fact or information that should be extracted\n",
    "\n",
    "Format your response as:\n",
    "Classification: [URGENT/IRRELEVANT/LESS_URGENT]\n",
    "Reasoning: [your reasoning]\n",
    "Key Fact (if LESS_URGENT): [extracted fact]\n",
    "\n",
    "Be conservative with URGENT - only use it for truly time-sensitive or critical items.\"\"\",\n",
    "    tools=[],  # Classification agent doesn't take actions, only classifies\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 2: Action Agent\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent receives classification results and executes the appropriate action\n",
    "\n",
    "action_agent = LlmAgent(\n",
    "    name=\"action_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an Action Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to execute actions based on classification results from the Classification Agent.\n",
    "\n",
    "You will receive:\n",
    "- The notification details (app, title, body)\n",
    "- The classification result (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- Any additional context (like extracted facts for LESS_URGENT items)\n",
    "\n",
    "Based on the classification, you must:\n",
    "1. For URGENT: Call `display_urgent_notification(app, title, body)`\n",
    "2. For IRRELEVANT: Call `block_notification(app, title, reason)` with a clear reason\n",
    "3. For LESS_URGENT: Call `save_notification_memory(app, title, body, extracted_fact)` with the key fact\n",
    "\n",
    "Execute the appropriate action immediately based on the classification provided.\"\"\",\n",
    "    tools=[\n",
    "        display_urgent_notification,\n",
    "        block_notification,\n",
    "        save_notification_memory,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 3: Memory Agent (for advanced memory operations)\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent handles memory extraction, consolidation, and retrieval\n",
    "\n",
    "def extract_memory_fact(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the key fact or information from a notification for memory storage.\n",
    "    This tool is used by the Memory Agent to extract structured information.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted fact.\n",
    "    \"\"\"\n",
    "    # This tool allows the memory agent to output extracted facts\n",
    "    pass  # Placeholder - agent will call this with extracted fact\n",
    "\n",
    "memory_agent = LlmAgent(\n",
    "    name=\"memory_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a Memory Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to extract, consolidate, and manage memories from notifications.\n",
    "\n",
    "When you receive a LESS_URGENT notification:\n",
    "1. Extract the most important fact or piece of information\n",
    "2. Format it as a concise, searchable memory\n",
    "3. Ensure it's useful for future reference\n",
    "\n",
    "For example:\n",
    "- \"Project deadline moved to Tuesday\" (not \"Your project deadline has moved to Tuesday\")\n",
    "- \"New team member joined: Alice\" (not the full notification text)\n",
    "\n",
    "Focus on extracting actionable, referenceable facts that the user might want to recall later.\"\"\",\n",
    "    tools=[],  # Memory agent primarily extracts facts (can be extended with retrieval tools)\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-agent system created:\")\n",
    "print(\"  â€¢ Classification Agent - Analyzes and classifies notifications\")\n",
    "print(\"  â€¢ Action Agent - Executes actions based on classification\")\n",
    "print(\"  â€¢ Memory Agent - Handles memory extraction and consolidation\")\n",
    "\n",
    "# Update agents to include retrieve_user_preferences tool\n",
    "# Add the tool to classification and action agents\n",
    "if retrieve_user_preferences not in classification_agent.tools:\n",
    "    classification_agent.tools.append(retrieve_user_preferences)\n",
    "\n",
    "if retrieve_user_preferences not in action_agent.tools:\n",
    "    action_agent.tools.append(retrieve_user_preferences)\n",
    "\n",
    "print(\"âœ… Agents updated with enhanced tools\")\n",
    "print(\"   â€¢ Classification Agent can now check user preferences\")\n",
    "print(\"   â€¢ Action Agent can now check user preferences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Observability system initialized\n",
      "   â€¢ Structured logging enabled\n",
      "   â€¢ Trace capture ready\n",
      "   â€¢ Metrics collection active\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OBSERVABILITY: Logging, Tracing, and Metrics\n",
    "# ============================================================================\n",
    "# This module provides comprehensive observability for the multi-agent system\n",
    "\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "\n",
    "# Configure structured logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"FocusFilter\")\n",
    "\n",
    "class ObservabilityManager:\n",
    "    \"\"\"Manages logging, tracing, and metrics for the multi-agent system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.traces: List[Dict] = []\n",
    "        self.metrics = {\n",
    "            \"total_notifications\": 0,\n",
    "            \"classifications\": defaultdict(int),\n",
    "            \"actions\": defaultdict(int),\n",
    "            \"agent_timings\": defaultdict(list),\n",
    "            \"errors\": []\n",
    "        }\n",
    "        self.current_trace: Optional[Dict] = None\n",
    "    \n",
    "    def start_trace(self, notification_id: str, notification_text: str):\n",
    "        \"\"\"Start a new trace for a notification processing session\"\"\"\n",
    "        self.current_trace = {\n",
    "            \"trace_id\": f\"trace_{uuid.uuid4().hex[:8]}\",\n",
    "            \"notification_id\": notification_id,\n",
    "            \"notification_text\": notification_text,\n",
    "            \"start_time\": datetime.now().isoformat(),\n",
    "            \"agents\": [],\n",
    "            \"classification\": None,\n",
    "            \"action\": None,\n",
    "            \"memory_operation\": None,\n",
    "            \"end_time\": None,\n",
    "            \"duration_ms\": None,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        logger.info(f\"ðŸ” Trace started: {self.current_trace['trace_id']}\")\n",
    "    \n",
    "    def log_agent_step(self, agent_name: str, step: str, input_data: Dict, output_data: Dict, duration_ms: float):\n",
    "        \"\"\"Log an agent step in the current trace\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        agent_step = {\n",
    "            \"agent\": agent_name,\n",
    "            \"step\": step,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"input\": input_data,\n",
    "            \"output\": output_data,\n",
    "            \"duration_ms\": duration_ms\n",
    "        }\n",
    "        self.current_trace[\"agents\"].append(agent_step)\n",
    "        self.metrics[\"agent_timings\"][f\"{agent_name}_{step}\"].append(duration_ms)\n",
    "        \n",
    "        logger.info(f\"ðŸ“Š {agent_name} - {step} completed in {duration_ms:.2f}ms\")\n",
    "    \n",
    "    def log_classification(self, classification: str, reasoning: str, confidence: Optional[float] = None):\n",
    "        \"\"\"Log classification result\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"classification\"] = {\n",
    "            \"result\": classification,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"confidence\": confidence,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"classifications\"][classification] += 1\n",
    "        \n",
    "        logger.info(f\"ðŸ·ï¸  Classification: {classification} - {reasoning[:100]}\")\n",
    "    \n",
    "    def log_action(self, action_type: str, action_details: Dict):\n",
    "        \"\"\"Log action execution\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"action\"] = {\n",
    "            \"type\": action_type,\n",
    "            \"details\": action_details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"actions\"][action_type] += 1\n",
    "        \n",
    "        logger.info(f\"âš¡ Action: {action_type} - {json.dumps(action_details, default=str)}\")\n",
    "    \n",
    "    def log_memory_operation(self, operation: str, details: Dict):\n",
    "        \"\"\"Log memory operation\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"memory_operation\"] = {\n",
    "            \"operation\": operation,\n",
    "            \"details\": details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"ðŸ’¾ Memory: {operation} - {json.dumps(details, default=str)}\")\n",
    "    \n",
    "    def log_error(self, error_type: str, error_message: str, context: Optional[Dict] = None):\n",
    "        \"\"\"Log an error\"\"\"\n",
    "        error_entry = {\n",
    "            \"type\": error_type,\n",
    "            \"message\": error_message,\n",
    "            \"context\": context or {},\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"errors\"].append(error_entry)\n",
    "        \n",
    "        if self.current_trace:\n",
    "            self.current_trace[\"errors\"].append(error_entry)\n",
    "        \n",
    "        logger.error(f\"âŒ Error [{error_type}]: {error_message}\")\n",
    "    \n",
    "    def end_trace(self):\n",
    "        \"\"\"End the current trace and store it\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        start_time = datetime.fromisoformat(self.current_trace[\"start_time\"])\n",
    "        duration_ms = (end_time - start_time).total_seconds() * 1000\n",
    "        \n",
    "        self.current_trace[\"end_time\"] = end_time.isoformat()\n",
    "        self.current_trace[\"duration_ms\"] = duration_ms\n",
    "        \n",
    "        self.traces.append(self.current_trace.copy())\n",
    "        self.metrics[\"total_notifications\"] += 1\n",
    "        \n",
    "        logger.info(f\"âœ… Trace completed: {self.current_trace['trace_id']} in {duration_ms:.2f}ms\")\n",
    "        self.current_trace = None\n",
    "    \n",
    "    def get_metrics_summary(self) -> Dict:\n",
    "        \"\"\"Get a summary of all metrics\"\"\"\n",
    "        avg_timings = {}\n",
    "        for key, timings in self.metrics[\"agent_timings\"].items():\n",
    "            if timings:\n",
    "                avg_timings[key] = {\n",
    "                    \"avg_ms\": sum(timings) / len(timings),\n",
    "                    \"min_ms\": min(timings),\n",
    "                    \"max_ms\": max(timings),\n",
    "                    \"count\": len(timings)\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            \"total_notifications\": self.metrics[\"total_notifications\"],\n",
    "            \"classifications\": dict(self.metrics[\"classifications\"]),\n",
    "            \"actions\": dict(self.metrics[\"actions\"]),\n",
    "            \"average_timings\": avg_timings,\n",
    "            \"error_count\": len(self.metrics[\"errors\"]),\n",
    "            \"total_traces\": len(self.traces)\n",
    "        }\n",
    "    \n",
    "    def get_recent_traces(self, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Get the most recent traces\"\"\"\n",
    "        return self.traces[-limit:] if self.traces else []\n",
    "    \n",
    "    def print_metrics_summary(self):\n",
    "        \"\"\"Print a formatted metrics summary\"\"\"\n",
    "        summary = self.get_metrics_summary()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“Š OBSERVABILITY METRICS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nðŸ“ˆ Total Notifications Processed: {summary['total_notifications']}\")\n",
    "        print(f\"ðŸ“ Total Traces Captured: {summary['total_traces']}\")\n",
    "        \n",
    "        print(\"\\nðŸ·ï¸  Classification Distribution:\")\n",
    "        for classification, count in summary['classifications'].items():\n",
    "            percentage = (count / summary['total_notifications'] * 100) if summary['total_notifications'] > 0 else 0\n",
    "            print(f\"   {classification}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nâš¡ Action Distribution:\")\n",
    "        for action, count in summary['actions'].items():\n",
    "            percentage = (count / summary['total_notifications'] * 100) if summary['total_notifications'] > 0 else 0\n",
    "            print(f\"   {action}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if summary['average_timings']:\n",
    "            print(\"\\nâ±ï¸  Performance Metrics:\")\n",
    "            for key, timing in summary['average_timings'].items():\n",
    "                print(f\"   {key}:\")\n",
    "                print(f\"      Average: {timing['avg_ms']:.2f}ms\")\n",
    "                print(f\"      Min: {timing['min_ms']:.2f}ms\")\n",
    "                print(f\"      Max: {timing['max_ms']:.2f}ms\")\n",
    "                print(f\"      Count: {timing['count']}\")\n",
    "        \n",
    "        if summary['error_count'] > 0:\n",
    "            print(f\"\\nâŒ Errors: {summary['error_count']}\")\n",
    "            for error in self.metrics['errors'][-5:]:  # Show last 5 errors\n",
    "                print(f\"   [{error['type']}] {error['message']}\")\n",
    "        \n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Initialize observability manager\n",
    "obs_manager = ObservabilityManager()\n",
    "\n",
    "print(\"âœ… Observability system initialized\")\n",
    "print(\"   â€¢ Structured logging enabled\")\n",
    "print(\"   â€¢ Trace capture ready\")\n",
    "print(\"   â€¢ Metrics collection active\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent orchestration layer initialized\n",
      "âœ… Sequential agent coordination ready\n",
      "âœ… Helper functions for async operations ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ORCHESTRATION LAYER: Sequential Agent Coordination\n",
    "# ============================================================================\n",
    "# This layer coordinates the sequential flow: Classification â†’ Action â†’ Memory\n",
    "\n",
    "# Create runners for each agent\n",
    "classification_runner = Runner(\n",
    "    app_name=\"FocusFilter_Classification\",\n",
    "    agent=classification_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "action_runner = Runner(\n",
    "    app_name=\"FocusFilter_Action\",\n",
    "    agent=action_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "memory_runner = Runner(\n",
    "    app_name=\"FocusFilter_Memory\",\n",
    "    agent=memory_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "# Main session service for the orchestration\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "def parse_classification_result(text: str) -> dict:\n",
    "    \"\"\"Parse the classification agent's response to extract structured data\"\"\"\n",
    "    result = {\n",
    "        \"classification\": None,\n",
    "        \"reasoning\": None,\n",
    "        \"key_fact\": None\n",
    "    }\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Try to find classification - look for URGENT, IRRELEVANT, or LESS_URGENT\n",
    "    for classification in [\"URGENT\", \"IRRELEVANT\", \"LESS_URGENT\", \"LESS URGENT\"]:\n",
    "        if classification.lower() in text_lower:\n",
    "            # Check if it's in a structured format like \"Classification: URGENT\"\n",
    "            if \"classification:\" in text_lower:\n",
    "                idx = text_lower.find(\"classification:\")\n",
    "                after_colon = text[text_lower.find(\"classification:\") + len(\"classification:\"):].strip()\n",
    "                # Extract the first word or phrase after the colon\n",
    "                words = after_colon.split()\n",
    "                if words:\n",
    "                    result[\"classification\"] = words[0].upper().rstrip(\".,;\")\n",
    "                    break\n",
    "            else:\n",
    "                # Look for the classification word in context\n",
    "                result[\"classification\"] = classification.upper()\n",
    "                break\n",
    "    \n",
    "    # Extract reasoning\n",
    "    if \"reasoning:\" in text_lower:\n",
    "        idx = text_lower.find(\"reasoning:\")\n",
    "        reasoning_text = text[idx + len(\"reasoning:\"):].strip()\n",
    "        # Take up to the next section or end of text\n",
    "        next_section = min(\n",
    "            reasoning_text.find(\"\\n\\n\"),\n",
    "            reasoning_text.find(\"Key Fact\"),\n",
    "            reasoning_text.find(\"key fact\"),\n",
    "            len(reasoning_text)\n",
    "        )\n",
    "        if next_section > 0:\n",
    "            result[\"reasoning\"] = reasoning_text[:next_section].strip()\n",
    "        else:\n",
    "            result[\"reasoning\"] = reasoning_text.strip()\n",
    "    \n",
    "    # Extract key fact (for LESS_URGENT items)\n",
    "    if \"key fact\" in text_lower:\n",
    "        idx = text_lower.find(\"key fact\")\n",
    "        fact_text = text[idx + len(\"key fact\"):].strip()\n",
    "        # Remove colon if present\n",
    "        if fact_text.startswith(\":\"):\n",
    "            fact_text = fact_text[1:].strip()\n",
    "        # Take up to next line break or end\n",
    "        next_line = fact_text.find(\"\\n\")\n",
    "        if next_line > 0:\n",
    "            result[\"key_fact\"] = fact_text[:next_line].strip()\n",
    "        else:\n",
    "            result[\"key_fact\"] = fact_text.strip()\n",
    "    \n",
    "    # Fallback: if classification not found, try to infer from text\n",
    "    if result[\"classification\"] is None:\n",
    "        if any(word in text_lower for word in [\"urgent\", \"immediate\", \"critical\", \"security alert\"]):\n",
    "            result[\"classification\"] = \"URGENT\"\n",
    "        elif any(word in text_lower for word in [\"irrelevant\", \"noise\", \"block\", \"spam\"]):\n",
    "            result[\"classification\"] = \"IRRELEVANT\"\n",
    "        elif any(word in text_lower for word in [\"less urgent\", \"store\", \"memory\", \"later\"]):\n",
    "            result[\"classification\"] = \"LESS_URGENT\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "async def process_notification_multi_agent(\n",
    "    notification_text: str,\n",
    "    user_id: str = \"default\",\n",
    "    session_id: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Orchestrate the sequential multi-agent processing of a notification.\n",
    "    \n",
    "    Flow:\n",
    "    1. Classification Agent analyzes and classifies\n",
    "    2. Action Agent executes appropriate action\n",
    "    3. Memory Agent (if needed) handles memory extraction\n",
    "    \n",
    "    Args:\n",
    "        notification_text: The notification message to process\n",
    "        user_id: User identifier\n",
    "        session_id: Optional session identifier (auto-generated if None)\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    if session_id is None:\n",
    "        session_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Start observability trace\n",
    "    notification_id = f\"notif_{uuid.uuid4().hex[:8]}\"\n",
    "    obs_manager.start_trace(notification_id, notification_text)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ” Processing notification with multi-agent system\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Step 1: Classification Agent\n",
    "    print(\"ðŸ“Š Step 1: Classification Agent analyzing...\")\n",
    "    classification_start = time.time()\n",
    "    classification_result_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        session = await classification_runner.session_service.create_session(\n",
    "            app_name=classification_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_classify\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"session_creation\", f\"Failed to create classification session: {e}\")\n",
    "        session = await classification_runner.session_service.get_session(\n",
    "            app_name=classification_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_classify\"\n",
    "        )\n",
    "    \n",
    "    message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=notification_text)]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        async for event in classification_runner.run_async(\n",
    "            user_id=user_id,\n",
    "            session_id=session.id,\n",
    "            new_message=message\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                if event.content.parts[0].text:\n",
    "                    classification_result_text += event.content.parts[0].text\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"classification_error\", f\"Classification agent error: {e}\", {\"session_id\": session_id})\n",
    "        raise\n",
    "    \n",
    "    classification_duration = (time.time() - classification_start) * 1000\n",
    "    print(f\"âœ… Classification complete\")\n",
    "    print(f\"   Result: {classification_result_text[:200]}...\\n\")\n",
    "    \n",
    "    # Parse classification result\n",
    "    classification_data = parse_classification_result(classification_result_text)\n",
    "    \n",
    "    # Log classification step\n",
    "    obs_manager.log_agent_step(\n",
    "        agent_name=\"Classification Agent\",\n",
    "        step=\"classify\",\n",
    "        input_data={\"notification_text\": notification_text[:200]},\n",
    "        output_data=classification_data,\n",
    "        duration_ms=classification_duration\n",
    "    )\n",
    "    \n",
    "    # Log classification result\n",
    "    if classification_data['classification']:\n",
    "        obs_manager.log_classification(\n",
    "            classification=classification_data['classification'],\n",
    "            reasoning=classification_data.get('reasoning', 'No reasoning provided')\n",
    "        )\n",
    "    \n",
    "    # Extract notification details from input\n",
    "    # Format: \"I received a notification: App: X, Title: Y, Body: Z\"\n",
    "    app = \"Unknown\"\n",
    "    title = \"Unknown\"\n",
    "    body = \"Unknown\"\n",
    "    \n",
    "    if \"App:\" in notification_text:\n",
    "        parts = notification_text.split(\"App:\")[-1]\n",
    "        if \"Title:\" in parts:\n",
    "            app = parts.split(\"Title:\")[0].strip().rstrip(\",\")\n",
    "            title_part = parts.split(\"Title:\")[-1]\n",
    "            if \"Body:\" in title_part:\n",
    "                title = title_part.split(\"Body:\")[0].strip().rstrip(\",\")\n",
    "                body = title_part.split(\"Body:\")[-1].strip()\n",
    "    \n",
    "    # Step 2: Action Agent\n",
    "    print(\"âš¡ Step 2: Action Agent executing...\")\n",
    "    action_start = time.time()\n",
    "    \n",
    "    # Prepare action message with classification result\n",
    "    action_message_text = f\"\"\"Notification Details:\n",
    "- App: {app}\n",
    "- Title: {title}\n",
    "- Body: {body}\n",
    "\n",
    "Classification Result:\n",
    "- Classification: {classification_data['classification']}\n",
    "- Reasoning: {classification_data['reasoning']}\n",
    "{f\"- Key Fact: {classification_data['key_fact']}\" if classification_data['key_fact'] else \"\"}\n",
    "\n",
    "Please execute the appropriate action based on the classification.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        action_session = await action_runner.session_service.create_session(\n",
    "            app_name=action_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_action\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"session_creation\", f\"Failed to create action session: {e}\")\n",
    "        action_session = await action_runner.session_service.get_session(\n",
    "            app_name=action_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_action\"\n",
    "        )\n",
    "    \n",
    "    action_message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=action_message_text)]\n",
    "    )\n",
    "    \n",
    "    action_output = \"\"\n",
    "    try:\n",
    "        async for event in action_runner.run_async(\n",
    "            user_id=user_id,\n",
    "            session_id=action_session.id,\n",
    "            new_message=action_message\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                if event.content.parts[0].text:\n",
    "                    action_output += event.content.parts[0].text\n",
    "                    print(event.content.parts[0].text)\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"action_error\", f\"Action agent error: {e}\", {\"session_id\": session_id})\n",
    "        raise\n",
    "    \n",
    "    action_duration = (time.time() - action_start) * 1000\n",
    "    \n",
    "    # Determine action type from output\n",
    "    action_type = \"unknown\"\n",
    "    if \"display_urgent_notification\" in action_output.lower() or \"urgent notification\" in action_output.lower():\n",
    "        action_type = \"display_urgent\"\n",
    "    elif \"block\" in action_output.lower() or \"blocked\" in action_output.lower():\n",
    "        action_type = \"block\"\n",
    "    elif \"save\" in action_output.lower() or \"memory\" in action_output.lower() or \"stored\" in action_output.lower():\n",
    "        action_type = \"save_memory\"\n",
    "    \n",
    "    # Log action step\n",
    "    obs_manager.log_agent_step(\n",
    "        agent_name=\"Action Agent\",\n",
    "        step=\"execute\",\n",
    "        input_data={\n",
    "            \"classification\": classification_data['classification'],\n",
    "            \"app\": app,\n",
    "            \"title\": title\n",
    "        },\n",
    "        output_data={\"action_type\": action_type, \"output\": action_output[:200]},\n",
    "        duration_ms=action_duration\n",
    "    )\n",
    "    \n",
    "    # Log action\n",
    "    obs_manager.log_action(\n",
    "        action_type=action_type,\n",
    "        action_details={\n",
    "            \"app\": app,\n",
    "            \"title\": title,\n",
    "            \"classification\": classification_data['classification']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Action execution complete\\n\")\n",
    "    \n",
    "    # Step 3: Memory Agent (only for LESS_URGENT items that need extraction refinement)\n",
    "    if classification_data['classification'] == 'LESS_URGENT':\n",
    "        print(\"ðŸ’¾ Step 3: Memory Agent extracting fact...\")\n",
    "        memory_start = time.time()\n",
    "        \n",
    "        # Log memory operation\n",
    "        if classification_data.get('key_fact'):\n",
    "            obs_manager.log_memory_operation(\n",
    "                operation=\"store\",\n",
    "                details={\n",
    "                    \"app\": app,\n",
    "                    \"extracted_fact\": classification_data['key_fact'],\n",
    "                    \"title\": title\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        memory_duration = (time.time() - memory_start) * 1000\n",
    "        obs_manager.log_agent_step(\n",
    "            agent_name=\"Memory Agent\",\n",
    "            step=\"extract\",\n",
    "            input_data={\"notification\": f\"{app}: {title}\"},\n",
    "            output_data={\"extracted_fact\": classification_data.get('key_fact', '')},\n",
    "            duration_ms=memory_duration\n",
    "        )\n",
    "        \n",
    "        # The action agent already stored the memory, but we can use memory agent\n",
    "        # for additional processing if needed (consolidation, deduplication, etc.)\n",
    "        # For now, we'll skip this step as the action agent handles storage\n",
    "        print(\"âœ… Memory extraction handled by Action Agent\\n\")\n",
    "    \n",
    "    # End trace\n",
    "    obs_manager.end_trace()\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"âœ… Multi-agent processing complete\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Legacy helper function for backward compatibility (uses single agent approach)\n",
    "async def run_notification_test(runner_instance, session_service, user_id, session_id, message_text):\n",
    "    \"\"\"Helper function to test notification processing (legacy single-agent)\"\"\"\n",
    "    # Create or get session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=runner_instance.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=runner_instance.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    \n",
    "    # Convert message to Content format\n",
    "    message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=message_text)]\n",
    "    )\n",
    "    \n",
    "    # Process the notification\n",
    "    async for event in runner_instance.run_async(\n",
    "        user_id=user_id, session_id=session.id, new_message=message\n",
    "    ):\n",
    "        if event.content and event.content.parts:\n",
    "            if event.content.parts[0].text:\n",
    "                print(event.content.parts[0].text)\n",
    "\n",
    "print(\"âœ… Multi-agent orchestration layer initialized\")\n",
    "print(\"âœ… Sequential agent coordination ready\")\n",
    "print(\"âœ… Helper functions for async operations ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Agent\n",
    "\n",
    "Let's test the agent with sample notifications:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:22,752 - FocusFilter - INFO - ðŸ” Trace started: trace_6342aa54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:23,234 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:43:23,980 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:23,991 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 1236.03ms\n",
      "2025-12-02 02:43:23,996 - FocusFilter - INFO - ðŸ·ï¸  Classification: URGENT - Security alert from a banking app requires immediate attention to prevent potential fraud.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: URGENT\n",
      "Reasoning: Security alert from a banking app requires immediate attention to prevent potential fraud.\n",
      "...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:24,330 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:43:25,161 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:25,163 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:43:25,174 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Banking App\n",
      "Title: Security Alert\n",
      "Body: Your bank flagged suspicious activity on your account. Please verify immediately.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:25,807 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:25,810 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1808.52ms\n",
      "2025-12-02 02:43:25,811 - FocusFilter - INFO - âš¡ Action: display_urgent - {\"app\": \"Banking App\", \"title\": \"Security Alert\", \"classification\": \"URGENT\"}\n",
      "2025-12-02 02:43:25,813 - FocusFilter - INFO - âœ… Trace completed: trace_6342aa54 in 3061.68ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have displayed the urgent notification to the user.\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 1 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 1: Urgent security alert\n",
    "USER_ID = \"test\"\n",
    "\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Banking App, Title: Security Alert, Body: Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_1\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 1 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:25,833 - FocusFilter - INFO - ðŸ” Trace started: trace_86cb1c48\n",
      "2025-12-02 02:43:25,839 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:26,491 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:26,495 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 658.09ms\n",
      "2025-12-02 02:43:26,496 - FocusFilter - INFO - ðŸ·ï¸  Classification: IRRELEVANT - Social media likes are generally not important or time-sensitive.\n",
      "2025-12-02 02:43:26,501 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: IRRELEVANT\n",
      "Reasoning: Social media likes are generally not important or time-sensitive.\n",
      "...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:27,209 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:27,211 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:43:27,224 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Social Media] New Like - social media noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:27,866 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:27,871 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1372.97ms\n",
      "2025-12-02 02:43:27,872 - FocusFilter - INFO - âš¡ Action: block - {\"app\": \"Social Media\", \"title\": \"New Like\", \"classification\": \"IRRELEVANT\"}\n",
      "2025-12-02 02:43:27,873 - FocusFilter - INFO - âœ… Trace completed: trace_86cb1c48 in 2040.36ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have blocked the notification from Social Media with the title \"New Like\" because it is social media noise.\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 2 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 2: Irrelevant social media\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_2\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 2 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š OBSERVABILITY METRICS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Total Notifications Processed: 2\n",
      "ðŸ“ Total Traces Captured: 2\n",
      "\n",
      "ðŸ·ï¸  Classification Distribution:\n",
      "   URGENT: 1 (50.0%)\n",
      "   IRRELEVANT: 1 (50.0%)\n",
      "\n",
      "âš¡ Action Distribution:\n",
      "   display_urgent: 1 (50.0%)\n",
      "   block: 1 (50.0%)\n",
      "\n",
      "â±ï¸  Performance Metrics:\n",
      "   Classification Agent_classify:\n",
      "      Average: 947.06ms\n",
      "      Min: 658.09ms\n",
      "      Max: 1236.03ms\n",
      "      Count: 2\n",
      "   Action Agent_execute:\n",
      "      Average: 1590.75ms\n",
      "      Min: 1372.97ms\n",
      "      Max: 1808.52ms\n",
      "      Count: 2\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display observability metrics\n",
    "obs_manager.print_metrics_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” DETAILED TRACE EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "Trace ID: trace_86cb1c48\n",
      "Notification ID: notif_aabb98dc\n",
      "Duration: 2040.36ms\n",
      "\n",
      "Notification Text: I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo....\n",
      "\n",
      "ðŸ“Š Classification:\n",
      "   Result: IRRELEVANT\n",
      "   Reasoning: Social media likes are generally not important or time-sensitive....\n",
      "\n",
      "âš¡ Action:\n",
      "   Type: block\n",
      "   Details: {'app': 'Social Media', 'title': 'New Like', 'classification': 'IRRELEVANT'}\n",
      "\n",
      "ðŸ¤– Agent Steps:\n",
      "   Classification Agent - classify: 658.09ms\n",
      "   Action Agent - execute: 1372.97ms\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a detailed trace example\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ” DETAILED TRACE EXAMPLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recent_traces = obs_manager.get_recent_traces(limit=1)\n",
    "if recent_traces:\n",
    "    trace = recent_traces[0]\n",
    "    print(f\"\\nTrace ID: {trace['trace_id']}\")\n",
    "    print(f\"Notification ID: {trace['notification_id']}\")\n",
    "    print(f\"Duration: {trace['duration_ms']:.2f}ms\")\n",
    "    print(f\"\\nNotification Text: {trace['notification_text'][:100]}...\")\n",
    "    \n",
    "    if trace['classification']:\n",
    "        print(f\"\\nðŸ“Š Classification:\")\n",
    "        print(f\"   Result: {trace['classification']['result']}\")\n",
    "        print(f\"   Reasoning: {trace['classification']['reasoning'][:150]}...\")\n",
    "    \n",
    "    if trace['action']:\n",
    "        print(f\"\\nâš¡ Action:\")\n",
    "        print(f\"   Type: {trace['action']['type']}\")\n",
    "        print(f\"   Details: {trace['action']['details']}\")\n",
    "    \n",
    "    if trace['memory_operation']:\n",
    "        print(f\"\\nðŸ’¾ Memory Operation:\")\n",
    "        print(f\"   Operation: {trace['memory_operation']['operation']}\")\n",
    "        print(f\"   Details: {trace['memory_operation']['details']}\")\n",
    "    \n",
    "    if trace['agents']:\n",
    "        print(f\"\\nðŸ¤– Agent Steps:\")\n",
    "        for agent_step in trace['agents']:\n",
    "            print(f\"   {agent_step['agent']} - {agent_step['step']}: {agent_step['duration_ms']:.2f}ms\")\n",
    "    \n",
    "    if trace['errors']:\n",
    "        print(f\"\\nâŒ Errors: {len(trace['errors'])}\")\n",
    "        for error in trace['errors']:\n",
    "            print(f\"   [{error['type']}] {error['message']}\")\n",
    "else:\n",
    "    print(\"No traces available yet. Run some notifications first!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:27,938 - FocusFilter - INFO - ðŸ” Trace started: trace_c13ff761\n",
      "2025-12-02 02:43:27,944 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:28,607 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:28,613 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 670.91ms\n",
      "2025-12-02 02:43:28,617 - FocusFilter - INFO - ðŸ·ï¸  Classification: LESS_URGENT - The notification is providing an update on a project deadline, which is important to know but doesn'\n",
      "2025-12-02 02:43:28,639 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: LESS_URGENT\n",
      "Reasoning: The notification is providing an update on a project deadline, which is important to know but doesn't require immediate action.\n",
      "Key Fact (if LESS_URGENT): Projec...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:29,563 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:29,565 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:43:29,579 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Project deadline moved to Tuesday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:30,180 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:30,187 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1559.93ms\n",
      "2025-12-02 02:43:30,190 - FocusFilter - INFO - âš¡ Action: save_memory - {\"app\": \"Project Manager\", \"title\": \"Deadline Update\", \"classification\": \"LESS_URGENT\"}\n",
      "2025-12-02 02:43:30,194 - FocusFilter - INFO - ðŸ’¾ Memory: store - {\"app\": \"Project Manager\", \"extracted_fact\": \"(if LESS_URGENT): Project deadline moved to Tuesday.\", \"title\": \"Deadline Update\"}\n",
      "2025-12-02 02:43:30,197 - FocusFilter - INFO - ðŸ“Š Memory Agent - extract completed in 3.48ms\n",
      "2025-12-02 02:43:30,200 - FocusFilter - INFO - âœ… Trace completed: trace_c13ff761 in 2262.49ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have saved the notification to memory with the key fact \"Project deadline moved to Tuesday.\"\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "ðŸ’¾ Step 3: Memory Agent extracting fact...\n",
      "âœ… Memory extraction handled by Action Agent\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 3 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 3: Less urgent project update\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Project Manager, Title: Deadline Update, Body: Your project deadline has moved to Tuesday.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_3\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 3 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ’¾ Stored Memories:\n",
      "======================================================================\n",
      "\n",
      "1. Project deadline moved to Tuesday.\n",
      "   From: Project Manager (stored at 2025-12-02T02:43:29.575162)\n"
     ]
    }
   ],
   "source": [
    "# Display stored memories\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’¾ Stored Memories:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "memories = memory_store.get_all()\n",
    "if memories:\n",
    "    for i, memory in enumerate(memories, 1):\n",
    "        print(f\"\\n{i}. {memory['extracted_fact']}\")\n",
    "        print(f\"   From: {memory['app']} (stored at {memory['stored_at']})\")\n",
    "else:\n",
    "    print(\"No memories stored yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”§ Testing Enhanced Features\n",
      "======================================================================\n",
      "\n",
      "1. Testing retrieve_user_preferences() tool:\n",
      "   Current preferences: {'always_urgent_apps': [], 'always_block_apps': [], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "2. Testing preference learning:\n",
      "âœ… Added preference: always_urgent_apps = Banking App\n",
      "âœ… Added preference: always_block_apps = Social Media\n",
      "   Updated preferences: {'always_urgent_apps': ['Banking App'], 'always_block_apps': ['Social Media'], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "3. Testing memory consolidation:\n",
      "ðŸ’¾ Stored memory: Project deadline moved to Tuesday\n",
      "   Memories before consolidation: 2\n",
      "   Memories after consolidation: 2\n",
      "\n",
      "4. Testing context compaction:\n",
      "   Compacted context: 2 most relevant memories\n",
      "\n",
      "5. Testing preference learning from patterns:\n",
      "   Learned preferences: {'always_urgent_apps': ['Banking App'], 'always_block_apps': ['Social Media'], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "======================================================================\n",
      "âœ… Enhanced features demonstration complete\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEMONSTRATION: Enhanced Memory and Tools Features\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”§ Testing Enhanced Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Retrieve user preferences\n",
    "print(\"\\n1. Testing retrieve_user_preferences() tool:\")\n",
    "prefs = retrieve_user_preferences()\n",
    "if prefs.get('status') == 'success' and 'preferences' in prefs:\n",
    "    print(f\"   Current preferences: {prefs['preferences']}\")\n",
    "else:\n",
    "    error_msg = prefs.get('error_message', 'Unknown error')\n",
    "    print(f\"   Error: {error_msg}\")\n",
    "    # Fallback: try direct access if method exists\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        try:\n",
    "            direct_prefs = memory_store.get_user_preferences()\n",
    "            print(f\"   Direct access preferences: {direct_prefs}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Direct access failed: {e}\")\n",
    "    else:\n",
    "        print(\"   Note: Enhanced methods not yet available (run enhancement cell first)\")\n",
    "\n",
    "# Test 2: Update preferences\n",
    "print(\"\\n2. Testing preference learning:\")\n",
    "if hasattr(memory_store, 'update_preference'):\n",
    "    memory_store.update_preference(\"always_urgent_apps\", \"Banking App\", \"add\")\n",
    "    memory_store.update_preference(\"always_block_apps\", \"Social Media\", \"add\")\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        print(f\"   Updated preferences: {memory_store.get_user_preferences()}\")\n",
    "    else:\n",
    "        print(\"   Preferences updated (get_user_preferences not available)\")\n",
    "else:\n",
    "    print(\"   Note: update_preference method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 3: Memory consolidation\n",
    "print(\"\\n3. Testing memory consolidation:\")\n",
    "if hasattr(memory_store, 'consolidate_memories'):\n",
    "    # Add a similar memory to test consolidation\n",
    "    if memory_store.memories:\n",
    "        test_notification = Notification(\n",
    "            id=str(uuid.uuid4()),\n",
    "            app=\"Project Manager\",\n",
    "            title=\"Deadline Update\",\n",
    "            body=\"Your project deadline has moved to Tuesday.\",\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        memory_store.store(test_notification, \"Project deadline moved to Tuesday\")\n",
    "        print(f\"   Memories before consolidation: {len(memory_store.memories)}\")\n",
    "        consolidated_count = memory_store.consolidate_memories()\n",
    "        print(f\"   Memories after consolidation: {consolidated_count}\")\n",
    "    else:\n",
    "        print(\"   No memories to consolidate\")\n",
    "else:\n",
    "    print(\"   Note: consolidate_memories method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 4: Context compaction\n",
    "print(\"\\n4. Testing context compaction:\")\n",
    "if hasattr(memory_store, 'compact_context'):\n",
    "    compacted = memory_store.compact_context(max_memories=5)\n",
    "    print(f\"   Compacted context: {len(compacted)} most relevant memories\")\n",
    "else:\n",
    "    print(\"   Note: compact_context method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 5: Preference learning from patterns\n",
    "print(\"\\n5. Testing preference learning from patterns:\")\n",
    "if hasattr(memory_store, 'learn_from_patterns'):\n",
    "    classification_history = [\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "    ]\n",
    "    memory_store.learn_from_patterns(classification_history)\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        print(f\"   Learned preferences: {memory_store.get_user_preferences()}\")\n",
    "    else:\n",
    "        print(\"   Pattern learning completed\")\n",
    "else:\n",
    "    print(\"   Note: learn_from_patterns method not available (run enhancement cell first)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Enhanced features demonstration complete\")\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent Evaluation Framework initialized\n",
      "   â€¢ Golden test suite ready ({len(GOLDEN_TEST_SUITE)} test cases)\n",
      "   â€¢ LLM-as-judge evaluation ready\n",
      "   â€¢ Metrics calculation ready\n",
      "   â€¢ Run evaluation_framework.run_evaluation() to start\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Agent Evaluation Framework (LLM-as-Judge)\n",
    "# ============================================================================\n",
    "# This implements automated evaluation of agent performance using:\n",
    "# - Golden test suite with labeled notifications\n",
    "# - LLM-as-judge evaluation framework\n",
    "# - Comprehensive metrics (classification accuracy, action correctness, memory quality)\n",
    "# - Automated scoring and reporting\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class TestCase:\n",
    "    \"\"\"Represents a test case with expected results\"\"\"\n",
    "    id: str\n",
    "    notification_text: str\n",
    "    app: str\n",
    "    title: str\n",
    "    body: str\n",
    "    expected_classification: str  # URGENT, IRRELEVANT, or LESS_URGENT\n",
    "    expected_action: str  # display_urgent, block, or save_memory\n",
    "    expected_extracted_fact: Optional[str] = None  # For LESS_URGENT cases\n",
    "    reasoning: str = \"\"  # Why this classification is expected\n",
    "\n",
    "# Golden test suite - labeled notifications for evaluation\n",
    "GOLDEN_TEST_SUITE = [\n",
    "    TestCase(\n",
    "        id=\"test_001\",\n",
    "        notification_text=\"I received a notification: App: Banking App, Title: Security Alert, Body: Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "        app=\"Banking App\",\n",
    "        title=\"Security Alert\",\n",
    "        body=\"Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "        expected_classification=\"URGENT\",\n",
    "        expected_action=\"display_urgent\",\n",
    "        reasoning=\"Security alerts from banking apps require immediate attention\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_002\",\n",
    "        notification_text=\"I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo.\",\n",
    "        app=\"Social Media\",\n",
    "        title=\"New Like\",\n",
    "        body=\"3 new people liked your photo.\",\n",
    "        expected_classification=\"IRRELEVANT\",\n",
    "        expected_action=\"block\",\n",
    "        reasoning=\"Social media likes are noise and don't require attention\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_003\",\n",
    "        notification_text=\"I received a notification: App: Project Manager, Title: Deadline Update, Body: Your project deadline has moved to Tuesday.\",\n",
    "        app=\"Project Manager\",\n",
    "        title=\"Deadline Update\",\n",
    "        body=\"Your project deadline has moved to Tuesday.\",\n",
    "        expected_classification=\"LESS_URGENT\",\n",
    "        expected_action=\"save_memory\",\n",
    "        expected_extracted_fact=\"Project deadline moved to Tuesday\",\n",
    "        reasoning=\"Project updates are important but not immediately urgent\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_004\",\n",
    "        notification_text=\"I received a notification: App: Email, Title: Meeting Reminder, Body: You have a meeting in 15 minutes with the CEO.\",\n",
    "        app=\"Email\",\n",
    "        title=\"Meeting Reminder\",\n",
    "        body=\"You have a meeting in 15 minutes with the CEO.\",\n",
    "        expected_classification=\"URGENT\",\n",
    "        expected_action=\"display_urgent\",\n",
    "        reasoning=\"Time-sensitive meeting reminders require immediate attention\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_005\",\n",
    "        notification_text=\"I received a notification: App: Shopping App, Title: Flash Sale, Body: 50% off all items! Limited time offer!\",\n",
    "        app=\"Shopping App\",\n",
    "        title=\"Flash Sale\",\n",
    "        body=\"50% off all items! Limited time offer!\",\n",
    "        expected_classification=\"IRRELEVANT\",\n",
    "        expected_action=\"block\",\n",
    "        reasoning=\"Promotional content is typically noise\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_006\",\n",
    "        notification_text=\"I received a notification: App: Calendar, Title: Event Tomorrow, Body: Team standup meeting scheduled for tomorrow at 10 AM.\",\n",
    "        app=\"Calendar\",\n",
    "        title=\"Event Tomorrow\",\n",
    "        body=\"Team standup meeting scheduled for tomorrow at 10 AM.\",\n",
    "        expected_classification=\"LESS_URGENT\",\n",
    "        expected_action=\"save_memory\",\n",
    "        expected_extracted_fact=\"Team standup meeting tomorrow at 10 AM\",\n",
    "        reasoning=\"Future events are important to remember but not urgent\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_007\",\n",
    "        notification_text=\"I received a notification: App: Health App, Title: Medication Reminder, Body: Time to take your daily medication.\",\n",
    "        app=\"Health App\",\n",
    "        title=\"Medication Reminder\",\n",
    "        body=\"Time to take your daily medication.\",\n",
    "        expected_classification=\"URGENT\",\n",
    "        expected_action=\"display_urgent\",\n",
    "        reasoning=\"Health-related reminders are time-sensitive and important\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_008\",\n",
    "        notification_text=\"I received a notification: App: News App, Title: Breaking News, Body: Local weather update: Sunny skies expected today.\",\n",
    "        app=\"News App\",\n",
    "        title=\"Breaking News\",\n",
    "        body=\"Local weather update: Sunny skies expected today.\",\n",
    "        expected_classification=\"IRRELEVANT\",\n",
    "        expected_action=\"block\",\n",
    "        reasoning=\"Generic news updates are typically not urgent\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "class EvaluationJudge:\n",
    "    \"\"\"LLM-as-judge for evaluating agent performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.judge_agent = LlmAgent(\n",
    "            name=\"evaluation_judge\",\n",
    "            model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "            instruction=\"\"\"You are an Evaluation Judge for the Focus Filter notification system.\n",
    "\n",
    "Your job is to evaluate whether an agent's classification and actions match the expected behavior.\n",
    "\n",
    "You will receive:\n",
    "1. The test case (notification and expected results)\n",
    "2. The agent's actual output (classification, action, extracted fact)\n",
    "\n",
    "Evaluate:\n",
    "1. **Classification Match**: Does the agent's classification match the expected classification?\n",
    "   - URGENT, IRRELEVANT, or LESS_URGENT\n",
    "   - Consider if the classification is reasonable even if not exact match\n",
    "\n",
    "2. **Action Match**: Does the agent's action match the expected action?\n",
    "   - display_urgent, block, or save_memory\n",
    "   - Action should align with classification\n",
    "\n",
    "3. **Memory Extraction Quality** (for LESS_URGENT cases):\n",
    "   - Is the extracted fact accurate and useful?\n",
    "   - Does it capture the key information?\n",
    "\n",
    "Respond in JSON format:\n",
    "{\n",
    "    \"classification_match\": true/false,\n",
    "    \"classification_score\": 0.0-1.0,\n",
    "    \"action_match\": true/false,\n",
    "    \"action_score\": 0.0-1.0,\n",
    "    \"memory_quality\": 0.0-1.0 (only for LESS_URGENT),\n",
    "    \"overall_score\": 0.0-1.0,\n",
    "    \"reasoning\": \"explanation of scores\"\n",
    "}\"\"\",\n",
    "            tools=[]\n",
    "        )\n",
    "        self.judge_runner = Runner(\n",
    "            app_name=\"FocusFilter_Evaluation\",\n",
    "            agent=self.judge_agent,\n",
    "            session_service=InMemorySessionService()\n",
    "        )\n",
    "    \n",
    "    async def evaluate_single_case(\n",
    "        self, \n",
    "        test_case: TestCase, \n",
    "        actual_classification: str,\n",
    "        actual_action: str,\n",
    "        actual_extracted_fact: Optional[str] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"Evaluate a single test case using LLM-as-judge\"\"\"\n",
    "        \n",
    "        evaluation_prompt = f\"\"\"Evaluate this agent performance:\n",
    "\n",
    "TEST CASE:\n",
    "- Notification: {test_case.app} - {test_case.title}: {test_case.body}\n",
    "- Expected Classification: {test_case.expected_classification}\n",
    "- Expected Action: {test_case.expected_action}\n",
    "{f\"- Expected Extracted Fact: {test_case.expected_extracted_fact}\" if test_case.expected_extracted_fact else \"\"}\n",
    "- Reasoning: {test_case.reasoning}\n",
    "\n",
    "AGENT OUTPUT:\n",
    "- Actual Classification: {actual_classification}\n",
    "- Actual Action: {actual_action}\n",
    "{f\"- Actual Extracted Fact: {actual_extracted_fact}\" if actual_extracted_fact else \"\"}\n",
    "\n",
    "Evaluate the agent's performance and provide scores in JSON format.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            session = await self.judge_runner.session_service.create_session(\n",
    "                app_name=self.judge_runner.app_name,\n",
    "                user_id=\"evaluator\",\n",
    "                session_id=f\"eval_{test_case.id}\"\n",
    "            )\n",
    "            \n",
    "            message = types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=evaluation_prompt)]\n",
    "            )\n",
    "            \n",
    "            judge_response = \"\"\n",
    "            async for event in self.judge_runner.run_async(\n",
    "                user_id=\"evaluator\",\n",
    "                session_id=session.id,\n",
    "                new_message=message\n",
    "            ):\n",
    "                if event.content and event.content.parts:\n",
    "                    if event.content.parts[0].text:\n",
    "                        judge_response += event.content.parts[0].text\n",
    "            \n",
    "            # Try to parse JSON from response\n",
    "            try:\n",
    "                # Extract JSON from response (might be wrapped in markdown)\n",
    "                if \"```json\" in judge_response:\n",
    "                    json_start = judge_response.find(\"```json\") + 7\n",
    "                    json_end = judge_response.find(\"```\", json_start)\n",
    "                    judge_response = judge_response[json_start:json_end].strip()\n",
    "                elif \"```\" in judge_response:\n",
    "                    json_start = judge_response.find(\"```\") + 3\n",
    "                    json_end = judge_response.find(\"```\", json_start)\n",
    "                    judge_response = judge_response[json_start:json_end].strip()\n",
    "                \n",
    "                evaluation_result = json.loads(judge_response)\n",
    "            except:\n",
    "                # Fallback: simple scoring based on exact matches\n",
    "                evaluation_result = {\n",
    "                    \"classification_match\": actual_classification.upper() == test_case.expected_classification.upper(),\n",
    "                    \"classification_score\": 1.0 if actual_classification.upper() == test_case.expected_classification.upper() else 0.0,\n",
    "                    \"action_match\": actual_action == test_case.expected_action,\n",
    "                    \"action_score\": 1.0 if actual_action == test_case.expected_action else 0.0,\n",
    "                    \"memory_quality\": 0.5,  # Default\n",
    "                    \"overall_score\": 0.5,\n",
    "                    \"reasoning\": \"Fallback scoring used (JSON parsing failed)\"\n",
    "                }\n",
    "            \n",
    "            return {\n",
    "                \"test_case_id\": test_case.id,\n",
    "                \"evaluation\": evaluation_result,\n",
    "                \"expected\": {\n",
    "                    \"classification\": test_case.expected_classification,\n",
    "                    \"action\": test_case.expected_action,\n",
    "                    \"extracted_fact\": test_case.expected_extracted_fact\n",
    "                },\n",
    "                \"actual\": {\n",
    "                    \"classification\": actual_classification,\n",
    "                    \"action\": actual_action,\n",
    "                    \"extracted_fact\": actual_extracted_fact\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"test_case_id\": test_case.id,\n",
    "                \"error\": str(e),\n",
    "                \"evaluation\": {\n",
    "                    \"classification_match\": False,\n",
    "                    \"classification_score\": 0.0,\n",
    "                    \"action_match\": False,\n",
    "                    \"action_score\": 0.0,\n",
    "                    \"overall_score\": 0.0,\n",
    "                    \"reasoning\": f\"Evaluation error: {e}\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "class EvaluationFramework:\n",
    "    \"\"\"Comprehensive evaluation framework for agent performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.judge = EvaluationJudge()\n",
    "        self.results: List[Dict] = []\n",
    "    \n",
    "    async def run_evaluation(self, test_suite: List[TestCase] = None) -> Dict:\n",
    "        \"\"\"Run evaluation on the test suite\"\"\"\n",
    "        if test_suite is None:\n",
    "            test_suite = GOLDEN_TEST_SUITE\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ”¬ AGENT EVALUATION FRAMEWORK\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nðŸ“‹ Running evaluation on {len(test_suite)} test cases...\\n\")\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        for i, test_case in enumerate(test_suite, 1):\n",
    "            print(f\"[{i}/{len(test_suite)}] Processing: {test_case.id} - {test_case.app}\")\n",
    "            \n",
    "            # Process notification through the agent system\n",
    "            try:\n",
    "                # Extract notification details\n",
    "                notification_id = f\"eval_{test_case.id}\"\n",
    "                \n",
    "                # Run through the multi-agent system\n",
    "                # We'll capture the results from the orchestration\n",
    "                # For now, we'll simulate by calling the process function\n",
    "                # and capturing the results\n",
    "                \n",
    "                # Start trace\n",
    "                obs_manager.start_trace(notification_id, test_case.notification_text)\n",
    "                \n",
    "                # Run classification\n",
    "                classification_start = time.time()\n",
    "                session = await classification_runner.session_service.create_session(\n",
    "                    app_name=classification_runner.app_name,\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=f\"eval_{test_case.id}_classify\"\n",
    "                )\n",
    "                \n",
    "                message = types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part(text=test_case.notification_text)]\n",
    "                )\n",
    "                \n",
    "                classification_result_text = \"\"\n",
    "                async for event in classification_runner.run_async(\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=session.id,\n",
    "                    new_message=message\n",
    "                ):\n",
    "                    if event.content and event.content.parts:\n",
    "                        if event.content.parts[0].text:\n",
    "                            classification_result_text += event.content.parts[0].text\n",
    "                \n",
    "                classification_data = parse_classification_result(classification_result_text)\n",
    "                actual_classification = classification_data.get('classification', 'UNKNOWN')\n",
    "                \n",
    "                # Run action\n",
    "                action_start = time.time()\n",
    "                action_session = await action_runner.session_service.create_session(\n",
    "                    app_name=action_runner.app_name,\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=f\"eval_{test_case.id}_action\"\n",
    "                )\n",
    "                \n",
    "                action_message_text = f\"\"\"Notification Details:\n",
    "- App: {test_case.app}\n",
    "- Title: {test_case.title}\n",
    "- Body: {test_case.body}\n",
    "\n",
    "Classification Result:\n",
    "- Classification: {actual_classification}\n",
    "- Reasoning: {classification_data.get('reasoning', '')}\n",
    "{f\"- Key Fact: {classification_data.get('key_fact', '')}\" if classification_data.get('key_fact') else \"\"}\n",
    "\n",
    "Please execute the appropriate action based on the classification.\"\"\"\n",
    "                \n",
    "                action_message = types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part(text=action_message_text)]\n",
    "                )\n",
    "                \n",
    "                action_output = \"\"\n",
    "                async for event in action_runner.run_async(\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=action_session.id,\n",
    "                    new_message=action_message\n",
    "                ):\n",
    "                    if event.content and event.content.parts:\n",
    "                        if event.content.parts[0].text:\n",
    "                            action_output += event.content.parts[0].text\n",
    "                \n",
    "                # Determine actual action from output\n",
    "                actual_action = \"unknown\"\n",
    "                if \"display_urgent_notification\" in action_output.lower() or \"urgent notification\" in action_output.lower():\n",
    "                    actual_action = \"display_urgent\"\n",
    "                elif \"block\" in action_output.lower() or \"blocked\" in action_output.lower():\n",
    "                    actual_action = \"block\"\n",
    "                elif \"save\" in action_output.lower() or \"memory\" in action_output.lower() or \"stored\" in action_output.lower():\n",
    "                    actual_action = \"save_memory\"\n",
    "                \n",
    "                actual_extracted_fact = classification_data.get('key_fact')\n",
    "                \n",
    "                # Evaluate using LLM-as-judge\n",
    "                evaluation_result = await self.judge.evaluate_single_case(\n",
    "                    test_case=test_case,\n",
    "                    actual_classification=actual_classification,\n",
    "                    actual_action=actual_action,\n",
    "                    actual_extracted_fact=actual_extracted_fact\n",
    "                )\n",
    "                \n",
    "                self.results.append(evaluation_result)\n",
    "                \n",
    "                # End trace\n",
    "                obs_manager.end_trace()\n",
    "                \n",
    "                print(f\"   âœ… Completed - Classification: {actual_classification}, Action: {actual_action}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Error: {e}\")\n",
    "                self.results.append({\n",
    "                    \"test_case_id\": test_case.id,\n",
    "                    \"error\": str(e),\n",
    "                    \"evaluation\": {\n",
    "                        \"overall_score\": 0.0,\n",
    "                        \"reasoning\": f\"Processing error: {e}\"\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self.calculate_metrics()\n",
    "        \n",
    "        # Print report\n",
    "        self.print_evaluation_report(metrics)\n",
    "        \n",
    "        return {\n",
    "            \"results\": self.results,\n",
    "            \"metrics\": metrics\n",
    "        }\n",
    "    \n",
    "    def calculate_metrics(self) -> Dict:\n",
    "        \"\"\"Calculate evaluation metrics from results\"\"\"\n",
    "        if not self.results:\n",
    "            return {}\n",
    "        \n",
    "        total = len(self.results)\n",
    "        classification_correct = sum(\n",
    "            1 for r in self.results \n",
    "            if r.get(\"evaluation\", {}).get(\"classification_match\", False)\n",
    "        )\n",
    "        action_correct = sum(\n",
    "            1 for r in self.results \n",
    "            if r.get(\"evaluation\", {}).get(\"action_match\", False)\n",
    "        )\n",
    "        \n",
    "        classification_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"classification_score\", 0.0)\n",
    "            for r in self.results\n",
    "        ]\n",
    "        action_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"action_score\", 0.0)\n",
    "            for r in self.results\n",
    "        ]\n",
    "        overall_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"overall_score\", 0.0)\n",
    "            for r in self.results\n",
    "        ]\n",
    "        \n",
    "        # Memory quality (only for LESS_URGENT cases)\n",
    "        memory_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"memory_quality\", 0.0)\n",
    "            for r in self.results\n",
    "            if r.get(\"expected\", {}).get(\"classification\") == \"LESS_URGENT\"\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            \"total_tests\": total,\n",
    "            \"classification_accuracy\": classification_correct / total if total > 0 else 0.0,\n",
    "            \"action_accuracy\": action_correct / total if total > 0 else 0.0,\n",
    "            \"avg_classification_score\": sum(classification_scores) / len(classification_scores) if classification_scores else 0.0,\n",
    "            \"avg_action_score\": sum(action_scores) / len(action_scores) if action_scores else 0.0,\n",
    "            \"avg_overall_score\": sum(overall_scores) / len(overall_scores) if overall_scores else 0.0,\n",
    "            \"avg_memory_quality\": sum(memory_scores) / len(memory_scores) if memory_scores else 0.0,\n",
    "            \"classification_correct\": classification_correct,\n",
    "            \"action_correct\": action_correct\n",
    "        }\n",
    "    \n",
    "    def print_evaluation_report(self, metrics: Dict):\n",
    "        \"\"\"Print a formatted evaluation report\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“Š EVALUATION REPORT\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nðŸ“ˆ Overall Metrics:\")\n",
    "        print(f\"   Total Tests: {metrics.get('total_tests', 0)}\")\n",
    "        print(f\"   Overall Score: {metrics.get('avg_overall_score', 0.0):.2%}\")\n",
    "        print(f\"\\nðŸ·ï¸  Classification Metrics:\")\n",
    "        print(f\"   Accuracy: {metrics.get('classification_accuracy', 0.0):.2%} ({metrics.get('classification_correct', 0)}/{metrics.get('total_tests', 0)})\")\n",
    "        print(f\"   Average Score: {metrics.get('avg_classification_score', 0.0):.2%}\")\n",
    "        print(f\"\\nâš¡ Action Metrics:\")\n",
    "        print(f\"   Accuracy: {metrics.get('action_accuracy', 0.0):.2%} ({metrics.get('action_correct', 0)}/{metrics.get('total_tests', 0)})\")\n",
    "        print(f\"   Average Score: {metrics.get('avg_action_score', 0.0):.2%}\")\n",
    "        if metrics.get('avg_memory_quality', 0) > 0:\n",
    "            print(f\"\\nðŸ’¾ Memory Extraction Quality:\")\n",
    "            print(f\"   Average Score: {metrics.get('avg_memory_quality', 0.0):.2%}\")\n",
    "        print(f\"\\n{'='*70}\\n\")\n",
    "        \n",
    "        # Print individual results\n",
    "        print(f\"\\nðŸ“‹ Individual Test Results:\\n\")\n",
    "        for result in self.results:\n",
    "            test_id = result.get(\"test_case_id\", \"unknown\")\n",
    "            eval_data = result.get(\"evaluation\", {})\n",
    "            expected = result.get(\"expected\", {})\n",
    "            actual = result.get(\"actual\", {})\n",
    "            \n",
    "            status = \"âœ…\" if eval_data.get(\"overall_score\", 0) >= 0.7 else \"âš ï¸\" if eval_data.get(\"overall_score\", 0) >= 0.4 else \"âŒ\"\n",
    "            \n",
    "            print(f\"{status} {test_id}:\")\n",
    "            print(f\"   Expected: {expected.get('classification')} â†’ {expected.get('action')}\")\n",
    "            print(f\"   Actual: {actual.get('classification')} â†’ {actual.get('action')}\")\n",
    "            print(f\"   Score: {eval_data.get('overall_score', 0.0):.2%}\")\n",
    "            if eval_data.get(\"reasoning\"):\n",
    "                print(f\"   Reasoning: {eval_data.get('reasoning')[:100]}...\")\n",
    "            print()\n",
    "\n",
    "# Initialize evaluation framework\n",
    "evaluation_framework = EvaluationFramework()\n",
    "\n",
    "print(\"âœ… Agent Evaluation Framework initialized\")\n",
    "print(\"   â€¢ Golden test suite ready ({len(GOLDEN_TEST_SUITE)} test cases)\")\n",
    "print(\"   â€¢ LLM-as-judge evaluation ready\")\n",
    "print(\"   â€¢ Metrics calculation ready\")\n",
    "print(\"   â€¢ Run evaluation_framework.run_evaluation() to start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:30,488 - FocusFilter - INFO - ðŸ” Trace started: trace_634db925\n",
      "2025-12-02 02:43:30,492 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”¬ AGENT EVALUATION FRAMEWORK\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Running evaluation on 8 test cases...\n",
      "\n",
      "[1/8] Processing: test_001 - Banking App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:31,000 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:31,012 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:43:31,800 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:31,803 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:43:31,818 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Banking App\n",
      "Title: Security Alert\n",
      "Body: Your bank flagged suspicious activity on your account. Please verify immediately.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:32,338 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:32,634 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:43:32,636 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:43:34,012 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:43:34,019 - FocusFilter - INFO - âœ… Trace completed: trace_634db925 in 3530.19ms\n",
      "2025-12-02 02:43:34,023 - FocusFilter - INFO - ðŸ” Trace started: trace_9e3e3186\n",
      "2025-12-02 02:43:34,034 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:43:34,136 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.9124071518184285 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'model': 'gemini-2.0-flash-exp', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: URGENT, Action: display_urgent\n",
      "[2/8] Processing: test_002 - Social Media\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:43:36,141 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.588038057768285 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}.\n",
      "2025-12-02 02:43:44,034 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.79926446261425 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}.\n",
      "2025-12-02 02:44:34,698 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:34,721 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:35,540 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:35,544 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:44:35,562 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Social Media] New Like - social media noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:44:36,227 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:36,239 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:36,243 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:44:37,556 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:37,559 - FocusFilter - INFO - âœ… Trace completed: trace_9e3e3186 in 63536.55ms\n",
      "2025-12-02 02:44:37,561 - FocusFilter - INFO - ðŸ” Trace started: trace_1091ed2d\n",
      "2025-12-02 02:44:37,567 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: IRRELEVANT, Action: block\n",
      "[3/8] Processing: test_003 - Project Manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:44:38,332 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:38,344 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:39,231 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:39,236 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:44:39,254 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Updated existing memory: Project deadline moved to Tuesday. (count: 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:44:40,119 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:40,129 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:40,133 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:44:41,347 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:41,352 - FocusFilter - INFO - âœ… Trace completed: trace_1091ed2d in 3790.55ms\n",
      "2025-12-02 02:44:41,355 - FocusFilter - INFO - ðŸ” Trace started: trace_2957df70\n",
      "2025-12-02 02:44:41,367 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: LESS_URGENT, Action: save_memory\n",
      "[4/8] Processing: test_004 - Email\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:44:42,183 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:42,192 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:43,011 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:43,015 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:44:43,037 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Email\n",
      "Title: Meeting Reminder\n",
      "Body: You have a meeting in 15 minutes with the CEO.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:44:43,627 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:43,638 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:43,642 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:44:44,649 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:44:44,657 - FocusFilter - INFO - âœ… Trace completed: trace_2957df70 in 3302.09ms\n",
      "2025-12-02 02:44:44,663 - FocusFilter - INFO - ðŸ” Trace started: trace_f67fc575\n",
      "2025-12-02 02:44:44,679 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:44:44,849 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.803216980959416 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: URGENT, Action: display_urgent\n",
      "[5/8] Processing: test_005 - Shopping App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:44:46,786 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.49055262752538 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}.\n",
      "2025-12-02 02:44:54,376 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.37079929107675 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}.\n",
      "2025-12-02 02:45:44,430 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:44,446 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:45:45,248 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:45,254 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:45:45,271 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Shopping App] Flash Sale - promotional content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:45:45,830 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:45,853 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:45:45,860 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:45:46,977 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:46,982 - FocusFilter - INFO - âœ… Trace completed: trace_f67fc575 in 62318.94ms\n",
      "2025-12-02 02:45:46,985 - FocusFilter - INFO - ðŸ” Trace started: trace_1c8fc67b\n",
      "2025-12-02 02:45:46,989 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: IRRELEVANT, Action: block\n",
      "[6/8] Processing: test_006 - Calendar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:45:47,953 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:47,973 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:45:48,730 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:48,734 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:45:48,776 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Team standup meeting scheduled for tomorrow at 10 AM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:45:49,442 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:49,448 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:45:49,450 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:45:50,568 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:50,572 - FocusFilter - INFO - âœ… Trace completed: trace_1c8fc67b in 3586.89ms\n",
      "2025-12-02 02:45:50,578 - FocusFilter - INFO - ðŸ” Trace started: trace_ff2346a6\n",
      "2025-12-02 02:45:50,584 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: LESS_URGENT, Action: save_memory\n",
      "[7/8] Processing: test_007 - Health App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:45:51,244 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:51,275 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:45:51,903 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:51,909 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:45:51,942 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Health App\n",
      "Title: Medication Reminder\n",
      "Body: Time to take your daily medication.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:45:52,517 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:45:52,534 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:45:52,539 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:45:52,700 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.5123670129088196 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}.\n",
      "2025-12-02 02:45:54,287 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.980337050171713 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}.\n",
      "2025-12-02 02:46:03,371 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:46:03,378 - FocusFilter - INFO - âœ… Trace completed: trace_ff2346a6 in 12799.94ms\n",
      "2025-12-02 02:46:03,385 - FocusFilter - INFO - ðŸ” Trace started: trace_c44f0e1e\n",
      "2025-12-02 02:46:03,398 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:46:03,515 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.9179741758900475 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '56s'}]}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: URGENT, Action: display_urgent\n",
      "[8/8] Processing: test_008 - News App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:46:06,092 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:46:06,104 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:46:06,204 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.1572651760070651 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}.\n",
      "2025-12-02 02:46:07,454 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.456903897167912 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}.\n",
      "2025-12-02 02:46:15,001 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.42649598688049 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}.\n",
      "2025-12-02 02:47:05,405 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:47:05,409 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:47:05,435 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Sunny skies expected today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:47:06,024 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:47:06,032 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:47:06,035 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:47:07,678 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:47:07,685 - FocusFilter - INFO - âœ… Trace completed: trace_c44f0e1e in 64300.17ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: LESS_URGENT, Action: save_memory\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š EVALUATION REPORT\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Overall Metrics:\n",
      "   Total Tests: 8\n",
      "   Overall Score: 91.25%\n",
      "\n",
      "ðŸ·ï¸  Classification Metrics:\n",
      "   Accuracy: 87.50% (7/8)\n",
      "   Average Score: 90.00%\n",
      "\n",
      "âš¡ Action Metrics:\n",
      "   Accuracy: 87.50% (7/8)\n",
      "   Average Score: 90.00%\n",
      "\n",
      "ðŸ’¾ Memory Extraction Quality:\n",
      "   Average Score: 100.00%\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "ðŸ“‹ Individual Test Results:\n",
      "\n",
      "âœ… test_001:\n",
      "   Expected: URGENT â†’ display_urgent\n",
      "   Actual: URGENT â†’ display_urgent\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as URGENT and took the appropriate action of display...\n",
      "\n",
      "âœ… test_002:\n",
      "   Expected: IRRELEVANT â†’ block\n",
      "   Actual: IRRELEVANT â†’ block\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the social media notification as irrelevant and chose to block it, wh...\n",
      "\n",
      "âœ… test_003:\n",
      "   Expected: LESS_URGENT â†’ save_memory\n",
      "   Actual: LESS_URGENT â†’ save_memory\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as LESS_URGENT and chose the appropriate action save...\n",
      "\n",
      "âœ… test_004:\n",
      "   Expected: URGENT â†’ display_urgent\n",
      "   Actual: URGENT â†’ display_urgent\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the email as URGENT and chose the appropriate action of displaying it...\n",
      "\n",
      "âœ… test_005:\n",
      "   Expected: IRRELEVANT â†’ block\n",
      "   Actual: IRRELEVANT â†’ block\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as irrelevant and chose to block it, which is the ex...\n",
      "\n",
      "âœ… test_006:\n",
      "   Expected: LESS_URGENT â†’ save_memory\n",
      "   Actual: LESS_URGENT â†’ save_memory\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as LESS_URGENT and chose the corresponding action of...\n",
      "\n",
      "âœ… test_007:\n",
      "   Expected: URGENT â†’ display_urgent\n",
      "   Actual: URGENT â†’ display_urgent\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as URGENT and chose the appropriate action, display_...\n",
      "\n",
      "âŒ test_008:\n",
      "   Expected: IRRELEVANT â†’ block\n",
      "   Actual: LESS_URGENT â†’ save_memory\n",
      "   Score: 30.00%\n",
      "   Reasoning: The agent classified the notification as LESS_URGENT and chose to save it to memory, while the expec...\n",
      "\n",
      "\n",
      "âœ… Evaluation complete!\n",
      "\n",
      "Access results via: evaluation_results['results'] and evaluation_results['metrics']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Run Agent Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "# Run the full evaluation suite\n",
    "evaluation_results = await evaluation_framework.run_evaluation()\n",
    "\n",
    "# The evaluation framework will:\n",
    "# 1. Process each test case through the multi-agent system\n",
    "# 2. Evaluate results using LLM-as-judge\n",
    "# 3. Calculate comprehensive metrics\n",
    "# 4. Print a detailed report\n",
    "\n",
    "print(\"\\nâœ… Evaluation complete!\")\n",
    "print(\"\\nAccess results via: evaluation_results['results'] and evaluation_results['metrics']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "This implementation demonstrates:\n",
    "\n",
    "1. **Multi-Agent System**: Sequential agents (Classification â†’ Action â†’ Memory)\n",
    "   - **Classification Agent**: Analyzes and classifies notifications\n",
    "   - **Action Agent**: Executes actions based on classification\n",
    "   - **Memory Agent**: Handles memory extraction and consolidation\n",
    "2. **Custom Tools**: Three tools for notification management (display, block, save)\n",
    "3. **Memory Management**: Simple in-memory storage (can be extended to vector DB)\n",
    "4. **Orchestration Layer**: Coordinates sequential agent flow\n",
    "5. **Agentic Loop**: Get Mission â†’ Think â†’ Act â†’ Observe pattern\n",
    "\n",
    "## Multi-Agent Flow\n",
    "\n",
    "```\n",
    "Notification Input\n",
    "    â†“\n",
    "[Classification Agent] â†’ Classifies as URGENT/IRRELEVANT/LESS_URGENT\n",
    "    â†“\n",
    "[Action Agent] â†’ Executes appropriate action (display/block/save)\n",
    "    â†“\n",
    "[Memory Agent] â†’ (Optional) Refines memory extraction for LESS_URGENT items\n",
    "    â†“\n",
    "Result\n",
    "```\n",
    "\n",
    "## Next Steps for Full Implementation\n",
    "\n",
    "- âœ… Multi-agent architecture (COMPLETE)\n",
    "- Add vector database for semantic memory search\n",
    "- Add context engineering with few-shot examples\n",
    "- Implement full observability with tracing\n",
    "- Add agent evaluation framework with LLM-as-judge\n",
    "- Add user preference learning\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this for Kaggle setup with the Google API Key in the secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GOOGLE_API_KEY found in environment variables\n",
      "âœ… Setup complete - GOOGLE_API_KEY is set (length: 39)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load API key from multiple sources\n",
    "api_key_loaded = False\n",
    "\n",
    "# Method 1: Check if already set in environment\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    print(\"âœ… GOOGLE_API_KEY found in environment variables\")\n",
    "    api_key_loaded = True\n",
    "\n",
    "# Method 2: Try Kaggle secrets (if running in Kaggle)\n",
    "if not api_key_loaded:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "        print(\"âœ… Loaded GOOGLE_API_KEY from Kaggle secrets\")\n",
    "        api_key_loaded = True\n",
    "    except ImportError:\n",
    "        pass  # Not in Kaggle environment\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not load from Kaggle secrets: {e}\")\n",
    "\n",
    "# Method 3: Try .env file (for local development)\n",
    "if not api_key_loaded:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        env_path = Path('.') / '.env'\n",
    "        if env_path.exists():\n",
    "            load_dotenv(env_path)\n",
    "            if \"GOOGLE_API_KEY\" in os.environ:\n",
    "                print(\"âœ… Loaded GOOGLE_API_KEY from .env file\")\n",
    "                api_key_loaded = True\n",
    "            else:\n",
    "                print(\"âš ï¸  .env file exists but GOOGLE_API_KEY not found in it\")\n",
    "        else:\n",
    "            print(\"âš ï¸  .env file not found\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  python-dotenv not installed (optional for local development)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error loading .env: {e}\")\n",
    "\n",
    "# Final check\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    key_length = len(os.environ['GOOGLE_API_KEY'])\n",
    "    print(f\"âœ… Setup complete - GOOGLE_API_KEY is set (length: {key_length})\")\n",
    "else:\n",
    "    print(\"âŒ GOOGLE_API_KEY is required but not found.\")\n",
    "    print(\"   Please set it using one of these methods:\")\n",
    "    print(\"   1. Kaggle: Add 'GOOGLE_API_KEY' to your Kaggle secrets\")\n",
    "    print(\"   2. Local: Create a .env file with: GOOGLE_API_KEY=your_key_here\")\n",
    "    print(\"   3. Environment: Set GOOGLE_API_KEY as an environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n",
      "âœ… Async support enabled for Jupyter notebooks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.agents.remote_a2a_agent import (\n",
    "    RemoteA2aAgent,\n",
    "    AGENT_CARD_WELL_KNOWN_PATH,\n",
    ")\n",
    "\n",
    "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# Hide additional warnings in the notebook\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable nested event loops for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")\n",
    "print(\"âœ… Async support enabled for Jupyter notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus Filter - Intelligent Notification Filtering Agent\n",
    "\n",
    "This notebook implements a **multi-agent system** that intelligently filters and manages notifications by:\n",
    "- Classifying notifications as urgent, irrelevant, or less urgent\n",
    "- Taking appropriate actions (pass through, block, or store in memory)\n",
    "- Learning from patterns to improve over time\n",
    "\n",
    "## Contest Track: Concierge\n",
    "## Key Concepts Demonstrated:\n",
    "1. **Multi-agent system** (sequential agents: Classification â†’ Action â†’ Memory)\n",
    "2. **Custom tools** for notification management\n",
    "3. **Sessions & Memory** (long-term memory storage)\n",
    "4. **Observability** (logging and tracing)\n",
    "5. **Agent evaluation** (LLM-as-judge)\n",
    "\n",
    "## Multi-Agent Architecture\n",
    "\n",
    "This implementation uses a **sequential multi-agent system** with three specialized agents:\n",
    "\n",
    "1. **Classification Agent**: Analyzes notifications and determines urgency category\n",
    "2. **Action Agent**: Executes appropriate actions based on classification results\n",
    "3. **Memory Agent**: Handles memory extraction, consolidation, and storage\n",
    "\n",
    "The agents work sequentially: Classification â†’ Action â†’ Memory (when needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Notification and Memory classes initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Notification Data Structure and Memory Management\n",
    "# ============================================================================\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Notification:\n",
    "    \"\"\"Represents a notification from an app or service\"\"\"\n",
    "    id: str\n",
    "    app: str\n",
    "    title: str\n",
    "    body: str\n",
    "    timestamp: str\n",
    "    category: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"app\": self.app,\n",
    "            \"title\": self.title,\n",
    "            \"body\": self.body,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"category\": self.category\n",
    "        }\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"[{self.app}] {self.title}: {self.body}\"\n",
    "\n",
    "# Simple in-memory storage for demonstration\n",
    "class NotificationMemory:\n",
    "    \"\"\"Simple memory store for less urgent notifications\"\"\"\n",
    "    def __init__(self):\n",
    "        self.memories: List[Dict] = []\n",
    "    \n",
    "    def store(self, notification: Notification, extracted_fact: str):\n",
    "        \"\"\"Store a notification fact in memory\"\"\"\n",
    "        memory = {\n",
    "            \"notification_id\": notification.id,\n",
    "            \"app\": notification.app,\n",
    "            \"extracted_fact\": extracted_fact,\n",
    "            \"timestamp\": notification.timestamp,\n",
    "            \"stored_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.memories.append(memory)\n",
    "        print(f\"ðŸ’¾ Stored memory: {extracted_fact}\")\n",
    "        return memory\n",
    "    \n",
    "    def get_all(self) -> List[Dict]:\n",
    "        \"\"\"Retrieve all stored memories\"\"\"\n",
    "        return self.memories\n",
    "    \n",
    "    def search(self, query: str) -> List[Dict]:\n",
    "        \"\"\"Simple keyword search (would use vector DB in production)\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        return [\n",
    "            m for m in self.memories\n",
    "            if query_lower in m[\"extracted_fact\"].lower() or \n",
    "               query_lower in m[\"app\"].lower()\n",
    "        ]\n",
    "\n",
    "# Initialize memory store\n",
    "memory_store = NotificationMemory()\n",
    "print(\"âœ… Notification and Memory classes initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced memory management initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3 & 4: Enhanced Memory Management\n",
    "# ============================================================================\n",
    "# This cell enhances the NotificationMemory class with advanced features:\n",
    "# - User preferences\n",
    "# - Memory consolidation\n",
    "# - Context compaction\n",
    "# - Pattern learning\n",
    "\n",
    "# Initialize enhanced attributes on the memory store\n",
    "memory_store.user_preferences = {\n",
    "    \"always_urgent_apps\": [],\n",
    "    \"always_block_apps\": [],\n",
    "    \"preferred_categories\": [],\n",
    "    \"blocked_keywords\": []\n",
    "}\n",
    "memory_store.consolidation_threshold = 0.8\n",
    "\n",
    "# Add enhanced methods to NotificationMemory\n",
    "def _find_similar_memory(self, fact: str) -> Optional[Dict]:\n",
    "    \"\"\"Find similar memories to avoid duplicates\"\"\"\n",
    "    fact_lower = fact.lower()\n",
    "    fact_words = set(fact_lower.split())\n",
    "    \n",
    "    for memory in self.memories:\n",
    "        existing_fact = memory[\"extracted_fact\"].lower()\n",
    "        existing_words = set(existing_fact.split())\n",
    "        \n",
    "        # Calculate simple similarity (Jaccard similarity)\n",
    "        intersection = len(fact_words & existing_words)\n",
    "        union = len(fact_words | existing_words)\n",
    "        similarity = intersection / union if union > 0 else 0\n",
    "        \n",
    "        if similarity >= self.consolidation_threshold:\n",
    "            return memory\n",
    "    \n",
    "    return None\n",
    "\n",
    "def _merge_memories(self, memories: List[Dict]) -> Dict:\n",
    "    \"\"\"Merge multiple similar memories into one\"\"\"\n",
    "    base = max(memories, key=lambda m: datetime.fromisoformat(m.get(\"last_updated\", m[\"stored_at\"])))\n",
    "    total_count = sum(m.get(\"occurrence_count\", 1) for m in memories)\n",
    "    base[\"occurrence_count\"] = total_count\n",
    "    base[\"merged_from\"] = len(memories)\n",
    "    return base\n",
    "\n",
    "def consolidate_memories(self):\n",
    "    \"\"\"Consolidate and merge similar memories\"\"\"\n",
    "    consolidated = []\n",
    "    processed = set()\n",
    "    \n",
    "    for i, memory in enumerate(self.memories):\n",
    "        if i in processed:\n",
    "            continue\n",
    "        \n",
    "        similar_group = [memory]\n",
    "        for j, other_memory in enumerate(self.memories[i+1:], start=i+1):\n",
    "            if j in processed:\n",
    "                continue\n",
    "            if self._find_similar_memory(other_memory[\"extracted_fact\"]) == memory:\n",
    "                similar_group.append(other_memory)\n",
    "                processed.add(j)\n",
    "        \n",
    "        if len(similar_group) > 1:\n",
    "            merged = self._merge_memories(similar_group)\n",
    "            consolidated.append(merged)\n",
    "            print(f\"ðŸ”— Consolidated {len(similar_group)} similar memories\")\n",
    "        else:\n",
    "            consolidated.append(memory)\n",
    "        \n",
    "        processed.add(i)\n",
    "    \n",
    "    self.memories = consolidated\n",
    "    return len(consolidated)\n",
    "\n",
    "def get_user_preferences(self) -> Dict:\n",
    "    \"\"\"Get user preferences for notification filtering\"\"\"\n",
    "    return self.user_preferences.copy()\n",
    "\n",
    "def update_preference(self, preference_type: str, value: str, action: str = \"add\"):\n",
    "    \"\"\"Update user preferences (add or remove)\"\"\"\n",
    "    if preference_type not in self.user_preferences:\n",
    "        return {\"status\": \"error\", \"message\": f\"Unknown preference type: {preference_type}\"}\n",
    "    \n",
    "    if action == \"add\":\n",
    "        if value not in self.user_preferences[preference_type]:\n",
    "            self.user_preferences[preference_type].append(value)\n",
    "            print(f\"âœ… Added preference: {preference_type} = {value}\")\n",
    "    elif action == \"remove\":\n",
    "        if value in self.user_preferences[preference_type]:\n",
    "            self.user_preferences[preference_type].remove(value)\n",
    "            print(f\"âœ… Removed preference: {preference_type} = {value}\")\n",
    "    \n",
    "    return {\"status\": \"success\", \"preferences\": self.user_preferences.copy()}\n",
    "\n",
    "def learn_from_patterns(self, classification_history: List[Dict]):\n",
    "    \"\"\"Learn user preferences from classification patterns\"\"\"\n",
    "    app_classifications = {}\n",
    "    \n",
    "    for entry in classification_history:\n",
    "        app = entry.get(\"app\", \"\")\n",
    "        classification = entry.get(\"classification\", \"\")\n",
    "        \n",
    "        if app not in app_classifications:\n",
    "            app_classifications[app] = {\"URGENT\": 0, \"IRRELEVANT\": 0, \"LESS_URGENT\": 0}\n",
    "        \n",
    "        app_classifications[app][classification] = app_classifications[app].get(classification, 0) + 1\n",
    "    \n",
    "    # Auto-update preferences based on patterns\n",
    "    for app, counts in app_classifications.items():\n",
    "        total = sum(counts.values())\n",
    "        if total >= 3:\n",
    "            urgent_ratio = counts[\"URGENT\"] / total\n",
    "            irrelevant_ratio = counts[\"IRRELEVANT\"] / total\n",
    "            \n",
    "            if urgent_ratio >= 0.8 and app not in self.user_preferences[\"always_urgent_apps\"]:\n",
    "                self.update_preference(\"always_urgent_apps\", app, \"add\")\n",
    "            elif irrelevant_ratio >= 0.8 and app not in self.user_preferences[\"always_block_apps\"]:\n",
    "                self.update_preference(\"always_block_apps\", app, \"add\")\n",
    "\n",
    "def compact_context(self, max_memories: int = 10) -> List[Dict]:\n",
    "    \"\"\"Compact context by returning most relevant memories\"\"\"\n",
    "    sorted_memories = sorted(\n",
    "        self.memories,\n",
    "        key=lambda m: (\n",
    "            datetime.fromisoformat(m.get(\"last_updated\", m[\"stored_at\"])),\n",
    "            m.get(\"occurrence_count\", 1)\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "    return sorted_memories[:max_memories]\n",
    "\n",
    "# Add methods to NotificationMemory class\n",
    "NotificationMemory._find_similar_memory = _find_similar_memory\n",
    "NotificationMemory._merge_memories = _merge_memories\n",
    "NotificationMemory.consolidate_memories = consolidate_memories\n",
    "NotificationMemory.get_user_preferences = get_user_preferences\n",
    "NotificationMemory.update_preference = update_preference\n",
    "NotificationMemory.learn_from_patterns = learn_from_patterns\n",
    "NotificationMemory.compact_context = compact_context\n",
    "\n",
    "# Enhanced store method with deduplication\n",
    "original_store = NotificationMemory.store\n",
    "def enhanced_store(self, notification: Notification, extracted_fact: str):\n",
    "    \"\"\"Store with deduplication\"\"\"\n",
    "    similar_memory = self._find_similar_memory(extracted_fact)\n",
    "    \n",
    "    if similar_memory:\n",
    "        similar_memory[\"last_updated\"] = datetime.now().isoformat()\n",
    "        similar_memory[\"occurrence_count\"] = similar_memory.get(\"occurrence_count\", 1) + 1\n",
    "        print(f\"ðŸ’¾ Updated existing memory: {extracted_fact} (count: {similar_memory['occurrence_count']})\")\n",
    "        return similar_memory\n",
    "    \n",
    "    memory = original_store(self, notification, extracted_fact)\n",
    "    memory[\"last_updated\"] = datetime.now().isoformat()\n",
    "    memory[\"occurrence_count\"] = 1\n",
    "    return memory\n",
    "\n",
    "NotificationMemory.store = enhanced_store\n",
    "\n",
    "print(\"âœ… Enhanced memory management initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced tools ready:\n",
      "   â€¢ retrieve_user_preferences() - Access user preferences\n",
      "   â€¢ Tool validation framework available\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Enhanced Tools - retrieve_user_preferences and Validation\n",
    "# ============================================================================\n",
    "\n",
    "def retrieve_user_preferences() -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve user preferences for notification filtering.\n",
    "    This tool allows agents to access learned user preferences to make better decisions.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with user preferences including:\n",
    "        - always_urgent_apps: Apps that should always be treated as urgent\n",
    "        - always_block_apps: Apps that should always be blocked\n",
    "        - preferred_categories: Categories the user cares about\n",
    "        - blocked_keywords: Keywords that indicate blocking\n",
    "        \n",
    "        Success: {\"status\": \"success\", \"preferences\": {...}}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preferences = memory_store.get_user_preferences()\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"preferences\": preferences,\n",
    "            \"message\": \"User preferences retrieved successfully\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": f\"Failed to retrieve preferences: {e}\"\n",
    "        }\n",
    "\n",
    "# Enhanced tool validation wrapper\n",
    "def validate_tool_input(func):\n",
    "    \"\"\"Decorator to validate tool inputs and handle errors\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            # Basic validation\n",
    "            if not args and not kwargs:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error_message\": \"No arguments provided\"\n",
    "                }\n",
    "            \n",
    "            # Call the original function\n",
    "            result = func(*args, **kwargs)\n",
    "            \n",
    "            # Validate result format\n",
    "            if not isinstance(result, dict):\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error_message\": \"Tool did not return a dictionary\"\n",
    "                }\n",
    "            \n",
    "            if \"status\" not in result:\n",
    "                result[\"status\"] = \"success\"\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except TypeError as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Invalid arguments: {e}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Tool execution error: {e}\"\n",
    "            }\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "# Apply validation to existing tools (optional - for demonstration)\n",
    "# In production, you'd wrap the tools before passing to agents\n",
    "\n",
    "print(\"âœ… Enhanced tools ready:\")\n",
    "print(\"   â€¢ retrieve_user_preferences() - Access user preferences\")\n",
    "print(\"   â€¢ Tool validation framework available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Custom tools defined\n"
     ]
    }
   ],
   "source": [
    "# Custom Tools for Notification Management\n",
    "\n",
    "def display_urgent_notification(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Display an urgent notification to the user immediately.\n",
    "    This tool is called when a notification requires immediate attention.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Notification displayed\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸš¨ URGENT NOTIFICATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"App: {app}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Body: {body}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    return {\"status\": \"success\", \"message\": f\"Urgent notification from {app} displayed to user\"}\n",
    "\n",
    "def block_notification(app: str, title: str, reason: str) -> dict:\n",
    "    \"\"\"\n",
    "    Block/suppress an irrelevant notification.\n",
    "    This tool is called when a notification is determined to be noise.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        reason: The reason for blocking (e.g., \"social media noise\", \"promotional content\")\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Notification blocked\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    print(f\"ðŸš« Blocked: [{app}] {title} - {reason}\")\n",
    "    return {\"status\": \"success\", \"message\": f\"Notification from {app} blocked: {reason}\"}\n",
    "\n",
    "def save_notification_memory(app: str, title: str, body: str, extracted_fact: str) -> dict:\n",
    "    \"\"\"\n",
    "    Save a less urgent notification as a memory for later review.\n",
    "    This tool extracts key information and stores it for future reference.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        extracted_fact: The key fact or information extracted from the notification\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Memory stored\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    # Create a temporary notification object for storage\n",
    "    temp_notification = Notification(\n",
    "        id=str(uuid.uuid4()),\n",
    "        app=app,\n",
    "        title=title,\n",
    "        body=body,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )\n",
    "    memory_store.store(temp_notification, extracted_fact)\n",
    "    return {\"status\": \"success\", \"message\": f\"Memory stored: {extracted_fact}\"}\n",
    "\n",
    "print(\"âœ… Custom tools defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Context engineering functions defined:\n",
      "   â€¢ Few-shot examples ready\n",
      "   â€¢ Dynamic context assembly ready\n",
      "   â€¢ User preference injection ready\n",
      "   â€¢ Optimized instructions ready for agents\n",
      "\n",
      "ðŸ’¡ Note: Agents will be updated with optimized instructions after they are created.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Enhanced Context Engineering\n",
    "# ============================================================================\n",
    "# This implements optimized context management with:\n",
    "# - Few-shot examples for classification\n",
    "# - Dynamic context assembly based on notification type\n",
    "# - User preference injection into context\n",
    "# - Context compaction for long conversations\n",
    "# - System instructions optimization\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Few-shot examples for classification agent\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\n",
    "        \"notification\": \"App: Banking App, Title: Security Alert, Body: Your account was accessed from a new device. Please verify.\",\n",
    "        \"classification\": \"URGENT\",\n",
    "        \"reasoning\": \"Security alerts from banking apps require immediate attention to prevent fraud or unauthorized access.\"\n",
    "    },\n",
    "    {\n",
    "        \"notification\": \"App: Social Media, Title: New Follower, Body: @username started following you.\",\n",
    "        \"classification\": \"IRRELEVANT\",\n",
    "        \"reasoning\": \"Social media follower notifications are low-value noise that don't require attention.\"\n",
    "    },\n",
    "    {\n",
    "        \"notification\": \"App: Project Manager, Title: Task Update, Body: Your task deadline has been extended to next Friday.\",\n",
    "        \"classification\": \"LESS_URGENT\",\n",
    "        \"reasoning\": \"Project updates are important to remember but don't require immediate action.\",\n",
    "        \"extracted_fact\": \"Task deadline extended to next Friday\"\n",
    "    },\n",
    "    {\n",
    "        \"notification\": \"App: Email, Title: Meeting in 10 minutes, Body: Your meeting with the team starts in 10 minutes.\",\n",
    "        \"classification\": \"URGENT\",\n",
    "        \"reasoning\": \"Time-sensitive meeting reminders require immediate attention.\"\n",
    "    },\n",
    "    {\n",
    "        \"notification\": \"App: Shopping App, Title: Special Offer, Body: 30% off all items today only!\",\n",
    "        \"classification\": \"IRRELEVANT\",\n",
    "        \"reasoning\": \"Promotional content is typically marketing noise.\"\n",
    "    },\n",
    "    {\n",
    "        \"notification\": \"App: Calendar, Title: Event Tomorrow, Body: Team standup meeting at 9 AM tomorrow.\",\n",
    "        \"classification\": \"LESS_URGENT\",\n",
    "        \"reasoning\": \"Future events are important to remember but not immediately urgent.\",\n",
    "        \"extracted_fact\": \"Team standup meeting tomorrow at 9 AM\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def build_few_shot_context(examples: List[Dict] = None) -> str:\n",
    "    \"\"\"Build few-shot examples context for classification agent\"\"\"\n",
    "    if examples is None:\n",
    "        examples = FEW_SHOT_EXAMPLES\n",
    "    \n",
    "    context = \"Here are some examples of how to classify notifications:\\n\\n\"\n",
    "    \n",
    "    for i, example in enumerate(examples, 1):\n",
    "        context += f\"Example {i}:\\n\"\n",
    "        context += f\"Notification: {example['notification']}\\n\"\n",
    "        context += f\"Classification: {example['classification']}\\n\"\n",
    "        context += f\"Reasoning: {example['reasoning']}\\n\"\n",
    "        if 'extracted_fact' in example:\n",
    "            context += f\"Key Fact: {example['extracted_fact']}\\n\"\n",
    "        context += \"\\n\"\n",
    "    \n",
    "    context += \"Use these examples as guidance when classifying new notifications.\\n\"\n",
    "    return context\n",
    "\n",
    "def build_user_preference_context() -> str:\n",
    "    \"\"\"Build context string from user preferences\"\"\"\n",
    "    try:\n",
    "        prefs = memory_store.get_user_preferences()\n",
    "        context = \"\\nUser Preferences:\\n\"\n",
    "        \n",
    "        if prefs.get('always_urgent_apps'):\n",
    "            context += f\"- Apps always treated as urgent: {', '.join(prefs['always_urgent_apps'])}\\n\"\n",
    "        if prefs.get('always_block_apps'):\n",
    "            context += f\"- Apps always blocked: {', '.join(prefs['always_block_apps'])}\\n\"\n",
    "        if prefs.get('preferred_categories'):\n",
    "            context += f\"- Preferred categories: {', '.join(prefs['preferred_categories'])}\\n\"\n",
    "        if prefs.get('blocked_keywords'):\n",
    "            context += f\"- Blocked keywords: {', '.join(prefs['blocked_keywords'])}\\n\"\n",
    "        \n",
    "        if context == \"\\nUser Preferences:\\n\":\n",
    "            context += \"- No specific preferences set yet\\n\"\n",
    "        \n",
    "        return context\n",
    "    except:\n",
    "        return \"\\nUser Preferences: Not available\\n\"\n",
    "\n",
    "def build_dynamic_context(notification_text: str, app: str = None, title: str = None) -> str:\n",
    "    \"\"\"Build dynamic context based on notification characteristics\"\"\"\n",
    "    context_parts = []\n",
    "    \n",
    "    # Add user preferences\n",
    "    context_parts.append(build_user_preference_context())\n",
    "    \n",
    "    # Add relevant memories if available\n",
    "    try:\n",
    "        if app:\n",
    "            relevant_memories = memory_store.search(app)\n",
    "            if relevant_memories:\n",
    "                context_parts.append(f\"\\nRelevant Past Notifications from {app}:\\n\")\n",
    "                for memory in relevant_memories[:3]:  # Limit to 3 most relevant\n",
    "                    context_parts.append(f\"- {memory.get('extracted_fact', 'N/A')}\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Add context compaction hint if memory is getting large\n",
    "    try:\n",
    "        if len(memory_store.memories) > 20:\n",
    "            context_parts.append(\"\\nNote: Memory store is large. Consider compacting context.\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return \"\".join(context_parts)\n",
    "\n",
    "def get_optimized_classification_instruction() -> str:\n",
    "    \"\"\"Get optimized classification instruction with few-shot examples\"\"\"\n",
    "    base_instruction = \"\"\"You are a Classification Agent in the Focus Filter system.\n",
    "\n",
    "Your ONLY job is to analyze notifications and classify them into one of three categories:\n",
    "\n",
    "1. **URGENT**: Requires immediate attention or action\n",
    "   - Security alerts (bank, account access)\n",
    "   - Critical deadlines or time-sensitive tasks\n",
    "   - Emergency communications\n",
    "   - Important personal messages requiring immediate response\n",
    "   - Health-related reminders (medication, appointments)\n",
    "\n",
    "2. **IRRELEVANT**: Noise that should be blocked\n",
    "   - Social media likes, follows, generic updates\n",
    "   - Marketing/promotional content\n",
    "   - Low-value informational updates\n",
    "   - Spam or unwanted notifications\n",
    "   - Generic news updates\n",
    "\n",
    "3. **LESS_URGENT**: Important but not immediate - should be stored in memory\n",
    "   - Project updates, deadline changes\n",
    "   - Informational updates worth remembering\n",
    "   - Non-critical but useful information\n",
    "   - Things the user might want to reference later\n",
    "   - Future events and reminders\n",
    "\n",
    "When you receive a notification, analyze the app, title, and body text, then respond with:\n",
    "- The classification (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- A brief reasoning for your decision\n",
    "- If LESS_URGENT, also provide the key fact or information that should be extracted\n",
    "\n",
    "Format your response as:\n",
    "Classification: [URGENT/IRRELEVANT/LESS_URGENT]\n",
    "Reasoning: [your reasoning]\n",
    "Key Fact (if LESS_URGENT): [extracted fact]\n",
    "\n",
    "Be conservative with URGENT - only use it for truly time-sensitive or critical items.\"\"\"\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    few_shot_context = build_few_shot_context()\n",
    "    \n",
    "    # Combine\n",
    "    optimized_instruction = base_instruction + \"\\n\\n\" + few_shot_context\n",
    "    \n",
    "    return optimized_instruction\n",
    "\n",
    "def get_enhanced_classification_prompt(notification_text: str, app: str = None, title: str = None) -> str:\n",
    "    \"\"\"Build enhanced classification prompt with dynamic context\"\"\"\n",
    "    base_prompt = notification_text\n",
    "    \n",
    "    # Add dynamic context\n",
    "    dynamic_context = build_dynamic_context(notification_text, app, title)\n",
    "    \n",
    "    if dynamic_context.strip():\n",
    "        enhanced_prompt = base_prompt + \"\\n\\n\" + dynamic_context\n",
    "    else:\n",
    "        enhanced_prompt = base_prompt\n",
    "    \n",
    "    return enhanced_prompt\n",
    "\n",
    "def get_optimized_action_instruction() -> str:\n",
    "    \"\"\"Get optimized action agent instruction\"\"\"\n",
    "    return \"\"\"You are an Action Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to execute actions based on classification results from the Classification Agent.\n",
    "\n",
    "You will receive:\n",
    "- The notification details (app, title, body)\n",
    "- The classification result (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- Any additional context (like extracted facts for LESS_URGENT items)\n",
    "- User preferences (if available)\n",
    "\n",
    "Based on the classification, you must:\n",
    "1. For URGENT: Call `display_urgent_notification(app, title, body)` immediately\n",
    "2. For IRRELEVANT: Call `block_notification(app, title, reason)` with a clear reason\n",
    "3. For LESS_URGENT: Call `save_notification_memory(app, title, body, extracted_fact)` with the key fact\n",
    "\n",
    "Important guidelines:\n",
    "- Always respect user preferences (if an app is in always_urgent_apps, treat as urgent even if borderline)\n",
    "- If an app is in always_block_apps, block it regardless of content\n",
    "- Execute the appropriate action immediately based on the classification provided\n",
    "- For LESS_URGENT items, ensure the extracted fact is concise and useful\"\"\"\n",
    "\n",
    "def get_optimized_memory_instruction() -> str:\n",
    "    \"\"\"Get optimized memory agent instruction\"\"\"\n",
    "    return \"\"\"You are a Memory Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to extract, consolidate, and manage memories from notifications.\n",
    "\n",
    "When you receive a LESS_URGENT notification:\n",
    "1. Extract the most important fact or piece of information\n",
    "2. Format it as a concise, searchable memory\n",
    "3. Ensure it's useful for future reference\n",
    "4. Avoid redundancy with existing memories\n",
    "\n",
    "For example:\n",
    "- \"Project deadline moved to Tuesday\" (not \"Your project deadline has moved to Tuesday\")\n",
    "- \"New team member joined: Alice\" (not the full notification text)\n",
    "- \"Meeting scheduled for tomorrow at 10 AM\" (not \"You have a meeting scheduled...\")\n",
    "\n",
    "Focus on extracting actionable, referenceable facts that the user might want to recall later.\n",
    "Keep facts concise (ideally under 15 words) and remove personal pronouns.\"\"\"\n",
    "\n",
    "\n",
    "print(\"âœ… Context engineering functions defined:\")\n",
    "print(\"   â€¢ Few-shot examples ready\")\n",
    "print(\"   â€¢ Dynamic context assembly ready\")\n",
    "print(\"   â€¢ User preference injection ready\")\n",
    "print(\"   â€¢ Optimized instructions ready for agents\")\n",
    "print(\"\\nðŸ’¡ Note: Agents will be updated with optimized instructions after they are created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ§ª Testing Enhanced Context Engineering\n",
      "======================================================================\n",
      "\n",
      "1. Few-Shot Examples Available:\n",
      "   â€¢ 6 examples loaded\n",
      "   1. URGENT: App: Banking App, Title: Security Alert, Body: You...\n",
      "   2. IRRELEVANT: App: Social Media, Title: New Follower, Body: @use...\n",
      "   3. LESS_URGENT: App: Project Manager, Title: Task Update, Body: Yo...\n",
      "\n",
      "2. Enhanced Context Building:\n",
      "   Original length: 118 chars\n",
      "   Enhanced length: 173 chars\n",
      "   Context added: 55 chars\n",
      "\n",
      "3. User Preference Context:\n",
      "\n",
      "User Preferences:\n",
      "- No specific preferences set yet\n",
      "\n",
      "\n",
      "4. Optimized Instructions:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6983/2788100991.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Test 4: Show optimized instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n4. Optimized Instructions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   â€¢ Classification Agent: {len(classification_agent.instruction)} chars (includes few-shot examples)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   â€¢ Action Agent: {len(action_agent.instruction)} chars (includes preference handling)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   â€¢ Memory Agent: {len(memory_agent.instruction)} chars (optimized for extraction)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_agent' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Demonstration: Enhanced Context Engineering\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ§ª Testing Enhanced Context Engineering\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Show few-shot examples\n",
    "print(\"\\n1. Few-Shot Examples Available:\")\n",
    "print(f\"   â€¢ {len(FEW_SHOT_EXAMPLES)} examples loaded\")\n",
    "for i, example in enumerate(FEW_SHOT_EXAMPLES[:3], 1):\n",
    "    print(f\"   {i}. {example['classification']}: {example['notification'][:50]}...\")\n",
    "\n",
    "# Test 2: Build enhanced prompt\n",
    "print(\"\\n2. Enhanced Context Building:\")\n",
    "test_notification = \"I received a notification: App: Banking App, Title: Security Alert, Body: Your account was accessed from a new device.\"\n",
    "enhanced_prompt = get_enhanced_classification_prompt(test_notification, app=\"Banking App\", title=\"Security Alert\")\n",
    "print(f\"   Original length: {len(test_notification)} chars\")\n",
    "print(f\"   Enhanced length: {len(enhanced_prompt)} chars\")\n",
    "print(f\"   Context added: {len(enhanced_prompt) - len(test_notification)} chars\")\n",
    "\n",
    "# Test 3: User preference context\n",
    "print(\"\\n3. User Preference Context:\")\n",
    "pref_context = build_user_preference_context()\n",
    "print(pref_context[:200] + \"...\" if len(pref_context) > 200 else pref_context)\n",
    "\n",
    "# Test 4: Show optimized instructions (if agents are available)\n",
    "print(\"\\n4. Optimized Instructions:\")\n",
    "if 'classification_agent' in globals() and 'action_agent' in globals() and 'memory_agent' in globals():\n",
    "    print(f\"   â€¢ Classification Agent: {len(classification_agent.instruction)} chars (includes few-shot examples)\")\n",
    "    print(f\"   â€¢ Action Agent: {len(action_agent.instruction)} chars (includes preference handling)\")\n",
    "    print(f\"   â€¢ Memory Agent: {len(memory_agent.instruction)} chars (optimized for extraction)\")\n",
    "else:\n",
    "    print(\"   â€¢ Agents not yet created (will be available after Multi-Agent Architecture cell runs)\")\n",
    "    print(\"   â€¢ Optimized instruction functions are ready:\")\n",
    "    print(f\"     - get_optimized_classification_instruction() â†’ {len(get_optimized_classification_instruction())} chars\")\n",
    "    print(f\"     - get_optimized_action_instruction() â†’ {len(get_optimized_action_instruction())} chars\")\n",
    "    print(f\"     - get_optimized_memory_instruction() â†’ {len(get_optimized_memory_instruction())} chars\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Context engineering demonstration complete\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: The agents have been updated with optimized instructions.\")\n",
    "print(\"   All future notifications will benefit from:\")\n",
    "print(\"   â€¢ Few-shot learning examples\")\n",
    "print(\"   â€¢ Dynamic context assembly\")\n",
    "print(\"   â€¢ User preference injection\")\n",
    "print(\"   â€¢ Optimized system prompts\")\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to use enhanced prompts\n",
    "def process_with_enhanced_context(notification_text: str, app: str = None, title: str = None) -> str:\n",
    "    \"\"\"Process notification with enhanced context engineering\"\"\"\n",
    "    return get_enhanced_classification_prompt(notification_text, app, title)\n",
    "\n",
    "print(\"\\nâœ… Enhanced context processing function available: process_with_enhanced_context()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent system created:\n",
      "  â€¢ Classification Agent - Analyzes and classifies notifications\n",
      "  â€¢ Action Agent - Executes actions based on classification\n",
      "  â€¢ Memory Agent - Handles memory extraction and consolidation\n",
      "âœ… Agents updated with enhanced tools\n",
      "   â€¢ Classification Agent can now check user preferences\n",
      "   â€¢ Action Agent can now check user preferences\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT ARCHITECTURE: Sequential Agent System\n",
    "# Note: Agent instructions will be optimized by Context Engineering cell above\n",
    "# The agents are created here, then enhanced with few-shot examples and optimized prompts\n",
    "# ============================================================================\n",
    "# This demonstrates a multi-agent system with three specialized agents:\n",
    "# 1. Classification Agent: Analyzes and classifies notifications\n",
    "# 2. Action Agent: Executes actions based on classification\n",
    "# 3. Memory Agent: Handles memory extraction and storage\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 1: Classification Agent\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent's sole responsibility is to analyze notifications and determine\n",
    "# their urgency category. It does NOT take actions, only classifies.\n",
    "\n",
    "def classify_notification(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Classify a notification into one of three categories: URGENT, IRRELEVANT, or LESS_URGENT.\n",
    "    This tool is used by the Classification Agent to output its decision.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with classification result.\n",
    "    \"\"\"\n",
    "    # This is a tool that the classification agent will call to output its decision\n",
    "    # The actual classification logic is in the agent's reasoning\n",
    "    pass  # Placeholder - agent will call this with classification result\n",
    "\n",
    "classification_agent = LlmAgent(\n",
    "    name=\"classification_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a Classification Agent in the Focus Filter system.\n",
    "\n",
    "Your ONLY job is to analyze notifications and classify them into one of three categories:\n",
    "\n",
    "1. **URGENT**: Requires immediate attention or action\n",
    "   - Security alerts (bank, account access)\n",
    "   - Critical deadlines or time-sensitive tasks\n",
    "   - Emergency communications\n",
    "   - Important personal messages requiring immediate response\n",
    "\n",
    "2. **IRRELEVANT**: Noise that should be blocked\n",
    "   - Social media likes, follows, generic updates\n",
    "   - Marketing/promotional content\n",
    "   - Low-value informational updates\n",
    "   - Spam or unwanted notifications\n",
    "\n",
    "3. **LESS_URGENT**: Important but not immediate - should be stored in memory\n",
    "   - Project updates, deadline changes\n",
    "   - Informational updates worth remembering\n",
    "   - Non-critical but useful information\n",
    "   - Things the user might want to reference later\n",
    "\n",
    "When you receive a notification, analyze the app, title, and body text, then respond with:\n",
    "- The classification (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- A brief reasoning for your decision\n",
    "- If LESS_URGENT, also provide the key fact or information that should be extracted\n",
    "\n",
    "Format your response as:\n",
    "Classification: [URGENT/IRRELEVANT/LESS_URGENT]\n",
    "Reasoning: [your reasoning]\n",
    "Key Fact (if LESS_URGENT): [extracted fact]\n",
    "\n",
    "Be conservative with URGENT - only use it for truly time-sensitive or critical items.\"\"\",\n",
    "    tools=[],  # Classification agent doesn't take actions, only classifies\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 2: Action Agent\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent receives classification results and executes the appropriate action\n",
    "\n",
    "action_agent = LlmAgent(\n",
    "    name=\"action_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an Action Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to execute actions based on classification results from the Classification Agent.\n",
    "\n",
    "You will receive:\n",
    "- The notification details (app, title, body)\n",
    "- The classification result (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- Any additional context (like extracted facts for LESS_URGENT items)\n",
    "\n",
    "Based on the classification, you must:\n",
    "1. For URGENT: Call `display_urgent_notification(app, title, body)`\n",
    "2. For IRRELEVANT: Call `block_notification(app, title, reason)` with a clear reason\n",
    "3. For LESS_URGENT: Call `save_notification_memory(app, title, body, extracted_fact)` with the key fact\n",
    "\n",
    "Execute the appropriate action immediately based on the classification provided.\"\"\",\n",
    "    tools=[\n",
    "        display_urgent_notification,\n",
    "        block_notification,\n",
    "        save_notification_memory,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 3: Memory Agent (for advanced memory operations)\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent handles memory extraction, consolidation, and retrieval\n",
    "\n",
    "def extract_memory_fact(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the key fact or information from a notification for memory storage.\n",
    "    This tool is used by the Memory Agent to extract structured information.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted fact.\n",
    "    \"\"\"\n",
    "    # This tool allows the memory agent to output extracted facts\n",
    "    pass  # Placeholder - agent will call this with extracted fact\n",
    "\n",
    "memory_agent = LlmAgent(\n",
    "    name=\"memory_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a Memory Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to extract, consolidate, and manage memories from notifications.\n",
    "\n",
    "When you receive a LESS_URGENT notification:\n",
    "1. Extract the most important fact or piece of information\n",
    "2. Format it as a concise, searchable memory\n",
    "3. Ensure it's useful for future reference\n",
    "\n",
    "For example:\n",
    "- \"Project deadline moved to Tuesday\" (not \"Your project deadline has moved to Tuesday\")\n",
    "- \"New team member joined: Alice\" (not the full notification text)\n",
    "\n",
    "Focus on extracting actionable, referenceable facts that the user might want to recall later.\"\"\",\n",
    "    tools=[],  # Memory agent primarily extracts facts (can be extended with retrieval tools)\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-agent system created:\")\n",
    "print(\"  â€¢ Classification Agent - Analyzes and classifies notifications\")\n",
    "print(\"  â€¢ Action Agent - Executes actions based on classification\")\n",
    "print(\"  â€¢ Memory Agent - Handles memory extraction and consolidation\")\n",
    "\n",
    "# Update agents to include retrieve_user_preferences tool\n",
    "# Add the tool to classification and action agents\n",
    "if retrieve_user_preferences not in classification_agent.tools:\n",
    "    classification_agent.tools.append(retrieve_user_preferences)\n",
    "\n",
    "if retrieve_user_preferences not in action_agent.tools:\n",
    "    action_agent.tools.append(retrieve_user_preferences)\n",
    "\n",
    "print(\"âœ… Agents updated with enhanced tools\")\n",
    "print(\"   â€¢ Classification Agent can now check user preferences\")\n",
    "print(\"   â€¢ Action Agent can now check user preferences\")\n",
    "\n",
    "# Update agents with optimized instructions from Context Engineering\n",
    "print(\"\\nðŸ”„ Updating agents with enhanced context engineering...\")\n",
    "\n",
    "# Update classification agent\n",
    "classification_agent.instruction = get_optimized_classification_instruction()\n",
    "\n",
    "# Update action agent\n",
    "action_agent.instruction = get_optimized_action_instruction()\n",
    "\n",
    "# Update memory agent\n",
    "memory_agent.instruction = get_optimized_memory_instruction()\n",
    "\n",
    "print(\"âœ… Context engineering enhancements applied:\")\n",
    "print(\"   â€¢ Few-shot examples added to classification agent\")\n",
    "print(\"   â€¢ Dynamic context assembly enabled\")\n",
    "print(\"   â€¢ User preference injection ready\")\n",
    "print(\"   â€¢ System instructions optimized\")\n",
    "print(\"   â€¢ Context compaction integrated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Observability system initialized\n",
      "   â€¢ Structured logging enabled\n",
      "   â€¢ Trace capture ready\n",
      "   â€¢ Metrics collection active\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OBSERVABILITY: Logging, Tracing, and Metrics\n",
    "# ============================================================================\n",
    "# This module provides comprehensive observability for the multi-agent system\n",
    "\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "\n",
    "# Configure structured logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"FocusFilter\")\n",
    "\n",
    "class ObservabilityManager:\n",
    "    \"\"\"Manages logging, tracing, and metrics for the multi-agent system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.traces: List[Dict] = []\n",
    "        self.metrics = {\n",
    "            \"total_notifications\": 0,\n",
    "            \"classifications\": defaultdict(int),\n",
    "            \"actions\": defaultdict(int),\n",
    "            \"agent_timings\": defaultdict(list),\n",
    "            \"errors\": []\n",
    "        }\n",
    "        self.current_trace: Optional[Dict] = None\n",
    "    \n",
    "    def start_trace(self, notification_id: str, notification_text: str):\n",
    "        \"\"\"Start a new trace for a notification processing session\"\"\"\n",
    "        self.current_trace = {\n",
    "            \"trace_id\": f\"trace_{uuid.uuid4().hex[:8]}\",\n",
    "            \"notification_id\": notification_id,\n",
    "            \"notification_text\": notification_text,\n",
    "            \"start_time\": datetime.now().isoformat(),\n",
    "            \"agents\": [],\n",
    "            \"classification\": None,\n",
    "            \"action\": None,\n",
    "            \"memory_operation\": None,\n",
    "            \"end_time\": None,\n",
    "            \"duration_ms\": None,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        logger.info(f\"ðŸ” Trace started: {self.current_trace['trace_id']}\")\n",
    "    \n",
    "    def log_agent_step(self, agent_name: str, step: str, input_data: Dict, output_data: Dict, duration_ms: float):\n",
    "        \"\"\"Log an agent step in the current trace\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        agent_step = {\n",
    "            \"agent\": agent_name,\n",
    "            \"step\": step,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"input\": input_data,\n",
    "            \"output\": output_data,\n",
    "            \"duration_ms\": duration_ms\n",
    "        }\n",
    "        self.current_trace[\"agents\"].append(agent_step)\n",
    "        self.metrics[\"agent_timings\"][f\"{agent_name}_{step}\"].append(duration_ms)\n",
    "        \n",
    "        logger.info(f\"ðŸ“Š {agent_name} - {step} completed in {duration_ms:.2f}ms\")\n",
    "    \n",
    "    def log_classification(self, classification: str, reasoning: str, confidence: Optional[float] = None):\n",
    "        \"\"\"Log classification result\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"classification\"] = {\n",
    "            \"result\": classification,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"confidence\": confidence,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"classifications\"][classification] += 1\n",
    "        \n",
    "        logger.info(f\"ðŸ·ï¸  Classification: {classification} - {reasoning[:100]}\")\n",
    "    \n",
    "    def log_action(self, action_type: str, action_details: Dict):\n",
    "        \"\"\"Log action execution\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"action\"] = {\n",
    "            \"type\": action_type,\n",
    "            \"details\": action_details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"actions\"][action_type] += 1\n",
    "        \n",
    "        logger.info(f\"âš¡ Action: {action_type} - {json.dumps(action_details, default=str)}\")\n",
    "    \n",
    "    def log_memory_operation(self, operation: str, details: Dict):\n",
    "        \"\"\"Log memory operation\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"memory_operation\"] = {\n",
    "            \"operation\": operation,\n",
    "            \"details\": details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"ðŸ’¾ Memory: {operation} - {json.dumps(details, default=str)}\")\n",
    "    \n",
    "    def log_error(self, error_type: str, error_message: str, context: Optional[Dict] = None):\n",
    "        \"\"\"Log an error\"\"\"\n",
    "        error_entry = {\n",
    "            \"type\": error_type,\n",
    "            \"message\": error_message,\n",
    "            \"context\": context or {},\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"errors\"].append(error_entry)\n",
    "        \n",
    "        if self.current_trace:\n",
    "            self.current_trace[\"errors\"].append(error_entry)\n",
    "        \n",
    "        logger.error(f\"âŒ Error [{error_type}]: {error_message}\")\n",
    "    \n",
    "    def end_trace(self):\n",
    "        \"\"\"End the current trace and store it\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        start_time = datetime.fromisoformat(self.current_trace[\"start_time\"])\n",
    "        duration_ms = (end_time - start_time).total_seconds() * 1000\n",
    "        \n",
    "        self.current_trace[\"end_time\"] = end_time.isoformat()\n",
    "        self.current_trace[\"duration_ms\"] = duration_ms\n",
    "        \n",
    "        self.traces.append(self.current_trace.copy())\n",
    "        self.metrics[\"total_notifications\"] += 1\n",
    "        \n",
    "        logger.info(f\"âœ… Trace completed: {self.current_trace['trace_id']} in {duration_ms:.2f}ms\")\n",
    "        self.current_trace = None\n",
    "    \n",
    "    def get_metrics_summary(self) -> Dict:\n",
    "        \"\"\"Get a summary of all metrics\"\"\"\n",
    "        avg_timings = {}\n",
    "        for key, timings in self.metrics[\"agent_timings\"].items():\n",
    "            if timings:\n",
    "                avg_timings[key] = {\n",
    "                    \"avg_ms\": sum(timings) / len(timings),\n",
    "                    \"min_ms\": min(timings),\n",
    "                    \"max_ms\": max(timings),\n",
    "                    \"count\": len(timings)\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            \"total_notifications\": self.metrics[\"total_notifications\"],\n",
    "            \"classifications\": dict(self.metrics[\"classifications\"]),\n",
    "            \"actions\": dict(self.metrics[\"actions\"]),\n",
    "            \"average_timings\": avg_timings,\n",
    "            \"error_count\": len(self.metrics[\"errors\"]),\n",
    "            \"total_traces\": len(self.traces)\n",
    "        }\n",
    "    \n",
    "    def get_recent_traces(self, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Get the most recent traces\"\"\"\n",
    "        return self.traces[-limit:] if self.traces else []\n",
    "    \n",
    "    def print_metrics_summary(self):\n",
    "        \"\"\"Print a formatted metrics summary\"\"\"\n",
    "        summary = self.get_metrics_summary()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“Š OBSERVABILITY METRICS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nðŸ“ˆ Total Notifications Processed: {summary['total_notifications']}\")\n",
    "        print(f\"ðŸ“ Total Traces Captured: {summary['total_traces']}\")\n",
    "        \n",
    "        print(\"\\nðŸ·ï¸  Classification Distribution:\")\n",
    "        for classification, count in summary['classifications'].items():\n",
    "            percentage = (count / summary['total_notifications'] * 100) if summary['total_notifications'] > 0 else 0\n",
    "            print(f\"   {classification}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nâš¡ Action Distribution:\")\n",
    "        for action, count in summary['actions'].items():\n",
    "            percentage = (count / summary['total_notifications'] * 100) if summary['total_notifications'] > 0 else 0\n",
    "            print(f\"   {action}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if summary['average_timings']:\n",
    "            print(\"\\nâ±ï¸  Performance Metrics:\")\n",
    "            for key, timing in summary['average_timings'].items():\n",
    "                print(f\"   {key}:\")\n",
    "                print(f\"      Average: {timing['avg_ms']:.2f}ms\")\n",
    "                print(f\"      Min: {timing['min_ms']:.2f}ms\")\n",
    "                print(f\"      Max: {timing['max_ms']:.2f}ms\")\n",
    "                print(f\"      Count: {timing['count']}\")\n",
    "        \n",
    "        if summary['error_count'] > 0:\n",
    "            print(f\"\\nâŒ Errors: {summary['error_count']}\")\n",
    "            for error in self.metrics['errors'][-5:]:  # Show last 5 errors\n",
    "                print(f\"   [{error['type']}] {error['message']}\")\n",
    "        \n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Initialize observability manager\n",
    "obs_manager = ObservabilityManager()\n",
    "\n",
    "print(\"âœ… Observability system initialized\")\n",
    "print(\"   â€¢ Structured logging enabled\")\n",
    "print(\"   â€¢ Trace capture ready\")\n",
    "print(\"   â€¢ Metrics collection active\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent orchestration layer initialized\n",
      "âœ… Sequential agent coordination ready\n",
      "âœ… Helper functions for async operations ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ORCHESTRATION LAYER: Sequential Agent Coordination\n",
    "# ============================================================================\n",
    "# This layer coordinates the sequential flow: Classification â†’ Action â†’ Memory\n",
    "\n",
    "# Create runners for each agent\n",
    "classification_runner = Runner(\n",
    "    app_name=\"FocusFilter_Classification\",\n",
    "    agent=classification_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "action_runner = Runner(\n",
    "    app_name=\"FocusFilter_Action\",\n",
    "    agent=action_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "memory_runner = Runner(\n",
    "    app_name=\"FocusFilter_Memory\",\n",
    "    agent=memory_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "# Main session service for the orchestration\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "def parse_classification_result(text: str) -> dict:\n",
    "    \"\"\"Parse the classification agent's response to extract structured data\"\"\"\n",
    "    result = {\n",
    "        \"classification\": None,\n",
    "        \"reasoning\": None,\n",
    "        \"key_fact\": None\n",
    "    }\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Try to find classification - look for URGENT, IRRELEVANT, or LESS_URGENT\n",
    "    for classification in [\"URGENT\", \"IRRELEVANT\", \"LESS_URGENT\", \"LESS URGENT\"]:\n",
    "        if classification.lower() in text_lower:\n",
    "            # Check if it's in a structured format like \"Classification: URGENT\"\n",
    "            if \"classification:\" in text_lower:\n",
    "                idx = text_lower.find(\"classification:\")\n",
    "                after_colon = text[text_lower.find(\"classification:\") + len(\"classification:\"):].strip()\n",
    "                # Extract the first word or phrase after the colon\n",
    "                words = after_colon.split()\n",
    "                if words:\n",
    "                    result[\"classification\"] = words[0].upper().rstrip(\".,;\")\n",
    "                    break\n",
    "            else:\n",
    "                # Look for the classification word in context\n",
    "                result[\"classification\"] = classification.upper()\n",
    "                break\n",
    "    \n",
    "    # Extract reasoning\n",
    "    if \"reasoning:\" in text_lower:\n",
    "        idx = text_lower.find(\"reasoning:\")\n",
    "        reasoning_text = text[idx + len(\"reasoning:\"):].strip()\n",
    "        # Take up to the next section or end of text\n",
    "        next_section = min(\n",
    "            reasoning_text.find(\"\\n\\n\"),\n",
    "            reasoning_text.find(\"Key Fact\"),\n",
    "            reasoning_text.find(\"key fact\"),\n",
    "            len(reasoning_text)\n",
    "        )\n",
    "        if next_section > 0:\n",
    "            result[\"reasoning\"] = reasoning_text[:next_section].strip()\n",
    "        else:\n",
    "            result[\"reasoning\"] = reasoning_text.strip()\n",
    "    \n",
    "    # Extract key fact (for LESS_URGENT items)\n",
    "    if \"key fact\" in text_lower:\n",
    "        idx = text_lower.find(\"key fact\")\n",
    "        fact_text = text[idx + len(\"key fact\"):].strip()\n",
    "        # Remove colon if present\n",
    "        if fact_text.startswith(\":\"):\n",
    "            fact_text = fact_text[1:].strip()\n",
    "        # Take up to next line break or end\n",
    "        next_line = fact_text.find(\"\\n\")\n",
    "        if next_line > 0:\n",
    "            result[\"key_fact\"] = fact_text[:next_line].strip()\n",
    "        else:\n",
    "            result[\"key_fact\"] = fact_text.strip()\n",
    "    \n",
    "    # Fallback: if classification not found, try to infer from text\n",
    "    if result[\"classification\"] is None:\n",
    "        if any(word in text_lower for word in [\"urgent\", \"immediate\", \"critical\", \"security alert\"]):\n",
    "            result[\"classification\"] = \"URGENT\"\n",
    "        elif any(word in text_lower for word in [\"irrelevant\", \"noise\", \"block\", \"spam\"]):\n",
    "            result[\"classification\"] = \"IRRELEVANT\"\n",
    "        elif any(word in text_lower for word in [\"less urgent\", \"store\", \"memory\", \"later\"]):\n",
    "            result[\"classification\"] = \"LESS_URGENT\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "async def process_notification_multi_agent(\n",
    "    notification_text: str,\n",
    "    user_id: str = \"default\",\n",
    "    session_id: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Orchestrate the sequential multi-agent processing of a notification.\n",
    "    \n",
    "    Flow:\n",
    "    1. Classification Agent analyzes and classifies\n",
    "    2. Action Agent executes appropriate action\n",
    "    3. Memory Agent (if needed) handles memory extraction\n",
    "    \n",
    "    Args:\n",
    "        notification_text: The notification message to process\n",
    "        user_id: User identifier\n",
    "        session_id: Optional session identifier (auto-generated if None)\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    if session_id is None:\n",
    "        session_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Start observability trace\n",
    "    notification_id = f\"notif_{uuid.uuid4().hex[:8]}\"\n",
    "    obs_manager.start_trace(notification_id, notification_text)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ” Processing notification with multi-agent system\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Step 1: Classification Agent\n",
    "    print(\"ðŸ“Š Step 1: Classification Agent analyzing...\")\n",
    "    classification_start = time.time()\n",
    "    classification_result_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        session = await classification_runner.session_service.create_session(\n",
    "            app_name=classification_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_classify\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"session_creation\", f\"Failed to create classification session: {e}\")\n",
    "        session = await classification_runner.session_service.get_session(\n",
    "            app_name=classification_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_classify\"\n",
    "        )\n",
    "    \n",
    "    message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=notification_text)]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        async for event in classification_runner.run_async(\n",
    "            user_id=user_id,\n",
    "            session_id=session.id,\n",
    "            new_message=message\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                if event.content.parts[0].text:\n",
    "                    classification_result_text += event.content.parts[0].text\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"classification_error\", f\"Classification agent error: {e}\", {\"session_id\": session_id})\n",
    "        raise\n",
    "    \n",
    "    classification_duration = (time.time() - classification_start) * 1000\n",
    "    print(f\"âœ… Classification complete\")\n",
    "    print(f\"   Result: {classification_result_text[:200]}...\\n\")\n",
    "    \n",
    "    # Parse classification result\n",
    "    classification_data = parse_classification_result(classification_result_text)\n",
    "    \n",
    "    # Log classification step\n",
    "    obs_manager.log_agent_step(\n",
    "        agent_name=\"Classification Agent\",\n",
    "        step=\"classify\",\n",
    "        input_data={\"notification_text\": notification_text[:200]},\n",
    "        output_data=classification_data,\n",
    "        duration_ms=classification_duration\n",
    "    )\n",
    "    \n",
    "    # Log classification result\n",
    "    if classification_data['classification']:\n",
    "        obs_manager.log_classification(\n",
    "            classification=classification_data['classification'],\n",
    "            reasoning=classification_data.get('reasoning', 'No reasoning provided')\n",
    "        )\n",
    "    \n",
    "    # Extract notification details from input\n",
    "    # Format: \"I received a notification: App: X, Title: Y, Body: Z\"\n",
    "    app = \"Unknown\"\n",
    "    title = \"Unknown\"\n",
    "    body = \"Unknown\"\n",
    "    \n",
    "    if \"App:\" in notification_text:\n",
    "        parts = notification_text.split(\"App:\")[-1]\n",
    "        if \"Title:\" in parts:\n",
    "            app = parts.split(\"Title:\")[0].strip().rstrip(\",\")\n",
    "            title_part = parts.split(\"Title:\")[-1]\n",
    "            if \"Body:\" in title_part:\n",
    "                title = title_part.split(\"Body:\")[0].strip().rstrip(\",\")\n",
    "                body = title_part.split(\"Body:\")[-1].strip()\n",
    "    \n",
    "    # Step 2: Action Agent\n",
    "    print(\"âš¡ Step 2: Action Agent executing...\")\n",
    "    action_start = time.time()\n",
    "    \n",
    "    # Prepare action message with classification result\n",
    "    action_message_text = f\"\"\"Notification Details:\n",
    "- App: {app}\n",
    "- Title: {title}\n",
    "- Body: {body}\n",
    "\n",
    "Classification Result:\n",
    "- Classification: {classification_data['classification']}\n",
    "- Reasoning: {classification_data['reasoning']}\n",
    "{f\"- Key Fact: {classification_data['key_fact']}\" if classification_data['key_fact'] else \"\"}\n",
    "\n",
    "Please execute the appropriate action based on the classification.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        action_session = await action_runner.session_service.create_session(\n",
    "            app_name=action_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_action\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"session_creation\", f\"Failed to create action session: {e}\")\n",
    "        action_session = await action_runner.session_service.get_session(\n",
    "            app_name=action_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_action\"\n",
    "        )\n",
    "    \n",
    "    action_message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=action_message_text)]\n",
    "    )\n",
    "    \n",
    "    action_output = \"\"\n",
    "    try:\n",
    "        async for event in action_runner.run_async(\n",
    "            user_id=user_id,\n",
    "            session_id=action_session.id,\n",
    "            new_message=action_message\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                if event.content.parts[0].text:\n",
    "                    action_output += event.content.parts[0].text\n",
    "                    print(event.content.parts[0].text)\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"action_error\", f\"Action agent error: {e}\", {\"session_id\": session_id})\n",
    "        raise\n",
    "    \n",
    "    action_duration = (time.time() - action_start) * 1000\n",
    "    \n",
    "    # Determine action type from output\n",
    "    action_type = \"unknown\"\n",
    "    if \"display_urgent_notification\" in action_output.lower() or \"urgent notification\" in action_output.lower():\n",
    "        action_type = \"display_urgent\"\n",
    "    elif \"block\" in action_output.lower() or \"blocked\" in action_output.lower():\n",
    "        action_type = \"block\"\n",
    "    elif \"save\" in action_output.lower() or \"memory\" in action_output.lower() or \"stored\" in action_output.lower():\n",
    "        action_type = \"save_memory\"\n",
    "    \n",
    "    # Log action step\n",
    "    obs_manager.log_agent_step(\n",
    "        agent_name=\"Action Agent\",\n",
    "        step=\"execute\",\n",
    "        input_data={\n",
    "            \"classification\": classification_data['classification'],\n",
    "            \"app\": app,\n",
    "            \"title\": title\n",
    "        },\n",
    "        output_data={\"action_type\": action_type, \"output\": action_output[:200]},\n",
    "        duration_ms=action_duration\n",
    "    )\n",
    "    \n",
    "    # Log action\n",
    "    obs_manager.log_action(\n",
    "        action_type=action_type,\n",
    "        action_details={\n",
    "            \"app\": app,\n",
    "            \"title\": title,\n",
    "            \"classification\": classification_data['classification']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Action execution complete\\n\")\n",
    "    \n",
    "    # Step 3: Memory Agent (only for LESS_URGENT items that need extraction refinement)\n",
    "    if classification_data['classification'] == 'LESS_URGENT':\n",
    "        print(\"ðŸ’¾ Step 3: Memory Agent extracting fact...\")\n",
    "        memory_start = time.time()\n",
    "        \n",
    "        # Log memory operation\n",
    "        if classification_data.get('key_fact'):\n",
    "            obs_manager.log_memory_operation(\n",
    "                operation=\"store\",\n",
    "                details={\n",
    "                    \"app\": app,\n",
    "                    \"extracted_fact\": classification_data['key_fact'],\n",
    "                    \"title\": title\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        memory_duration = (time.time() - memory_start) * 1000\n",
    "        obs_manager.log_agent_step(\n",
    "            agent_name=\"Memory Agent\",\n",
    "            step=\"extract\",\n",
    "            input_data={\"notification\": f\"{app}: {title}\"},\n",
    "            output_data={\"extracted_fact\": classification_data.get('key_fact', '')},\n",
    "            duration_ms=memory_duration\n",
    "        )\n",
    "        \n",
    "        # The action agent already stored the memory, but we can use memory agent\n",
    "        # for additional processing if needed (consolidation, deduplication, etc.)\n",
    "        # For now, we'll skip this step as the action agent handles storage\n",
    "        print(\"âœ… Memory extraction handled by Action Agent\\n\")\n",
    "    \n",
    "    # End trace\n",
    "    obs_manager.end_trace()\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"âœ… Multi-agent processing complete\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Legacy helper function for backward compatibility (uses single agent approach)\n",
    "async def run_notification_test(runner_instance, session_service, user_id, session_id, message_text):\n",
    "    \"\"\"Helper function to test notification processing (legacy single-agent)\"\"\"\n",
    "    # Create or get session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=runner_instance.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=runner_instance.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    \n",
    "    # Convert message to Content format\n",
    "    message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=message_text)]\n",
    "    )\n",
    "    \n",
    "    # Process the notification\n",
    "    async for event in runner_instance.run_async(\n",
    "        user_id=user_id, session_id=session.id, new_message=message\n",
    "    ):\n",
    "        if event.content and event.content.parts:\n",
    "            if event.content.parts[0].text:\n",
    "                print(event.content.parts[0].text)\n",
    "\n",
    "print(\"âœ… Multi-agent orchestration layer initialized\")\n",
    "print(\"âœ… Sequential agent coordination ready\")\n",
    "print(\"âœ… Helper functions for async operations ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Agent\n",
    "\n",
    "Let's test the agent with sample notifications:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:21,030 - FocusFilter - INFO - ðŸ” Trace started: trace_99d2f874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:21,507 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:52:22,222 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:22,225 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 1191.56ms\n",
      "2025-12-02 02:52:22,229 - FocusFilter - INFO - ðŸ·ï¸  Classification: URGENT - Security alert from a bank requires immediate attention to prevent potential financial loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: URGENT\n",
      "Reasoning: Security alert from a bank requires immediate attention to prevent potential financial loss.\n",
      "...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:22,584 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:52:23,427 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:23,429 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:52:23,436 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Banking App\n",
      "Title: Security Alert\n",
      "Body: Your bank flagged suspicious activity on your account. Please verify immediately.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:24,050 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:24,059 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1827.62ms\n",
      "2025-12-02 02:52:24,063 - FocusFilter - INFO - âš¡ Action: display_urgent - {\"app\": \"Banking App\", \"title\": \"Security Alert\", \"classification\": \"URGENT\"}\n",
      "2025-12-02 02:52:24,067 - FocusFilter - INFO - âœ… Trace completed: trace_99d2f874 in 3037.00ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have displayed the urgent notification.\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 1 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 1: Urgent security alert\n",
    "USER_ID = \"test\"\n",
    "\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Banking App, Title: Security Alert, Body: Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_1\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 1 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:24,120 - FocusFilter - INFO - ðŸ” Trace started: trace_18f0ca69\n",
      "2025-12-02 02:52:24,136 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:24,812 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:24,818 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 690.86ms\n",
      "2025-12-02 02:52:24,822 - FocusFilter - INFO - ðŸ·ï¸  Classification: IRRELEVANT - Social media likes are generally not important or time-sensitive.\n",
      "2025-12-02 02:52:24,839 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: IRRELEVANT\n",
      "Reasoning: Social media likes are generally not important or time-sensitive.\n",
      "...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:25,432 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:25,435 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:52:25,451 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Social Media] New Like - social media noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:25,964 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:25,970 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1142.85ms\n",
      "2025-12-02 02:52:25,973 - FocusFilter - INFO - âš¡ Action: block - {\"app\": \"Social Media\", \"title\": \"New Like\", \"classification\": \"IRRELEVANT\"}\n",
      "2025-12-02 02:52:25,975 - FocusFilter - INFO - âœ… Trace completed: trace_18f0ca69 in 1855.12ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have blocked the notification from Social Media with the reason \"social media noise\".\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 2 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 2: Irrelevant social media\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_2\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 2 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š OBSERVABILITY METRICS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Total Notifications Processed: 2\n",
      "ðŸ“ Total Traces Captured: 2\n",
      "\n",
      "ðŸ·ï¸  Classification Distribution:\n",
      "   URGENT: 1 (50.0%)\n",
      "   IRRELEVANT: 1 (50.0%)\n",
      "\n",
      "âš¡ Action Distribution:\n",
      "   display_urgent: 1 (50.0%)\n",
      "   block: 1 (50.0%)\n",
      "\n",
      "â±ï¸  Performance Metrics:\n",
      "   Classification Agent_classify:\n",
      "      Average: 941.21ms\n",
      "      Min: 690.86ms\n",
      "      Max: 1191.56ms\n",
      "      Count: 2\n",
      "   Action Agent_execute:\n",
      "      Average: 1485.24ms\n",
      "      Min: 1142.85ms\n",
      "      Max: 1827.62ms\n",
      "      Count: 2\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display observability metrics\n",
    "obs_manager.print_metrics_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” DETAILED TRACE EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "Trace ID: trace_18f0ca69\n",
      "Notification ID: notif_145b23f9\n",
      "Duration: 1855.12ms\n",
      "\n",
      "Notification Text: I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo....\n",
      "\n",
      "ðŸ“Š Classification:\n",
      "   Result: IRRELEVANT\n",
      "   Reasoning: Social media likes are generally not important or time-sensitive....\n",
      "\n",
      "âš¡ Action:\n",
      "   Type: block\n",
      "   Details: {'app': 'Social Media', 'title': 'New Like', 'classification': 'IRRELEVANT'}\n",
      "\n",
      "ðŸ¤– Agent Steps:\n",
      "   Classification Agent - classify: 690.86ms\n",
      "   Action Agent - execute: 1142.85ms\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a detailed trace example\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ” DETAILED TRACE EXAMPLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recent_traces = obs_manager.get_recent_traces(limit=1)\n",
    "if recent_traces:\n",
    "    trace = recent_traces[0]\n",
    "    print(f\"\\nTrace ID: {trace['trace_id']}\")\n",
    "    print(f\"Notification ID: {trace['notification_id']}\")\n",
    "    print(f\"Duration: {trace['duration_ms']:.2f}ms\")\n",
    "    print(f\"\\nNotification Text: {trace['notification_text'][:100]}...\")\n",
    "    \n",
    "    if trace['classification']:\n",
    "        print(f\"\\nðŸ“Š Classification:\")\n",
    "        print(f\"   Result: {trace['classification']['result']}\")\n",
    "        print(f\"   Reasoning: {trace['classification']['reasoning'][:150]}...\")\n",
    "    \n",
    "    if trace['action']:\n",
    "        print(f\"\\nâš¡ Action:\")\n",
    "        print(f\"   Type: {trace['action']['type']}\")\n",
    "        print(f\"   Details: {trace['action']['details']}\")\n",
    "    \n",
    "    if trace['memory_operation']:\n",
    "        print(f\"\\nðŸ’¾ Memory Operation:\")\n",
    "        print(f\"   Operation: {trace['memory_operation']['operation']}\")\n",
    "        print(f\"   Details: {trace['memory_operation']['details']}\")\n",
    "    \n",
    "    if trace['agents']:\n",
    "        print(f\"\\nðŸ¤– Agent Steps:\")\n",
    "        for agent_step in trace['agents']:\n",
    "            print(f\"   {agent_step['agent']} - {agent_step['step']}: {agent_step['duration_ms']:.2f}ms\")\n",
    "    \n",
    "    if trace['errors']:\n",
    "        print(f\"\\nâŒ Errors: {len(trace['errors'])}\")\n",
    "        for error in trace['errors']:\n",
    "            print(f\"   [{error['type']}] {error['message']}\")\n",
    "else:\n",
    "    print(\"No traces available yet. Run some notifications first!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:26,074 - FocusFilter - INFO - ðŸ” Trace started: trace_05bbeba9\n",
      "2025-12-02 02:52:26,083 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:26,979 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:26,984 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 904.37ms\n",
      "2025-12-02 02:52:26,989 - FocusFilter - INFO - ðŸ·ï¸  Classification: LESS_URGENT - This is an important update about a project deadline, but it doesn't require immediate action.\n",
      "Key F\n",
      "2025-12-02 02:52:26,998 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: LESS_URGENT\n",
      "Reasoning: This is an important update about a project deadline, but it doesn't require immediate action.\n",
      "Key Fact (if LESS_URGENT): The project deadline has moved to Tuesd...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:27,881 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:27,883 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:52:27,898 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: The project deadline has moved to Tuesday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:28,562 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:28,566 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1574.42ms\n",
      "2025-12-02 02:52:28,569 - FocusFilter - INFO - âš¡ Action: save_memory - {\"app\": \"Project Manager\", \"title\": \"Deadline Update\", \"classification\": \"LESS_URGENT\"}\n",
      "2025-12-02 02:52:28,572 - FocusFilter - INFO - ðŸ’¾ Memory: store - {\"app\": \"Project Manager\", \"extracted_fact\": \"(if LESS_URGENT): The project deadline has moved to Tuesday.\", \"title\": \"Deadline Update\"}\n",
      "2025-12-02 02:52:28,574 - FocusFilter - INFO - ðŸ“Š Memory Agent - extract completed in 2.29ms\n",
      "2025-12-02 02:52:28,576 - FocusFilter - INFO - âœ… Trace completed: trace_05bbeba9 in 2502.04ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have saved the notification to memory with the extracted fact: \"The project deadline has moved to Tuesday.\".\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "ðŸ’¾ Step 3: Memory Agent extracting fact...\n",
      "âœ… Memory extraction handled by Action Agent\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 3 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 3: Less urgent project update\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Project Manager, Title: Deadline Update, Body: Your project deadline has moved to Tuesday.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_3\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 3 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ’¾ Stored Memories:\n",
      "======================================================================\n",
      "\n",
      "1. The project deadline has moved to Tuesday.\n",
      "   From: Project Manager (stored at 2025-12-02T02:52:27.892114)\n"
     ]
    }
   ],
   "source": [
    "# Display stored memories\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’¾ Stored Memories:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "memories = memory_store.get_all()\n",
    "if memories:\n",
    "    for i, memory in enumerate(memories, 1):\n",
    "        print(f\"\\n{i}. {memory['extracted_fact']}\")\n",
    "        print(f\"   From: {memory['app']} (stored at {memory['stored_at']})\")\n",
    "else:\n",
    "    print(\"No memories stored yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”§ Testing Enhanced Features\n",
      "======================================================================\n",
      "\n",
      "1. Testing retrieve_user_preferences() tool:\n",
      "   Current preferences: {'always_urgent_apps': [], 'always_block_apps': [], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "2. Testing preference learning:\n",
      "âœ… Added preference: always_urgent_apps = Banking App\n",
      "âœ… Added preference: always_block_apps = Social Media\n",
      "   Updated preferences: {'always_urgent_apps': ['Banking App'], 'always_block_apps': ['Social Media'], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "3. Testing memory consolidation:\n",
      "ðŸ’¾ Stored memory: Project deadline moved to Tuesday\n",
      "   Memories before consolidation: 2\n",
      "   Memories after consolidation: 2\n",
      "\n",
      "4. Testing context compaction:\n",
      "   Compacted context: 2 most relevant memories\n",
      "\n",
      "5. Testing preference learning from patterns:\n",
      "   Learned preferences: {'always_urgent_apps': ['Banking App'], 'always_block_apps': ['Social Media'], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "======================================================================\n",
      "âœ… Enhanced features demonstration complete\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEMONSTRATION: Enhanced Memory and Tools Features\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”§ Testing Enhanced Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Retrieve user preferences\n",
    "print(\"\\n1. Testing retrieve_user_preferences() tool:\")\n",
    "prefs = retrieve_user_preferences()\n",
    "if prefs.get('status') == 'success' and 'preferences' in prefs:\n",
    "    print(f\"   Current preferences: {prefs['preferences']}\")\n",
    "else:\n",
    "    error_msg = prefs.get('error_message', 'Unknown error')\n",
    "    print(f\"   Error: {error_msg}\")\n",
    "    # Fallback: try direct access if method exists\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        try:\n",
    "            direct_prefs = memory_store.get_user_preferences()\n",
    "            print(f\"   Direct access preferences: {direct_prefs}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Direct access failed: {e}\")\n",
    "    else:\n",
    "        print(\"   Note: Enhanced methods not yet available (run enhancement cell first)\")\n",
    "\n",
    "# Test 2: Update preferences\n",
    "print(\"\\n2. Testing preference learning:\")\n",
    "if hasattr(memory_store, 'update_preference'):\n",
    "    memory_store.update_preference(\"always_urgent_apps\", \"Banking App\", \"add\")\n",
    "    memory_store.update_preference(\"always_block_apps\", \"Social Media\", \"add\")\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        print(f\"   Updated preferences: {memory_store.get_user_preferences()}\")\n",
    "    else:\n",
    "        print(\"   Preferences updated (get_user_preferences not available)\")\n",
    "else:\n",
    "    print(\"   Note: update_preference method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 3: Memory consolidation\n",
    "print(\"\\n3. Testing memory consolidation:\")\n",
    "if hasattr(memory_store, 'consolidate_memories'):\n",
    "    # Add a similar memory to test consolidation\n",
    "    if memory_store.memories:\n",
    "        test_notification = Notification(\n",
    "            id=str(uuid.uuid4()),\n",
    "            app=\"Project Manager\",\n",
    "            title=\"Deadline Update\",\n",
    "            body=\"Your project deadline has moved to Tuesday.\",\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        memory_store.store(test_notification, \"Project deadline moved to Tuesday\")\n",
    "        print(f\"   Memories before consolidation: {len(memory_store.memories)}\")\n",
    "        consolidated_count = memory_store.consolidate_memories()\n",
    "        print(f\"   Memories after consolidation: {consolidated_count}\")\n",
    "    else:\n",
    "        print(\"   No memories to consolidate\")\n",
    "else:\n",
    "    print(\"   Note: consolidate_memories method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 4: Context compaction\n",
    "print(\"\\n4. Testing context compaction:\")\n",
    "if hasattr(memory_store, 'compact_context'):\n",
    "    compacted = memory_store.compact_context(max_memories=5)\n",
    "    print(f\"   Compacted context: {len(compacted)} most relevant memories\")\n",
    "else:\n",
    "    print(\"   Note: compact_context method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 5: Preference learning from patterns\n",
    "print(\"\\n5. Testing preference learning from patterns:\")\n",
    "if hasattr(memory_store, 'learn_from_patterns'):\n",
    "    classification_history = [\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "    ]\n",
    "    memory_store.learn_from_patterns(classification_history)\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        print(f\"   Learned preferences: {memory_store.get_user_preferences()}\")\n",
    "    else:\n",
    "        print(\"   Pattern learning completed\")\n",
    "else:\n",
    "    print(\"   Note: learn_from_patterns method not available (run enhancement cell first)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Enhanced features demonstration complete\")\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent Evaluation Framework initialized\n",
      "   â€¢ Golden test suite ready ({len(GOLDEN_TEST_SUITE)} test cases)\n",
      "   â€¢ LLM-as-judge evaluation ready\n",
      "   â€¢ Metrics calculation ready\n",
      "   â€¢ Run evaluation_framework.run_evaluation() to start\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Agent Evaluation Framework (LLM-as-Judge)\n",
    "# ============================================================================\n",
    "# This implements automated evaluation of agent performance using:\n",
    "# - Golden test suite with labeled notifications\n",
    "# - LLM-as-judge evaluation framework\n",
    "# - Comprehensive metrics (classification accuracy, action correctness, memory quality)\n",
    "# - Automated scoring and reporting\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class TestCase:\n",
    "    \"\"\"Represents a test case with expected results\"\"\"\n",
    "    id: str\n",
    "    notification_text: str\n",
    "    app: str\n",
    "    title: str\n",
    "    body: str\n",
    "    expected_classification: str  # URGENT, IRRELEVANT, or LESS_URGENT\n",
    "    expected_action: str  # display_urgent, block, or save_memory\n",
    "    expected_extracted_fact: Optional[str] = None  # For LESS_URGENT cases\n",
    "    reasoning: str = \"\"  # Why this classification is expected\n",
    "\n",
    "# Golden test suite - labeled notifications for evaluation\n",
    "GOLDEN_TEST_SUITE = [\n",
    "    TestCase(\n",
    "        id=\"test_001\",\n",
    "        notification_text=\"I received a notification: App: Banking App, Title: Security Alert, Body: Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "        app=\"Banking App\",\n",
    "        title=\"Security Alert\",\n",
    "        body=\"Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "        expected_classification=\"URGENT\",\n",
    "        expected_action=\"display_urgent\",\n",
    "        reasoning=\"Security alerts from banking apps require immediate attention\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_002\",\n",
    "        notification_text=\"I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo.\",\n",
    "        app=\"Social Media\",\n",
    "        title=\"New Like\",\n",
    "        body=\"3 new people liked your photo.\",\n",
    "        expected_classification=\"IRRELEVANT\",\n",
    "        expected_action=\"block\",\n",
    "        reasoning=\"Social media likes are noise and don't require attention\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_003\",\n",
    "        notification_text=\"I received a notification: App: Project Manager, Title: Deadline Update, Body: Your project deadline has moved to Tuesday.\",\n",
    "        app=\"Project Manager\",\n",
    "        title=\"Deadline Update\",\n",
    "        body=\"Your project deadline has moved to Tuesday.\",\n",
    "        expected_classification=\"LESS_URGENT\",\n",
    "        expected_action=\"save_memory\",\n",
    "        expected_extracted_fact=\"Project deadline moved to Tuesday\",\n",
    "        reasoning=\"Project updates are important but not immediately urgent\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_004\",\n",
    "        notification_text=\"I received a notification: App: Email, Title: Meeting Reminder, Body: You have a meeting in 15 minutes with the CEO.\",\n",
    "        app=\"Email\",\n",
    "        title=\"Meeting Reminder\",\n",
    "        body=\"You have a meeting in 15 minutes with the CEO.\",\n",
    "        expected_classification=\"URGENT\",\n",
    "        expected_action=\"display_urgent\",\n",
    "        reasoning=\"Time-sensitive meeting reminders require immediate attention\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_005\",\n",
    "        notification_text=\"I received a notification: App: Shopping App, Title: Flash Sale, Body: 50% off all items! Limited time offer!\",\n",
    "        app=\"Shopping App\",\n",
    "        title=\"Flash Sale\",\n",
    "        body=\"50% off all items! Limited time offer!\",\n",
    "        expected_classification=\"IRRELEVANT\",\n",
    "        expected_action=\"block\",\n",
    "        reasoning=\"Promotional content is typically noise\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_006\",\n",
    "        notification_text=\"I received a notification: App: Calendar, Title: Event Tomorrow, Body: Team standup meeting scheduled for tomorrow at 10 AM.\",\n",
    "        app=\"Calendar\",\n",
    "        title=\"Event Tomorrow\",\n",
    "        body=\"Team standup meeting scheduled for tomorrow at 10 AM.\",\n",
    "        expected_classification=\"LESS_URGENT\",\n",
    "        expected_action=\"save_memory\",\n",
    "        expected_extracted_fact=\"Team standup meeting tomorrow at 10 AM\",\n",
    "        reasoning=\"Future events are important to remember but not urgent\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_007\",\n",
    "        notification_text=\"I received a notification: App: Health App, Title: Medication Reminder, Body: Time to take your daily medication.\",\n",
    "        app=\"Health App\",\n",
    "        title=\"Medication Reminder\",\n",
    "        body=\"Time to take your daily medication.\",\n",
    "        expected_classification=\"URGENT\",\n",
    "        expected_action=\"display_urgent\",\n",
    "        reasoning=\"Health-related reminders are time-sensitive and important\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"test_008\",\n",
    "        notification_text=\"I received a notification: App: News App, Title: Breaking News, Body: Local weather update: Sunny skies expected today.\",\n",
    "        app=\"News App\",\n",
    "        title=\"Breaking News\",\n",
    "        body=\"Local weather update: Sunny skies expected today.\",\n",
    "        expected_classification=\"IRRELEVANT\",\n",
    "        expected_action=\"block\",\n",
    "        reasoning=\"Generic news updates are typically not urgent\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "class EvaluationJudge:\n",
    "    \"\"\"LLM-as-judge for evaluating agent performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.judge_agent = LlmAgent(\n",
    "            name=\"evaluation_judge\",\n",
    "            model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "            instruction=\"\"\"You are an Evaluation Judge for the Focus Filter notification system.\n",
    "\n",
    "Your job is to evaluate whether an agent's classification and actions match the expected behavior.\n",
    "\n",
    "You will receive:\n",
    "1. The test case (notification and expected results)\n",
    "2. The agent's actual output (classification, action, extracted fact)\n",
    "\n",
    "Evaluate:\n",
    "1. **Classification Match**: Does the agent's classification match the expected classification?\n",
    "   - URGENT, IRRELEVANT, or LESS_URGENT\n",
    "   - Consider if the classification is reasonable even if not exact match\n",
    "\n",
    "2. **Action Match**: Does the agent's action match the expected action?\n",
    "   - display_urgent, block, or save_memory\n",
    "   - Action should align with classification\n",
    "\n",
    "3. **Memory Extraction Quality** (for LESS_URGENT cases):\n",
    "   - Is the extracted fact accurate and useful?\n",
    "   - Does it capture the key information?\n",
    "\n",
    "Respond in JSON format:\n",
    "{\n",
    "    \"classification_match\": true/false,\n",
    "    \"classification_score\": 0.0-1.0,\n",
    "    \"action_match\": true/false,\n",
    "    \"action_score\": 0.0-1.0,\n",
    "    \"memory_quality\": 0.0-1.0 (only for LESS_URGENT),\n",
    "    \"overall_score\": 0.0-1.0,\n",
    "    \"reasoning\": \"explanation of scores\"\n",
    "}\"\"\",\n",
    "            tools=[]\n",
    "        )\n",
    "        self.judge_runner = Runner(\n",
    "            app_name=\"FocusFilter_Evaluation\",\n",
    "            agent=self.judge_agent,\n",
    "            session_service=InMemorySessionService()\n",
    "        )\n",
    "    \n",
    "    async def evaluate_single_case(\n",
    "        self, \n",
    "        test_case: TestCase, \n",
    "        actual_classification: str,\n",
    "        actual_action: str,\n",
    "        actual_extracted_fact: Optional[str] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"Evaluate a single test case using LLM-as-judge\"\"\"\n",
    "        \n",
    "        evaluation_prompt = f\"\"\"Evaluate this agent performance:\n",
    "\n",
    "TEST CASE:\n",
    "- Notification: {test_case.app} - {test_case.title}: {test_case.body}\n",
    "- Expected Classification: {test_case.expected_classification}\n",
    "- Expected Action: {test_case.expected_action}\n",
    "{f\"- Expected Extracted Fact: {test_case.expected_extracted_fact}\" if test_case.expected_extracted_fact else \"\"}\n",
    "- Reasoning: {test_case.reasoning}\n",
    "\n",
    "AGENT OUTPUT:\n",
    "- Actual Classification: {actual_classification}\n",
    "- Actual Action: {actual_action}\n",
    "{f\"- Actual Extracted Fact: {actual_extracted_fact}\" if actual_extracted_fact else \"\"}\n",
    "\n",
    "Evaluate the agent's performance and provide scores in JSON format.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            session = await self.judge_runner.session_service.create_session(\n",
    "                app_name=self.judge_runner.app_name,\n",
    "                user_id=\"evaluator\",\n",
    "                session_id=f\"eval_{test_case.id}\"\n",
    "            )\n",
    "            \n",
    "            message = types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=evaluation_prompt)]\n",
    "            )\n",
    "            \n",
    "            judge_response = \"\"\n",
    "            async for event in self.judge_runner.run_async(\n",
    "                user_id=\"evaluator\",\n",
    "                session_id=session.id,\n",
    "                new_message=message\n",
    "            ):\n",
    "                if event.content and event.content.parts:\n",
    "                    if event.content.parts[0].text:\n",
    "                        judge_response += event.content.parts[0].text\n",
    "            \n",
    "            # Try to parse JSON from response\n",
    "            try:\n",
    "                # Extract JSON from response (might be wrapped in markdown)\n",
    "                if \"```json\" in judge_response:\n",
    "                    json_start = judge_response.find(\"```json\") + 7\n",
    "                    json_end = judge_response.find(\"```\", json_start)\n",
    "                    judge_response = judge_response[json_start:json_end].strip()\n",
    "                elif \"```\" in judge_response:\n",
    "                    json_start = judge_response.find(\"```\") + 3\n",
    "                    json_end = judge_response.find(\"```\", json_start)\n",
    "                    judge_response = judge_response[json_start:json_end].strip()\n",
    "                \n",
    "                evaluation_result = json.loads(judge_response)\n",
    "            except:\n",
    "                # Fallback: simple scoring based on exact matches\n",
    "                evaluation_result = {\n",
    "                    \"classification_match\": actual_classification.upper() == test_case.expected_classification.upper(),\n",
    "                    \"classification_score\": 1.0 if actual_classification.upper() == test_case.expected_classification.upper() else 0.0,\n",
    "                    \"action_match\": actual_action == test_case.expected_action,\n",
    "                    \"action_score\": 1.0 if actual_action == test_case.expected_action else 0.0,\n",
    "                    \"memory_quality\": 0.5,  # Default\n",
    "                    \"overall_score\": 0.5,\n",
    "                    \"reasoning\": \"Fallback scoring used (JSON parsing failed)\"\n",
    "                }\n",
    "            \n",
    "            return {\n",
    "                \"test_case_id\": test_case.id,\n",
    "                \"evaluation\": evaluation_result,\n",
    "                \"expected\": {\n",
    "                    \"classification\": test_case.expected_classification,\n",
    "                    \"action\": test_case.expected_action,\n",
    "                    \"extracted_fact\": test_case.expected_extracted_fact\n",
    "                },\n",
    "                \"actual\": {\n",
    "                    \"classification\": actual_classification,\n",
    "                    \"action\": actual_action,\n",
    "                    \"extracted_fact\": actual_extracted_fact\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"test_case_id\": test_case.id,\n",
    "                \"error\": str(e),\n",
    "                \"evaluation\": {\n",
    "                    \"classification_match\": False,\n",
    "                    \"classification_score\": 0.0,\n",
    "                    \"action_match\": False,\n",
    "                    \"action_score\": 0.0,\n",
    "                    \"overall_score\": 0.0,\n",
    "                    \"reasoning\": f\"Evaluation error: {e}\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "class EvaluationFramework:\n",
    "    \"\"\"Comprehensive evaluation framework for agent performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.judge = EvaluationJudge()\n",
    "        self.results: List[Dict] = []\n",
    "    \n",
    "    async def run_evaluation(self, test_suite: List[TestCase] = None) -> Dict:\n",
    "        \"\"\"Run evaluation on the test suite\"\"\"\n",
    "        if test_suite is None:\n",
    "            test_suite = GOLDEN_TEST_SUITE\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ”¬ AGENT EVALUATION FRAMEWORK\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nðŸ“‹ Running evaluation on {len(test_suite)} test cases...\\n\")\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        for i, test_case in enumerate(test_suite, 1):\n",
    "            print(f\"[{i}/{len(test_suite)}] Processing: {test_case.id} - {test_case.app}\")\n",
    "            \n",
    "            # Process notification through the agent system\n",
    "            try:\n",
    "                # Extract notification details\n",
    "                notification_id = f\"eval_{test_case.id}\"\n",
    "                \n",
    "                # Run through the multi-agent system\n",
    "                # We'll capture the results from the orchestration\n",
    "                # For now, we'll simulate by calling the process function\n",
    "                # and capturing the results\n",
    "                \n",
    "                # Start trace\n",
    "                obs_manager.start_trace(notification_id, test_case.notification_text)\n",
    "                \n",
    "                # Run classification\n",
    "                classification_start = time.time()\n",
    "                session = await classification_runner.session_service.create_session(\n",
    "                    app_name=classification_runner.app_name,\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=f\"eval_{test_case.id}_classify\"\n",
    "                )\n",
    "                \n",
    "                message = types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part(text=test_case.notification_text)]\n",
    "                )\n",
    "                \n",
    "                classification_result_text = \"\"\n",
    "                async for event in classification_runner.run_async(\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=session.id,\n",
    "                    new_message=message\n",
    "                ):\n",
    "                    if event.content and event.content.parts:\n",
    "                        if event.content.parts[0].text:\n",
    "                            classification_result_text += event.content.parts[0].text\n",
    "                \n",
    "                classification_data = parse_classification_result(classification_result_text)\n",
    "                actual_classification = classification_data.get('classification', 'UNKNOWN')\n",
    "                \n",
    "                # Run action\n",
    "                action_start = time.time()\n",
    "                action_session = await action_runner.session_service.create_session(\n",
    "                    app_name=action_runner.app_name,\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=f\"eval_{test_case.id}_action\"\n",
    "                )\n",
    "                \n",
    "                action_message_text = f\"\"\"Notification Details:\n",
    "- App: {test_case.app}\n",
    "- Title: {test_case.title}\n",
    "- Body: {test_case.body}\n",
    "\n",
    "Classification Result:\n",
    "- Classification: {actual_classification}\n",
    "- Reasoning: {classification_data.get('reasoning', '')}\n",
    "{f\"- Key Fact: {classification_data.get('key_fact', '')}\" if classification_data.get('key_fact') else \"\"}\n",
    "\n",
    "Please execute the appropriate action based on the classification.\"\"\"\n",
    "                \n",
    "                action_message = types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part(text=action_message_text)]\n",
    "                )\n",
    "                \n",
    "                action_output = \"\"\n",
    "                async for event in action_runner.run_async(\n",
    "                    user_id=\"evaluator\",\n",
    "                    session_id=action_session.id,\n",
    "                    new_message=action_message\n",
    "                ):\n",
    "                    if event.content and event.content.parts:\n",
    "                        if event.content.parts[0].text:\n",
    "                            action_output += event.content.parts[0].text\n",
    "                \n",
    "                # Determine actual action from output\n",
    "                actual_action = \"unknown\"\n",
    "                if \"display_urgent_notification\" in action_output.lower() or \"urgent notification\" in action_output.lower():\n",
    "                    actual_action = \"display_urgent\"\n",
    "                elif \"block\" in action_output.lower() or \"blocked\" in action_output.lower():\n",
    "                    actual_action = \"block\"\n",
    "                elif \"save\" in action_output.lower() or \"memory\" in action_output.lower() or \"stored\" in action_output.lower():\n",
    "                    actual_action = \"save_memory\"\n",
    "                \n",
    "                actual_extracted_fact = classification_data.get('key_fact')\n",
    "                \n",
    "                # Evaluate using LLM-as-judge\n",
    "                evaluation_result = await self.judge.evaluate_single_case(\n",
    "                    test_case=test_case,\n",
    "                    actual_classification=actual_classification,\n",
    "                    actual_action=actual_action,\n",
    "                    actual_extracted_fact=actual_extracted_fact\n",
    "                )\n",
    "                \n",
    "                self.results.append(evaluation_result)\n",
    "                \n",
    "                # End trace\n",
    "                obs_manager.end_trace()\n",
    "                \n",
    "                print(f\"   âœ… Completed - Classification: {actual_classification}, Action: {actual_action}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Error: {e}\")\n",
    "                self.results.append({\n",
    "                    \"test_case_id\": test_case.id,\n",
    "                    \"error\": str(e),\n",
    "                    \"evaluation\": {\n",
    "                        \"overall_score\": 0.0,\n",
    "                        \"reasoning\": f\"Processing error: {e}\"\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self.calculate_metrics()\n",
    "        \n",
    "        # Print report\n",
    "        self.print_evaluation_report(metrics)\n",
    "        \n",
    "        return {\n",
    "            \"results\": self.results,\n",
    "            \"metrics\": metrics\n",
    "        }\n",
    "    \n",
    "    def calculate_metrics(self) -> Dict:\n",
    "        \"\"\"Calculate evaluation metrics from results\"\"\"\n",
    "        if not self.results:\n",
    "            return {}\n",
    "        \n",
    "        total = len(self.results)\n",
    "        classification_correct = sum(\n",
    "            1 for r in self.results \n",
    "            if r.get(\"evaluation\", {}).get(\"classification_match\", False)\n",
    "        )\n",
    "        action_correct = sum(\n",
    "            1 for r in self.results \n",
    "            if r.get(\"evaluation\", {}).get(\"action_match\", False)\n",
    "        )\n",
    "        \n",
    "        classification_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"classification_score\", 0.0)\n",
    "            for r in self.results\n",
    "        ]\n",
    "        action_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"action_score\", 0.0)\n",
    "            for r in self.results\n",
    "        ]\n",
    "        overall_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"overall_score\", 0.0)\n",
    "            for r in self.results\n",
    "        ]\n",
    "        \n",
    "        # Memory quality (only for LESS_URGENT cases)\n",
    "        memory_scores = [\n",
    "            r.get(\"evaluation\", {}).get(\"memory_quality\", 0.0)\n",
    "            for r in self.results\n",
    "            if r.get(\"expected\", {}).get(\"classification\") == \"LESS_URGENT\"\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            \"total_tests\": total,\n",
    "            \"classification_accuracy\": classification_correct / total if total > 0 else 0.0,\n",
    "            \"action_accuracy\": action_correct / total if total > 0 else 0.0,\n",
    "            \"avg_classification_score\": sum(classification_scores) / len(classification_scores) if classification_scores else 0.0,\n",
    "            \"avg_action_score\": sum(action_scores) / len(action_scores) if action_scores else 0.0,\n",
    "            \"avg_overall_score\": sum(overall_scores) / len(overall_scores) if overall_scores else 0.0,\n",
    "            \"avg_memory_quality\": sum(memory_scores) / len(memory_scores) if memory_scores else 0.0,\n",
    "            \"classification_correct\": classification_correct,\n",
    "            \"action_correct\": action_correct\n",
    "        }\n",
    "    \n",
    "    def print_evaluation_report(self, metrics: Dict):\n",
    "        \"\"\"Print a formatted evaluation report\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“Š EVALUATION REPORT\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nðŸ“ˆ Overall Metrics:\")\n",
    "        print(f\"   Total Tests: {metrics.get('total_tests', 0)}\")\n",
    "        print(f\"   Overall Score: {metrics.get('avg_overall_score', 0.0):.2%}\")\n",
    "        print(f\"\\nðŸ·ï¸  Classification Metrics:\")\n",
    "        print(f\"   Accuracy: {metrics.get('classification_accuracy', 0.0):.2%} ({metrics.get('classification_correct', 0)}/{metrics.get('total_tests', 0)})\")\n",
    "        print(f\"   Average Score: {metrics.get('avg_classification_score', 0.0):.2%}\")\n",
    "        print(f\"\\nâš¡ Action Metrics:\")\n",
    "        print(f\"   Accuracy: {metrics.get('action_accuracy', 0.0):.2%} ({metrics.get('action_correct', 0)}/{metrics.get('total_tests', 0)})\")\n",
    "        print(f\"   Average Score: {metrics.get('avg_action_score', 0.0):.2%}\")\n",
    "        if metrics.get('avg_memory_quality', 0) > 0:\n",
    "            print(f\"\\nðŸ’¾ Memory Extraction Quality:\")\n",
    "            print(f\"   Average Score: {metrics.get('avg_memory_quality', 0.0):.2%}\")\n",
    "        print(f\"\\n{'='*70}\\n\")\n",
    "        \n",
    "        # Print individual results\n",
    "        print(f\"\\nðŸ“‹ Individual Test Results:\\n\")\n",
    "        for result in self.results:\n",
    "            test_id = result.get(\"test_case_id\", \"unknown\")\n",
    "            eval_data = result.get(\"evaluation\", {})\n",
    "            expected = result.get(\"expected\", {})\n",
    "            actual = result.get(\"actual\", {})\n",
    "            \n",
    "            status = \"âœ…\" if eval_data.get(\"overall_score\", 0) >= 0.7 else \"âš ï¸\" if eval_data.get(\"overall_score\", 0) >= 0.4 else \"âŒ\"\n",
    "            \n",
    "            print(f\"{status} {test_id}:\")\n",
    "            print(f\"   Expected: {expected.get('classification')} â†’ {expected.get('action')}\")\n",
    "            print(f\"   Actual: {actual.get('classification')} â†’ {actual.get('action')}\")\n",
    "            print(f\"   Score: {eval_data.get('overall_score', 0.0):.2%}\")\n",
    "            if eval_data.get(\"reasoning\"):\n",
    "                print(f\"   Reasoning: {eval_data.get('reasoning')[:100]}...\")\n",
    "            print()\n",
    "\n",
    "# Initialize evaluation framework\n",
    "evaluation_framework = EvaluationFramework()\n",
    "\n",
    "print(\"âœ… Agent Evaluation Framework initialized\")\n",
    "print(\"   â€¢ Golden test suite ready ({len(GOLDEN_TEST_SUITE)} test cases)\")\n",
    "print(\"   â€¢ LLM-as-judge evaluation ready\")\n",
    "print(\"   â€¢ Metrics calculation ready\")\n",
    "print(\"   â€¢ Run evaluation_framework.run_evaluation() to start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:28,849 - FocusFilter - INFO - ðŸ” Trace started: trace_72aa47d9\n",
      "2025-12-02 02:52:28,857 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”¬ AGENT EVALUATION FRAMEWORK\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Running evaluation on 8 test cases...\n",
      "\n",
      "[1/8] Processing: test_001 - Banking App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:29,520 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:29,531 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:52:30,222 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:30,225 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:52:30,235 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Banking App\n",
      "Title: Security Alert\n",
      "Body: Your bank flagged suspicious activity on your account. Please verify immediately.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:30,721 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:31,151 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:52:31,153 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:52:31,346 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.893986910025507 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}.\n",
      "2025-12-02 02:52:34,638 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:34,643 - FocusFilter - INFO - âœ… Trace completed: trace_72aa47d9 in 5794.07ms\n",
      "2025-12-02 02:52:34,650 - FocusFilter - INFO - ðŸ” Trace started: trace_1ed9c4c9\n",
      "2025-12-02 02:52:34,659 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: URGENT, Action: display_urgent\n",
      "[2/8] Processing: test_002 - Social Media\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:52:35,377 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:52:35,391 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:52:35,570 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.673504022662028 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}.\n",
      "2025-12-02 02:52:37,343 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.714367034793067 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}.\n",
      "2025-12-02 02:52:45,153 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.819204362561024 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}.\n",
      "2025-12-02 02:53:35,979 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:35,983 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:53:35,995 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Social Media] New Like - social media noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:53:36,591 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:36,599 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:36,607 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:53:37,675 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:37,681 - FocusFilter - INFO - âœ… Trace completed: trace_1ed9c4c9 in 63031.00ms\n",
      "2025-12-02 02:53:37,685 - FocusFilter - INFO - ðŸ” Trace started: trace_9dfffb00\n",
      "2025-12-02 02:53:37,695 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: IRRELEVANT, Action: block\n",
      "[3/8] Processing: test_003 - Project Manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:53:38,543 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:38,568 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:39,258 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:39,261 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:53:39,282 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Project deadline moved to Tuesday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:53:39,871 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:39,881 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:39,885 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:53:41,025 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:41,031 - FocusFilter - INFO - âœ… Trace completed: trace_9dfffb00 in 3345.87ms\n",
      "2025-12-02 02:53:41,034 - FocusFilter - INFO - ðŸ” Trace started: trace_29b34e38\n",
      "2025-12-02 02:53:41,044 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: LESS_URGENT, Action: save_memory\n",
      "[4/8] Processing: test_004 - Email\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:53:41,612 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:41,629 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:42,199 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:42,203 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:53:42,225 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Email\n",
      "Title: Meeting Reminder\n",
      "Body: You have a meeting in 15 minutes with the CEO.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:53:42,725 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:42,736 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:42,739 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:53:43,838 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:43,845 - FocusFilter - INFO - âœ… Trace completed: trace_29b34e38 in 2810.84ms\n",
      "2025-12-02 02:53:43,849 - FocusFilter - INFO - ðŸ” Trace started: trace_79b67f35\n",
      "2025-12-02 02:53:43,872 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:43,978 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.4959319132253308 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: URGENT, Action: display_urgent\n",
      "[5/8] Processing: test_005 - Shopping App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:53:45,706 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.025409365573258 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}.\n",
      "2025-12-02 02:53:53,327 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:53:53,340 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:53:53,505 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.1849681989871192 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}.\n",
      "2025-12-02 02:53:54,784 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.2677738537617795 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'model': 'gemini-2.0-flash-exp', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}.\n",
      "2025-12-02 02:54:02,160 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.10924852041359 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}.\n",
      "2025-12-02 02:54:52,064 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:52,068 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:54:52,094 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Shopping App] Flash Sale - promotional content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:54:52,770 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:52,780 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:54:52,784 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:54:54,112 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:54,117 - FocusFilter - INFO - âœ… Trace completed: trace_79b67f35 in 70267.99ms\n",
      "2025-12-02 02:54:54,121 - FocusFilter - INFO - ðŸ” Trace started: trace_e56d0b4c\n",
      "2025-12-02 02:54:54,131 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: IRRELEVANT, Action: block\n",
      "[6/8] Processing: test_006 - Calendar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:54:55,034 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:55,046 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:54:55,816 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:55,818 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:54:55,827 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Team standup meeting scheduled for tomorrow at 10 AM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:54:56,265 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:56,275 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:54:56,278 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:54:57,300 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:57,306 - FocusFilter - INFO - âœ… Trace completed: trace_e56d0b4c in 3185.41ms\n",
      "2025-12-02 02:54:57,309 - FocusFilter - INFO - ðŸ” Trace started: trace_f01fe38f\n",
      "2025-12-02 02:54:57,323 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: LESS_URGENT, Action: save_memory\n",
      "[7/8] Processing: test_007 - Health App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:54:57,976 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:57,990 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:54:58,631 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:58,634 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:54:58,652 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Health App\n",
      "Title: Medication Reminder\n",
      "Body: Time to take your daily medication.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:54:59,251 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:54:59,262 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:54:59,265 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:54:59,366 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.580272068428986 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'model': 'gemini-2.0-flash-exp', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}.\n",
      "2025-12-02 02:55:01,974 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:55:01,982 - FocusFilter - INFO - âœ… Trace completed: trace_f01fe38f in 4672.83ms\n",
      "2025-12-02 02:55:01,992 - FocusFilter - INFO - ðŸ” Trace started: trace_6c8186e4\n",
      "2025-12-02 02:55:02,002 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:55:02,105 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.4242794893641502 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'model': 'gemini-2.0-flash-exp', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: URGENT, Action: display_urgent\n",
      "[8/8] Processing: test_008 - News App\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:55:04,456 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:55:04,478 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:55:04,612 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.066343074263127 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '55s'}]}}.\n",
      "2025-12-02 02:55:05,805 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.014774643279715 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}.\n",
      "2025-12-02 02:55:12,912 - google_genai._api_client - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.937624359261136 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_requests_per_model', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel', 'quotaDimensions': {'model': 'gemini-2.0-flash-exp', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '47s'}]}}.\n",
      "2025-12-02 02:56:03,627 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:56:03,631 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:56:03,654 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Sunny skies expected today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:56:04,292 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:56:04,315 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:56:04,319 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-02 02:56:05,892 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:56:05,894 - FocusFilter - INFO - âœ… Trace completed: trace_6c8186e4 in 63902.58ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Completed - Classification: LESS_URGENT, Action: save_memory\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š EVALUATION REPORT\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Overall Metrics:\n",
      "   Total Tests: 8\n",
      "   Overall Score: 91.25%\n",
      "\n",
      "ðŸ·ï¸  Classification Metrics:\n",
      "   Accuracy: 87.50% (7/8)\n",
      "   Average Score: 90.00%\n",
      "\n",
      "âš¡ Action Metrics:\n",
      "   Accuracy: 87.50% (7/8)\n",
      "   Average Score: 90.00%\n",
      "\n",
      "ðŸ’¾ Memory Extraction Quality:\n",
      "   Average Score: 100.00%\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "ðŸ“‹ Individual Test Results:\n",
      "\n",
      "âœ… test_001:\n",
      "   Expected: URGENT â†’ display_urgent\n",
      "   Actual: URGENT â†’ display_urgent\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as URGENT and chose the appropriate action (display_...\n",
      "\n",
      "âœ… test_002:\n",
      "   Expected: IRRELEVANT â†’ block\n",
      "   Actual: IRRELEVANT â†’ block\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as IRRELEVANT and chose the appropriate action 'bloc...\n",
      "\n",
      "âœ… test_003:\n",
      "   Expected: LESS_URGENT â†’ save_memory\n",
      "   Actual: LESS_URGENT â†’ save_memory\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent's classification and action perfectly match the expected behavior. The extracted fact is a...\n",
      "\n",
      "âœ… test_004:\n",
      "   Expected: URGENT â†’ display_urgent\n",
      "   Actual: URGENT â†’ display_urgent\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the email as URGENT and took the appropriate action of displaying it ...\n",
      "\n",
      "âœ… test_005:\n",
      "   Expected: IRRELEVANT â†’ block\n",
      "   Actual: IRRELEVANT â†’ block\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as irrelevant and chose the appropriate action (bloc...\n",
      "\n",
      "âœ… test_006:\n",
      "   Expected: LESS_URGENT â†’ save_memory\n",
      "   Actual: LESS_URGENT â†’ save_memory\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as LESS_URGENT and chose the corresponding action sa...\n",
      "\n",
      "âœ… test_007:\n",
      "   Expected: URGENT â†’ display_urgent\n",
      "   Actual: URGENT â†’ display_urgent\n",
      "   Score: 100.00%\n",
      "   Reasoning: The agent correctly classified the notification as URGENT and chose the appropriate action (display_...\n",
      "\n",
      "âŒ test_008:\n",
      "   Expected: IRRELEVANT â†’ block\n",
      "   Actual: LESS_URGENT â†’ save_memory\n",
      "   Score: 30.00%\n",
      "   Reasoning: The classification should have been 'IRRELEVANT' because it is a generic weather update. The action ...\n",
      "\n",
      "\n",
      "âœ… Evaluation complete!\n",
      "\n",
      "Access results via: evaluation_results['results'] and evaluation_results['metrics']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Run Agent Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "# Run the full evaluation suite\n",
    "evaluation_results = await evaluation_framework.run_evaluation()\n",
    "\n",
    "# The evaluation framework will:\n",
    "# 1. Process each test case through the multi-agent system\n",
    "# 2. Evaluate results using LLM-as-judge\n",
    "# 3. Calculate comprehensive metrics\n",
    "# 4. Print a detailed report\n",
    "\n",
    "print(\"\\nâœ… Evaluation complete!\")\n",
    "print(\"\\nAccess results via: evaluation_results['results'] and evaluation_results['metrics']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "This implementation demonstrates:\n",
    "\n",
    "1. **Multi-Agent System**: Sequential agents (Classification â†’ Action â†’ Memory)\n",
    "   - **Classification Agent**: Analyzes and classifies notifications\n",
    "   - **Action Agent**: Executes actions based on classification\n",
    "   - **Memory Agent**: Handles memory extraction and consolidation\n",
    "2. **Custom Tools**: Three tools for notification management (display, block, save)\n",
    "3. **Memory Management**: Simple in-memory storage (can be extended to vector DB)\n",
    "4. **Orchestration Layer**: Coordinates sequential agent flow\n",
    "5. **Agentic Loop**: Get Mission â†’ Think â†’ Act â†’ Observe pattern\n",
    "\n",
    "## Multi-Agent Flow\n",
    "\n",
    "```\n",
    "Notification Input\n",
    "    â†“\n",
    "[Classification Agent] â†’ Classifies as URGENT/IRRELEVANT/LESS_URGENT\n",
    "    â†“\n",
    "[Action Agent] â†’ Executes appropriate action (display/block/save)\n",
    "    â†“\n",
    "[Memory Agent] â†’ (Optional) Refines memory extraction for LESS_URGENT items\n",
    "    â†“\n",
    "Result\n",
    "```\n",
    "\n",
    "## Next Steps for Full Implementation\n",
    "\n",
    "- âœ… Multi-agent architecture (COMPLETE)\n",
    "- Add vector database for semantic memory search\n",
    "- Add context engineering with few-shot examples\n",
    "- Implement full observability with tracing\n",
    "- Add agent evaluation framework with LLM-as-judge\n",
    "- Add user preference learning\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

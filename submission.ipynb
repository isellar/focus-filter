{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this for Kaggle setup with the Google API Key in the secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GOOGLE_API_KEY found in environment variables\n",
      "âœ… Setup complete - GOOGLE_API_KEY is set (length: 39)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load API key from multiple sources\n",
    "api_key_loaded = False\n",
    "\n",
    "# Method 1: Check if already set in environment\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    print(\"âœ… GOOGLE_API_KEY found in environment variables\")\n",
    "    api_key_loaded = True\n",
    "\n",
    "# Method 2: Try Kaggle secrets (if running in Kaggle)\n",
    "if not api_key_loaded:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "        print(\"âœ… Loaded GOOGLE_API_KEY from Kaggle secrets\")\n",
    "        api_key_loaded = True\n",
    "    except ImportError:\n",
    "        pass  # Not in Kaggle environment\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not load from Kaggle secrets: {e}\")\n",
    "\n",
    "# Method 3: Try .env file (for local development)\n",
    "if not api_key_loaded:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        env_path = Path('.') / '.env'\n",
    "        if env_path.exists():\n",
    "            load_dotenv(env_path)\n",
    "            if \"GOOGLE_API_KEY\" in os.environ:\n",
    "                print(\"âœ… Loaded GOOGLE_API_KEY from .env file\")\n",
    "                api_key_loaded = True\n",
    "            else:\n",
    "                print(\"âš ï¸  .env file exists but GOOGLE_API_KEY not found in it\")\n",
    "        else:\n",
    "            print(\"âš ï¸  .env file not found\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  python-dotenv not installed (optional for local development)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error loading .env: {e}\")\n",
    "\n",
    "# Final check\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    key_length = len(os.environ['GOOGLE_API_KEY'])\n",
    "    print(f\"âœ… Setup complete - GOOGLE_API_KEY is set (length: {key_length})\")\n",
    "else:\n",
    "    print(\"âŒ GOOGLE_API_KEY is required but not found.\")\n",
    "    print(\"   Please set it using one of these methods:\")\n",
    "    print(\"   1. Kaggle: Add 'GOOGLE_API_KEY' to your Kaggle secrets\")\n",
    "    print(\"   2. Local: Create a .env file with: GOOGLE_API_KEY=your_key_here\")\n",
    "    print(\"   3. Environment: Set GOOGLE_API_KEY as an environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n",
      "âœ… Async support enabled for Jupyter notebooks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.agents.remote_a2a_agent import (\n",
    "    RemoteA2aAgent,\n",
    "    AGENT_CARD_WELL_KNOWN_PATH,\n",
    ")\n",
    "\n",
    "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# Hide additional warnings in the notebook\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable nested event loops for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")\n",
    "print(\"âœ… Async support enabled for Jupyter notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus Filter - Intelligent Notification Filtering Agent\n",
    "\n",
    "This notebook implements a **multi-agent system** that intelligently filters and manages notifications by:\n",
    "- Classifying notifications as urgent, irrelevant, or less urgent\n",
    "- Taking appropriate actions (pass through, block, or store in memory)\n",
    "- Learning from patterns to improve over time\n",
    "\n",
    "## Contest Track: Concierge\n",
    "## Key Concepts Demonstrated:\n",
    "1. **Multi-agent system** (sequential agents: Classification â†’ Action â†’ Memory)\n",
    "2. **Custom tools** for notification management\n",
    "3. **Sessions & Memory** (long-term memory storage)\n",
    "4. **Observability** (logging and tracing)\n",
    "5. **Agent evaluation** (LLM-as-judge)\n",
    "\n",
    "## Multi-Agent Architecture\n",
    "\n",
    "This implementation uses a **sequential multi-agent system** with three specialized agents:\n",
    "\n",
    "1. **Classification Agent**: Analyzes notifications and determines urgency category\n",
    "2. **Action Agent**: Executes appropriate actions based on classification results\n",
    "3. **Memory Agent**: Handles memory extraction, consolidation, and storage\n",
    "\n",
    "The agents work sequentially: Classification â†’ Action â†’ Memory (when needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Notification and Memory classes initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Notification Data Structure and Memory Management\n",
    "# ============================================================================\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Notification:\n",
    "    \"\"\"Represents a notification from an app or service\"\"\"\n",
    "    id: str\n",
    "    app: str\n",
    "    title: str\n",
    "    body: str\n",
    "    timestamp: str\n",
    "    category: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"app\": self.app,\n",
    "            \"title\": self.title,\n",
    "            \"body\": self.body,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"category\": self.category\n",
    "        }\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"[{self.app}] {self.title}: {self.body}\"\n",
    "\n",
    "# Simple in-memory storage for demonstration\n",
    "class NotificationMemory:\n",
    "    \"\"\"Simple memory store for less urgent notifications\"\"\"\n",
    "    def __init__(self):\n",
    "        self.memories: List[Dict] = []\n",
    "    \n",
    "    def store(self, notification: Notification, extracted_fact: str):\n",
    "        \"\"\"Store a notification fact in memory\"\"\"\n",
    "        memory = {\n",
    "            \"notification_id\": notification.id,\n",
    "            \"app\": notification.app,\n",
    "            \"extracted_fact\": extracted_fact,\n",
    "            \"timestamp\": notification.timestamp,\n",
    "            \"stored_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.memories.append(memory)\n",
    "        print(f\"ðŸ’¾ Stored memory: {extracted_fact}\")\n",
    "        return memory\n",
    "    \n",
    "    def get_all(self) -> List[Dict]:\n",
    "        \"\"\"Retrieve all stored memories\"\"\"\n",
    "        return self.memories\n",
    "    \n",
    "    def search(self, query: str) -> List[Dict]:\n",
    "        \"\"\"Simple keyword search (would use vector DB in production)\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        return [\n",
    "            m for m in self.memories\n",
    "            if query_lower in m[\"extracted_fact\"].lower() or \n",
    "               query_lower in m[\"app\"].lower()\n",
    "        ]\n",
    "\n",
    "# Initialize memory store\n",
    "memory_store = NotificationMemory()\n",
    "print(\"âœ… Notification and Memory classes initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced memory management initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3 & 4: Enhanced Memory Management\n",
    "# ============================================================================\n",
    "# This cell enhances the NotificationMemory class with advanced features:\n",
    "# - User preferences\n",
    "# - Memory consolidation\n",
    "# - Context compaction\n",
    "# - Pattern learning\n",
    "\n",
    "# Initialize enhanced attributes on the memory store\n",
    "memory_store.user_preferences = {\n",
    "    \"always_urgent_apps\": [],\n",
    "    \"always_block_apps\": [],\n",
    "    \"preferred_categories\": [],\n",
    "    \"blocked_keywords\": []\n",
    "}\n",
    "memory_store.consolidation_threshold = 0.8\n",
    "\n",
    "# Add enhanced methods to NotificationMemory\n",
    "def _find_similar_memory(self, fact: str) -> Optional[Dict]:\n",
    "    \"\"\"Find similar memories to avoid duplicates\"\"\"\n",
    "    fact_lower = fact.lower()\n",
    "    fact_words = set(fact_lower.split())\n",
    "    \n",
    "    for memory in self.memories:\n",
    "        existing_fact = memory[\"extracted_fact\"].lower()\n",
    "        existing_words = set(existing_fact.split())\n",
    "        \n",
    "        # Calculate simple similarity (Jaccard similarity)\n",
    "        intersection = len(fact_words & existing_words)\n",
    "        union = len(fact_words | existing_words)\n",
    "        similarity = intersection / union if union > 0 else 0\n",
    "        \n",
    "        if similarity >= self.consolidation_threshold:\n",
    "            return memory\n",
    "    \n",
    "    return None\n",
    "\n",
    "def _merge_memories(self, memories: List[Dict]) -> Dict:\n",
    "    \"\"\"Merge multiple similar memories into one\"\"\"\n",
    "    base = max(memories, key=lambda m: datetime.fromisoformat(m.get(\"last_updated\", m[\"stored_at\"])))\n",
    "    total_count = sum(m.get(\"occurrence_count\", 1) for m in memories)\n",
    "    base[\"occurrence_count\"] = total_count\n",
    "    base[\"merged_from\"] = len(memories)\n",
    "    return base\n",
    "\n",
    "def consolidate_memories(self):\n",
    "    \"\"\"Consolidate and merge similar memories\"\"\"\n",
    "    consolidated = []\n",
    "    processed = set()\n",
    "    \n",
    "    for i, memory in enumerate(self.memories):\n",
    "        if i in processed:\n",
    "            continue\n",
    "        \n",
    "        similar_group = [memory]\n",
    "        for j, other_memory in enumerate(self.memories[i+1:], start=i+1):\n",
    "            if j in processed:\n",
    "                continue\n",
    "            if self._find_similar_memory(other_memory[\"extracted_fact\"]) == memory:\n",
    "                similar_group.append(other_memory)\n",
    "                processed.add(j)\n",
    "        \n",
    "        if len(similar_group) > 1:\n",
    "            merged = self._merge_memories(similar_group)\n",
    "            consolidated.append(merged)\n",
    "            print(f\"ðŸ”— Consolidated {len(similar_group)} similar memories\")\n",
    "        else:\n",
    "            consolidated.append(memory)\n",
    "        \n",
    "        processed.add(i)\n",
    "    \n",
    "    self.memories = consolidated\n",
    "    return len(consolidated)\n",
    "\n",
    "def get_user_preferences(self) -> Dict:\n",
    "    \"\"\"Get user preferences for notification filtering\"\"\"\n",
    "    return self.user_preferences.copy()\n",
    "\n",
    "def update_preference(self, preference_type: str, value: str, action: str = \"add\"):\n",
    "    \"\"\"Update user preferences (add or remove)\"\"\"\n",
    "    if preference_type not in self.user_preferences:\n",
    "        return {\"status\": \"error\", \"message\": f\"Unknown preference type: {preference_type}\"}\n",
    "    \n",
    "    if action == \"add\":\n",
    "        if value not in self.user_preferences[preference_type]:\n",
    "            self.user_preferences[preference_type].append(value)\n",
    "            print(f\"âœ… Added preference: {preference_type} = {value}\")\n",
    "    elif action == \"remove\":\n",
    "        if value in self.user_preferences[preference_type]:\n",
    "            self.user_preferences[preference_type].remove(value)\n",
    "            print(f\"âœ… Removed preference: {preference_type} = {value}\")\n",
    "    \n",
    "    return {\"status\": \"success\", \"preferences\": self.user_preferences.copy()}\n",
    "\n",
    "def learn_from_patterns(self, classification_history: List[Dict]):\n",
    "    \"\"\"Learn user preferences from classification patterns\"\"\"\n",
    "    app_classifications = {}\n",
    "    \n",
    "    for entry in classification_history:\n",
    "        app = entry.get(\"app\", \"\")\n",
    "        classification = entry.get(\"classification\", \"\")\n",
    "        \n",
    "        if app not in app_classifications:\n",
    "            app_classifications[app] = {\"URGENT\": 0, \"IRRELEVANT\": 0, \"LESS_URGENT\": 0}\n",
    "        \n",
    "        app_classifications[app][classification] = app_classifications[app].get(classification, 0) + 1\n",
    "    \n",
    "    # Auto-update preferences based on patterns\n",
    "    for app, counts in app_classifications.items():\n",
    "        total = sum(counts.values())\n",
    "        if total >= 3:\n",
    "            urgent_ratio = counts[\"URGENT\"] / total\n",
    "            irrelevant_ratio = counts[\"IRRELEVANT\"] / total\n",
    "            \n",
    "            if urgent_ratio >= 0.8 and app not in self.user_preferences[\"always_urgent_apps\"]:\n",
    "                self.update_preference(\"always_urgent_apps\", app, \"add\")\n",
    "            elif irrelevant_ratio >= 0.8 and app not in self.user_preferences[\"always_block_apps\"]:\n",
    "                self.update_preference(\"always_block_apps\", app, \"add\")\n",
    "\n",
    "def compact_context(self, max_memories: int = 10) -> List[Dict]:\n",
    "    \"\"\"Compact context by returning most relevant memories\"\"\"\n",
    "    sorted_memories = sorted(\n",
    "        self.memories,\n",
    "        key=lambda m: (\n",
    "            datetime.fromisoformat(m.get(\"last_updated\", m[\"stored_at\"])),\n",
    "            m.get(\"occurrence_count\", 1)\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "    return sorted_memories[:max_memories]\n",
    "\n",
    "# Add methods to NotificationMemory class\n",
    "NotificationMemory._find_similar_memory = _find_similar_memory\n",
    "NotificationMemory._merge_memories = _merge_memories\n",
    "NotificationMemory.consolidate_memories = consolidate_memories\n",
    "NotificationMemory.get_user_preferences = get_user_preferences\n",
    "NotificationMemory.update_preference = update_preference\n",
    "NotificationMemory.learn_from_patterns = learn_from_patterns\n",
    "NotificationMemory.compact_context = compact_context\n",
    "\n",
    "# Enhanced store method with deduplication\n",
    "original_store = NotificationMemory.store\n",
    "def enhanced_store(self, notification: Notification, extracted_fact: str):\n",
    "    \"\"\"Store with deduplication\"\"\"\n",
    "    similar_memory = self._find_similar_memory(extracted_fact)\n",
    "    \n",
    "    if similar_memory:\n",
    "        similar_memory[\"last_updated\"] = datetime.now().isoformat()\n",
    "        similar_memory[\"occurrence_count\"] = similar_memory.get(\"occurrence_count\", 1) + 1\n",
    "        print(f\"ðŸ’¾ Updated existing memory: {extracted_fact} (count: {similar_memory['occurrence_count']})\")\n",
    "        return similar_memory\n",
    "    \n",
    "    memory = original_store(self, notification, extracted_fact)\n",
    "    memory[\"last_updated\"] = datetime.now().isoformat()\n",
    "    memory[\"occurrence_count\"] = 1\n",
    "    return memory\n",
    "\n",
    "NotificationMemory.store = enhanced_store\n",
    "\n",
    "print(\"âœ… Enhanced memory management initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced tools ready:\n",
      "   â€¢ retrieve_user_preferences() - Access user preferences\n",
      "   â€¢ Tool validation framework available\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Enhanced Tools - retrieve_user_preferences and Validation\n",
    "# ============================================================================\n",
    "\n",
    "def retrieve_user_preferences() -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve user preferences for notification filtering.\n",
    "    This tool allows agents to access learned user preferences to make better decisions.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with user preferences including:\n",
    "        - always_urgent_apps: Apps that should always be treated as urgent\n",
    "        - always_block_apps: Apps that should always be blocked\n",
    "        - preferred_categories: Categories the user cares about\n",
    "        - blocked_keywords: Keywords that indicate blocking\n",
    "        \n",
    "        Success: {\"status\": \"success\", \"preferences\": {...}}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preferences = memory_store.get_user_preferences()\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"preferences\": preferences,\n",
    "            \"message\": \"User preferences retrieved successfully\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": f\"Failed to retrieve preferences: {e}\"\n",
    "        }\n",
    "\n",
    "# Enhanced tool validation wrapper\n",
    "def validate_tool_input(func):\n",
    "    \"\"\"Decorator to validate tool inputs and handle errors\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            # Basic validation\n",
    "            if not args and not kwargs:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error_message\": \"No arguments provided\"\n",
    "                }\n",
    "            \n",
    "            # Call the original function\n",
    "            result = func(*args, **kwargs)\n",
    "            \n",
    "            # Validate result format\n",
    "            if not isinstance(result, dict):\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error_message\": \"Tool did not return a dictionary\"\n",
    "                }\n",
    "            \n",
    "            if \"status\" not in result:\n",
    "                result[\"status\"] = \"success\"\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except TypeError as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Invalid arguments: {e}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Tool execution error: {e}\"\n",
    "            }\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "# Apply validation to existing tools (optional - for demonstration)\n",
    "# In production, you'd wrap the tools before passing to agents\n",
    "\n",
    "print(\"âœ… Enhanced tools ready:\")\n",
    "print(\"   â€¢ retrieve_user_preferences() - Access user preferences\")\n",
    "print(\"   â€¢ Tool validation framework available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Custom tools defined\n"
     ]
    }
   ],
   "source": [
    "# Custom Tools for Notification Management\n",
    "\n",
    "def display_urgent_notification(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Display an urgent notification to the user immediately.\n",
    "    This tool is called when a notification requires immediate attention.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Notification displayed\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸš¨ URGENT NOTIFICATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"App: {app}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Body: {body}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    return {\"status\": \"success\", \"message\": f\"Urgent notification from {app} displayed to user\"}\n",
    "\n",
    "def block_notification(app: str, title: str, reason: str) -> dict:\n",
    "    \"\"\"\n",
    "    Block/suppress an irrelevant notification.\n",
    "    This tool is called when a notification is determined to be noise.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        reason: The reason for blocking (e.g., \"social media noise\", \"promotional content\")\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Notification blocked\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    print(f\"ðŸš« Blocked: [{app}] {title} - {reason}\")\n",
    "    return {\"status\": \"success\", \"message\": f\"Notification from {app} blocked: {reason}\"}\n",
    "\n",
    "def save_notification_memory(app: str, title: str, body: str, extracted_fact: str) -> dict:\n",
    "    \"\"\"\n",
    "    Save a less urgent notification as a memory for later review.\n",
    "    This tool extracts key information and stores it for future reference.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        extracted_fact: The key fact or information extracted from the notification\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and result information.\n",
    "        Success: {\"status\": \"success\", \"message\": \"Memory stored\"}\n",
    "        Error: {\"status\": \"error\", \"error_message\": \"...\"}\n",
    "    \"\"\"\n",
    "    # Create a temporary notification object for storage\n",
    "    temp_notification = Notification(\n",
    "        id=str(uuid.uuid4()),\n",
    "        app=app,\n",
    "        title=title,\n",
    "        body=body,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )\n",
    "    memory_store.store(temp_notification, extracted_fact)\n",
    "    return {\"status\": \"success\", \"message\": f\"Memory stored: {extracted_fact}\"}\n",
    "\n",
    "print(\"âœ… Custom tools defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent system created:\n",
      "  â€¢ Classification Agent - Analyzes and classifies notifications\n",
      "  â€¢ Action Agent - Executes actions based on classification\n",
      "  â€¢ Memory Agent - Handles memory extraction and consolidation\n",
      "âœ… Agents updated with enhanced tools\n",
      "   â€¢ Classification Agent can now check user preferences\n",
      "   â€¢ Action Agent can now check user preferences\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT ARCHITECTURE: Sequential Agent System\n",
    "# ============================================================================\n",
    "# This demonstrates a multi-agent system with three specialized agents:\n",
    "# 1. Classification Agent: Analyzes and classifies notifications\n",
    "# 2. Action Agent: Executes actions based on classification\n",
    "# 3. Memory Agent: Handles memory extraction and storage\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 1: Classification Agent\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent's sole responsibility is to analyze notifications and determine\n",
    "# their urgency category. It does NOT take actions, only classifies.\n",
    "\n",
    "def classify_notification(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Classify a notification into one of three categories: URGENT, IRRELEVANT, or LESS_URGENT.\n",
    "    This tool is used by the Classification Agent to output its decision.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with classification result.\n",
    "    \"\"\"\n",
    "    # This is a tool that the classification agent will call to output its decision\n",
    "    # The actual classification logic is in the agent's reasoning\n",
    "    pass  # Placeholder - agent will call this with classification result\n",
    "\n",
    "classification_agent = LlmAgent(\n",
    "    name=\"classification_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a Classification Agent in the Focus Filter system.\n",
    "\n",
    "Your ONLY job is to analyze notifications and classify them into one of three categories:\n",
    "\n",
    "1. **URGENT**: Requires immediate attention or action\n",
    "   - Security alerts (bank, account access)\n",
    "   - Critical deadlines or time-sensitive tasks\n",
    "   - Emergency communications\n",
    "   - Important personal messages requiring immediate response\n",
    "\n",
    "2. **IRRELEVANT**: Noise that should be blocked\n",
    "   - Social media likes, follows, generic updates\n",
    "   - Marketing/promotional content\n",
    "   - Low-value informational updates\n",
    "   - Spam or unwanted notifications\n",
    "\n",
    "3. **LESS_URGENT**: Important but not immediate - should be stored in memory\n",
    "   - Project updates, deadline changes\n",
    "   - Informational updates worth remembering\n",
    "   - Non-critical but useful information\n",
    "   - Things the user might want to reference later\n",
    "\n",
    "When you receive a notification, analyze the app, title, and body text, then respond with:\n",
    "- The classification (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- A brief reasoning for your decision\n",
    "- If LESS_URGENT, also provide the key fact or information that should be extracted\n",
    "\n",
    "Format your response as:\n",
    "Classification: [URGENT/IRRELEVANT/LESS_URGENT]\n",
    "Reasoning: [your reasoning]\n",
    "Key Fact (if LESS_URGENT): [extracted fact]\n",
    "\n",
    "Be conservative with URGENT - only use it for truly time-sensitive or critical items.\"\"\",\n",
    "    tools=[],  # Classification agent doesn't take actions, only classifies\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 2: Action Agent\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent receives classification results and executes the appropriate action\n",
    "\n",
    "action_agent = LlmAgent(\n",
    "    name=\"action_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an Action Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to execute actions based on classification results from the Classification Agent.\n",
    "\n",
    "You will receive:\n",
    "- The notification details (app, title, body)\n",
    "- The classification result (URGENT, IRRELEVANT, or LESS_URGENT)\n",
    "- Any additional context (like extracted facts for LESS_URGENT items)\n",
    "\n",
    "Based on the classification, you must:\n",
    "1. For URGENT: Call `display_urgent_notification(app, title, body)`\n",
    "2. For IRRELEVANT: Call `block_notification(app, title, reason)` with a clear reason\n",
    "3. For LESS_URGENT: Call `save_notification_memory(app, title, body, extracted_fact)` with the key fact\n",
    "\n",
    "Execute the appropriate action immediately based on the classification provided.\"\"\",\n",
    "    tools=[\n",
    "        display_urgent_notification,\n",
    "        block_notification,\n",
    "        save_notification_memory,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Agent 3: Memory Agent (for advanced memory operations)\n",
    "# ----------------------------------------------------------------------------\n",
    "# This agent handles memory extraction, consolidation, and retrieval\n",
    "\n",
    "def extract_memory_fact(app: str, title: str, body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the key fact or information from a notification for memory storage.\n",
    "    This tool is used by the Memory Agent to extract structured information.\n",
    "    \n",
    "    Args:\n",
    "        app: The name of the app sending the notification\n",
    "        title: The notification title\n",
    "        body: The notification body text\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted fact.\n",
    "    \"\"\"\n",
    "    # This tool allows the memory agent to output extracted facts\n",
    "    pass  # Placeholder - agent will call this with extracted fact\n",
    "\n",
    "memory_agent = LlmAgent(\n",
    "    name=\"memory_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-exp\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a Memory Agent in the Focus Filter system.\n",
    "\n",
    "Your job is to extract, consolidate, and manage memories from notifications.\n",
    "\n",
    "When you receive a LESS_URGENT notification:\n",
    "1. Extract the most important fact or piece of information\n",
    "2. Format it as a concise, searchable memory\n",
    "3. Ensure it's useful for future reference\n",
    "\n",
    "For example:\n",
    "- \"Project deadline moved to Tuesday\" (not \"Your project deadline has moved to Tuesday\")\n",
    "- \"New team member joined: Alice\" (not the full notification text)\n",
    "\n",
    "Focus on extracting actionable, referenceable facts that the user might want to recall later.\"\"\",\n",
    "    tools=[],  # Memory agent primarily extracts facts (can be extended with retrieval tools)\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-agent system created:\")\n",
    "print(\"  â€¢ Classification Agent - Analyzes and classifies notifications\")\n",
    "print(\"  â€¢ Action Agent - Executes actions based on classification\")\n",
    "print(\"  â€¢ Memory Agent - Handles memory extraction and consolidation\")\n",
    "\n",
    "# Update agents to include retrieve_user_preferences tool\n",
    "# Add the tool to classification and action agents\n",
    "if retrieve_user_preferences not in classification_agent.tools:\n",
    "    classification_agent.tools.append(retrieve_user_preferences)\n",
    "\n",
    "if retrieve_user_preferences not in action_agent.tools:\n",
    "    action_agent.tools.append(retrieve_user_preferences)\n",
    "\n",
    "print(\"âœ… Agents updated with enhanced tools\")\n",
    "print(\"   â€¢ Classification Agent can now check user preferences\")\n",
    "print(\"   â€¢ Action Agent can now check user preferences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Observability system initialized\n",
      "   â€¢ Structured logging enabled\n",
      "   â€¢ Trace capture ready\n",
      "   â€¢ Metrics collection active\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OBSERVABILITY: Logging, Tracing, and Metrics\n",
    "# ============================================================================\n",
    "# This module provides comprehensive observability for the multi-agent system\n",
    "\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "\n",
    "# Configure structured logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"FocusFilter\")\n",
    "\n",
    "class ObservabilityManager:\n",
    "    \"\"\"Manages logging, tracing, and metrics for the multi-agent system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.traces: List[Dict] = []\n",
    "        self.metrics = {\n",
    "            \"total_notifications\": 0,\n",
    "            \"classifications\": defaultdict(int),\n",
    "            \"actions\": defaultdict(int),\n",
    "            \"agent_timings\": defaultdict(list),\n",
    "            \"errors\": []\n",
    "        }\n",
    "        self.current_trace: Optional[Dict] = None\n",
    "    \n",
    "    def start_trace(self, notification_id: str, notification_text: str):\n",
    "        \"\"\"Start a new trace for a notification processing session\"\"\"\n",
    "        self.current_trace = {\n",
    "            \"trace_id\": f\"trace_{uuid.uuid4().hex[:8]}\",\n",
    "            \"notification_id\": notification_id,\n",
    "            \"notification_text\": notification_text,\n",
    "            \"start_time\": datetime.now().isoformat(),\n",
    "            \"agents\": [],\n",
    "            \"classification\": None,\n",
    "            \"action\": None,\n",
    "            \"memory_operation\": None,\n",
    "            \"end_time\": None,\n",
    "            \"duration_ms\": None,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        logger.info(f\"ðŸ” Trace started: {self.current_trace['trace_id']}\")\n",
    "    \n",
    "    def log_agent_step(self, agent_name: str, step: str, input_data: Dict, output_data: Dict, duration_ms: float):\n",
    "        \"\"\"Log an agent step in the current trace\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        agent_step = {\n",
    "            \"agent\": agent_name,\n",
    "            \"step\": step,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"input\": input_data,\n",
    "            \"output\": output_data,\n",
    "            \"duration_ms\": duration_ms\n",
    "        }\n",
    "        self.current_trace[\"agents\"].append(agent_step)\n",
    "        self.metrics[\"agent_timings\"][f\"{agent_name}_{step}\"].append(duration_ms)\n",
    "        \n",
    "        logger.info(f\"ðŸ“Š {agent_name} - {step} completed in {duration_ms:.2f}ms\")\n",
    "    \n",
    "    def log_classification(self, classification: str, reasoning: str, confidence: Optional[float] = None):\n",
    "        \"\"\"Log classification result\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"classification\"] = {\n",
    "            \"result\": classification,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"confidence\": confidence,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"classifications\"][classification] += 1\n",
    "        \n",
    "        logger.info(f\"ðŸ·ï¸  Classification: {classification} - {reasoning[:100]}\")\n",
    "    \n",
    "    def log_action(self, action_type: str, action_details: Dict):\n",
    "        \"\"\"Log action execution\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"action\"] = {\n",
    "            \"type\": action_type,\n",
    "            \"details\": action_details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"actions\"][action_type] += 1\n",
    "        \n",
    "        logger.info(f\"âš¡ Action: {action_type} - {json.dumps(action_details, default=str)}\")\n",
    "    \n",
    "    def log_memory_operation(self, operation: str, details: Dict):\n",
    "        \"\"\"Log memory operation\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        self.current_trace[\"memory_operation\"] = {\n",
    "            \"operation\": operation,\n",
    "            \"details\": details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"ðŸ’¾ Memory: {operation} - {json.dumps(details, default=str)}\")\n",
    "    \n",
    "    def log_error(self, error_type: str, error_message: str, context: Optional[Dict] = None):\n",
    "        \"\"\"Log an error\"\"\"\n",
    "        error_entry = {\n",
    "            \"type\": error_type,\n",
    "            \"message\": error_message,\n",
    "            \"context\": context or {},\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.metrics[\"errors\"].append(error_entry)\n",
    "        \n",
    "        if self.current_trace:\n",
    "            self.current_trace[\"errors\"].append(error_entry)\n",
    "        \n",
    "        logger.error(f\"âŒ Error [{error_type}]: {error_message}\")\n",
    "    \n",
    "    def end_trace(self):\n",
    "        \"\"\"End the current trace and store it\"\"\"\n",
    "        if self.current_trace is None:\n",
    "            return\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        start_time = datetime.fromisoformat(self.current_trace[\"start_time\"])\n",
    "        duration_ms = (end_time - start_time).total_seconds() * 1000\n",
    "        \n",
    "        self.current_trace[\"end_time\"] = end_time.isoformat()\n",
    "        self.current_trace[\"duration_ms\"] = duration_ms\n",
    "        \n",
    "        self.traces.append(self.current_trace.copy())\n",
    "        self.metrics[\"total_notifications\"] += 1\n",
    "        \n",
    "        logger.info(f\"âœ… Trace completed: {self.current_trace['trace_id']} in {duration_ms:.2f}ms\")\n",
    "        self.current_trace = None\n",
    "    \n",
    "    def get_metrics_summary(self) -> Dict:\n",
    "        \"\"\"Get a summary of all metrics\"\"\"\n",
    "        avg_timings = {}\n",
    "        for key, timings in self.metrics[\"agent_timings\"].items():\n",
    "            if timings:\n",
    "                avg_timings[key] = {\n",
    "                    \"avg_ms\": sum(timings) / len(timings),\n",
    "                    \"min_ms\": min(timings),\n",
    "                    \"max_ms\": max(timings),\n",
    "                    \"count\": len(timings)\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            \"total_notifications\": self.metrics[\"total_notifications\"],\n",
    "            \"classifications\": dict(self.metrics[\"classifications\"]),\n",
    "            \"actions\": dict(self.metrics[\"actions\"]),\n",
    "            \"average_timings\": avg_timings,\n",
    "            \"error_count\": len(self.metrics[\"errors\"]),\n",
    "            \"total_traces\": len(self.traces)\n",
    "        }\n",
    "    \n",
    "    def get_recent_traces(self, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Get the most recent traces\"\"\"\n",
    "        return self.traces[-limit:] if self.traces else []\n",
    "    \n",
    "    def print_metrics_summary(self):\n",
    "        \"\"\"Print a formatted metrics summary\"\"\"\n",
    "        summary = self.get_metrics_summary()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“Š OBSERVABILITY METRICS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nðŸ“ˆ Total Notifications Processed: {summary['total_notifications']}\")\n",
    "        print(f\"ðŸ“ Total Traces Captured: {summary['total_traces']}\")\n",
    "        \n",
    "        print(\"\\nðŸ·ï¸  Classification Distribution:\")\n",
    "        for classification, count in summary['classifications'].items():\n",
    "            percentage = (count / summary['total_notifications'] * 100) if summary['total_notifications'] > 0 else 0\n",
    "            print(f\"   {classification}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nâš¡ Action Distribution:\")\n",
    "        for action, count in summary['actions'].items():\n",
    "            percentage = (count / summary['total_notifications'] * 100) if summary['total_notifications'] > 0 else 0\n",
    "            print(f\"   {action}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if summary['average_timings']:\n",
    "            print(\"\\nâ±ï¸  Performance Metrics:\")\n",
    "            for key, timing in summary['average_timings'].items():\n",
    "                print(f\"   {key}:\")\n",
    "                print(f\"      Average: {timing['avg_ms']:.2f}ms\")\n",
    "                print(f\"      Min: {timing['min_ms']:.2f}ms\")\n",
    "                print(f\"      Max: {timing['max_ms']:.2f}ms\")\n",
    "                print(f\"      Count: {timing['count']}\")\n",
    "        \n",
    "        if summary['error_count'] > 0:\n",
    "            print(f\"\\nâŒ Errors: {summary['error_count']}\")\n",
    "            for error in self.metrics['errors'][-5:]:  # Show last 5 errors\n",
    "                print(f\"   [{error['type']}] {error['message']}\")\n",
    "        \n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Initialize observability manager\n",
    "obs_manager = ObservabilityManager()\n",
    "\n",
    "print(\"âœ… Observability system initialized\")\n",
    "print(\"   â€¢ Structured logging enabled\")\n",
    "print(\"   â€¢ Trace capture ready\")\n",
    "print(\"   â€¢ Metrics collection active\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-agent orchestration layer initialized\n",
      "âœ… Sequential agent coordination ready\n",
      "âœ… Helper functions for async operations ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ORCHESTRATION LAYER: Sequential Agent Coordination\n",
    "# ============================================================================\n",
    "# This layer coordinates the sequential flow: Classification â†’ Action â†’ Memory\n",
    "\n",
    "# Create runners for each agent\n",
    "classification_runner = Runner(\n",
    "    app_name=\"FocusFilter_Classification\",\n",
    "    agent=classification_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "action_runner = Runner(\n",
    "    app_name=\"FocusFilter_Action\",\n",
    "    agent=action_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "memory_runner = Runner(\n",
    "    app_name=\"FocusFilter_Memory\",\n",
    "    agent=memory_agent,\n",
    "    session_service=InMemorySessionService(),\n",
    ")\n",
    "\n",
    "# Main session service for the orchestration\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "def parse_classification_result(text: str) -> dict:\n",
    "    \"\"\"Parse the classification agent's response to extract structured data\"\"\"\n",
    "    result = {\n",
    "        \"classification\": None,\n",
    "        \"reasoning\": None,\n",
    "        \"key_fact\": None\n",
    "    }\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Try to find classification - look for URGENT, IRRELEVANT, or LESS_URGENT\n",
    "    for classification in [\"URGENT\", \"IRRELEVANT\", \"LESS_URGENT\", \"LESS URGENT\"]:\n",
    "        if classification.lower() in text_lower:\n",
    "            # Check if it's in a structured format like \"Classification: URGENT\"\n",
    "            if \"classification:\" in text_lower:\n",
    "                idx = text_lower.find(\"classification:\")\n",
    "                after_colon = text[text_lower.find(\"classification:\") + len(\"classification:\"):].strip()\n",
    "                # Extract the first word or phrase after the colon\n",
    "                words = after_colon.split()\n",
    "                if words:\n",
    "                    result[\"classification\"] = words[0].upper().rstrip(\".,;\")\n",
    "                    break\n",
    "            else:\n",
    "                # Look for the classification word in context\n",
    "                result[\"classification\"] = classification.upper()\n",
    "                break\n",
    "    \n",
    "    # Extract reasoning\n",
    "    if \"reasoning:\" in text_lower:\n",
    "        idx = text_lower.find(\"reasoning:\")\n",
    "        reasoning_text = text[idx + len(\"reasoning:\"):].strip()\n",
    "        # Take up to the next section or end of text\n",
    "        next_section = min(\n",
    "            reasoning_text.find(\"\\n\\n\"),\n",
    "            reasoning_text.find(\"Key Fact\"),\n",
    "            reasoning_text.find(\"key fact\"),\n",
    "            len(reasoning_text)\n",
    "        )\n",
    "        if next_section > 0:\n",
    "            result[\"reasoning\"] = reasoning_text[:next_section].strip()\n",
    "        else:\n",
    "            result[\"reasoning\"] = reasoning_text.strip()\n",
    "    \n",
    "    # Extract key fact (for LESS_URGENT items)\n",
    "    if \"key fact\" in text_lower:\n",
    "        idx = text_lower.find(\"key fact\")\n",
    "        fact_text = text[idx + len(\"key fact\"):].strip()\n",
    "        # Remove colon if present\n",
    "        if fact_text.startswith(\":\"):\n",
    "            fact_text = fact_text[1:].strip()\n",
    "        # Take up to next line break or end\n",
    "        next_line = fact_text.find(\"\\n\")\n",
    "        if next_line > 0:\n",
    "            result[\"key_fact\"] = fact_text[:next_line].strip()\n",
    "        else:\n",
    "            result[\"key_fact\"] = fact_text.strip()\n",
    "    \n",
    "    # Fallback: if classification not found, try to infer from text\n",
    "    if result[\"classification\"] is None:\n",
    "        if any(word in text_lower for word in [\"urgent\", \"immediate\", \"critical\", \"security alert\"]):\n",
    "            result[\"classification\"] = \"URGENT\"\n",
    "        elif any(word in text_lower for word in [\"irrelevant\", \"noise\", \"block\", \"spam\"]):\n",
    "            result[\"classification\"] = \"IRRELEVANT\"\n",
    "        elif any(word in text_lower for word in [\"less urgent\", \"store\", \"memory\", \"later\"]):\n",
    "            result[\"classification\"] = \"LESS_URGENT\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "async def process_notification_multi_agent(\n",
    "    notification_text: str,\n",
    "    user_id: str = \"default\",\n",
    "    session_id: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Orchestrate the sequential multi-agent processing of a notification.\n",
    "    \n",
    "    Flow:\n",
    "    1. Classification Agent analyzes and classifies\n",
    "    2. Action Agent executes appropriate action\n",
    "    3. Memory Agent (if needed) handles memory extraction\n",
    "    \n",
    "    Args:\n",
    "        notification_text: The notification message to process\n",
    "        user_id: User identifier\n",
    "        session_id: Optional session identifier (auto-generated if None)\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    if session_id is None:\n",
    "        session_id = f\"session_{uuid.uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Start observability trace\n",
    "    notification_id = f\"notif_{uuid.uuid4().hex[:8]}\"\n",
    "    obs_manager.start_trace(notification_id, notification_text)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ” Processing notification with multi-agent system\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Step 1: Classification Agent\n",
    "    print(\"ðŸ“Š Step 1: Classification Agent analyzing...\")\n",
    "    classification_start = time.time()\n",
    "    classification_result_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        session = await classification_runner.session_service.create_session(\n",
    "            app_name=classification_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_classify\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"session_creation\", f\"Failed to create classification session: {e}\")\n",
    "        session = await classification_runner.session_service.get_session(\n",
    "            app_name=classification_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_classify\"\n",
    "        )\n",
    "    \n",
    "    message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=notification_text)]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        async for event in classification_runner.run_async(\n",
    "            user_id=user_id,\n",
    "            session_id=session.id,\n",
    "            new_message=message\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                if event.content.parts[0].text:\n",
    "                    classification_result_text += event.content.parts[0].text\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"classification_error\", f\"Classification agent error: {e}\", {\"session_id\": session_id})\n",
    "        raise\n",
    "    \n",
    "    classification_duration = (time.time() - classification_start) * 1000\n",
    "    print(f\"âœ… Classification complete\")\n",
    "    print(f\"   Result: {classification_result_text[:200]}...\\n\")\n",
    "    \n",
    "    # Parse classification result\n",
    "    classification_data = parse_classification_result(classification_result_text)\n",
    "    \n",
    "    # Log classification step\n",
    "    obs_manager.log_agent_step(\n",
    "        agent_name=\"Classification Agent\",\n",
    "        step=\"classify\",\n",
    "        input_data={\"notification_text\": notification_text[:200]},\n",
    "        output_data=classification_data,\n",
    "        duration_ms=classification_duration\n",
    "    )\n",
    "    \n",
    "    # Log classification result\n",
    "    if classification_data['classification']:\n",
    "        obs_manager.log_classification(\n",
    "            classification=classification_data['classification'],\n",
    "            reasoning=classification_data.get('reasoning', 'No reasoning provided')\n",
    "        )\n",
    "    \n",
    "    # Extract notification details from input\n",
    "    # Format: \"I received a notification: App: X, Title: Y, Body: Z\"\n",
    "    app = \"Unknown\"\n",
    "    title = \"Unknown\"\n",
    "    body = \"Unknown\"\n",
    "    \n",
    "    if \"App:\" in notification_text:\n",
    "        parts = notification_text.split(\"App:\")[-1]\n",
    "        if \"Title:\" in parts:\n",
    "            app = parts.split(\"Title:\")[0].strip().rstrip(\",\")\n",
    "            title_part = parts.split(\"Title:\")[-1]\n",
    "            if \"Body:\" in title_part:\n",
    "                title = title_part.split(\"Body:\")[0].strip().rstrip(\",\")\n",
    "                body = title_part.split(\"Body:\")[-1].strip()\n",
    "    \n",
    "    # Step 2: Action Agent\n",
    "    print(\"âš¡ Step 2: Action Agent executing...\")\n",
    "    action_start = time.time()\n",
    "    \n",
    "    # Prepare action message with classification result\n",
    "    action_message_text = f\"\"\"Notification Details:\n",
    "- App: {app}\n",
    "- Title: {title}\n",
    "- Body: {body}\n",
    "\n",
    "Classification Result:\n",
    "- Classification: {classification_data['classification']}\n",
    "- Reasoning: {classification_data['reasoning']}\n",
    "{f\"- Key Fact: {classification_data['key_fact']}\" if classification_data['key_fact'] else \"\"}\n",
    "\n",
    "Please execute the appropriate action based on the classification.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        action_session = await action_runner.session_service.create_session(\n",
    "            app_name=action_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_action\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"session_creation\", f\"Failed to create action session: {e}\")\n",
    "        action_session = await action_runner.session_service.get_session(\n",
    "            app_name=action_runner.app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=f\"{session_id}_action\"\n",
    "        )\n",
    "    \n",
    "    action_message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=action_message_text)]\n",
    "    )\n",
    "    \n",
    "    action_output = \"\"\n",
    "    try:\n",
    "        async for event in action_runner.run_async(\n",
    "            user_id=user_id,\n",
    "            session_id=action_session.id,\n",
    "            new_message=action_message\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                if event.content.parts[0].text:\n",
    "                    action_output += event.content.parts[0].text\n",
    "                    print(event.content.parts[0].text)\n",
    "    except Exception as e:\n",
    "        obs_manager.log_error(\"action_error\", f\"Action agent error: {e}\", {\"session_id\": session_id})\n",
    "        raise\n",
    "    \n",
    "    action_duration = (time.time() - action_start) * 1000\n",
    "    \n",
    "    # Determine action type from output\n",
    "    action_type = \"unknown\"\n",
    "    if \"display_urgent_notification\" in action_output.lower() or \"urgent notification\" in action_output.lower():\n",
    "        action_type = \"display_urgent\"\n",
    "    elif \"block\" in action_output.lower() or \"blocked\" in action_output.lower():\n",
    "        action_type = \"block\"\n",
    "    elif \"save\" in action_output.lower() or \"memory\" in action_output.lower() or \"stored\" in action_output.lower():\n",
    "        action_type = \"save_memory\"\n",
    "    \n",
    "    # Log action step\n",
    "    obs_manager.log_agent_step(\n",
    "        agent_name=\"Action Agent\",\n",
    "        step=\"execute\",\n",
    "        input_data={\n",
    "            \"classification\": classification_data['classification'],\n",
    "            \"app\": app,\n",
    "            \"title\": title\n",
    "        },\n",
    "        output_data={\"action_type\": action_type, \"output\": action_output[:200]},\n",
    "        duration_ms=action_duration\n",
    "    )\n",
    "    \n",
    "    # Log action\n",
    "    obs_manager.log_action(\n",
    "        action_type=action_type,\n",
    "        action_details={\n",
    "            \"app\": app,\n",
    "            \"title\": title,\n",
    "            \"classification\": classification_data['classification']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Action execution complete\\n\")\n",
    "    \n",
    "    # Step 3: Memory Agent (only for LESS_URGENT items that need extraction refinement)\n",
    "    if classification_data['classification'] == 'LESS_URGENT':\n",
    "        print(\"ðŸ’¾ Step 3: Memory Agent extracting fact...\")\n",
    "        memory_start = time.time()\n",
    "        \n",
    "        # Log memory operation\n",
    "        if classification_data.get('key_fact'):\n",
    "            obs_manager.log_memory_operation(\n",
    "                operation=\"store\",\n",
    "                details={\n",
    "                    \"app\": app,\n",
    "                    \"extracted_fact\": classification_data['key_fact'],\n",
    "                    \"title\": title\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        memory_duration = (time.time() - memory_start) * 1000\n",
    "        obs_manager.log_agent_step(\n",
    "            agent_name=\"Memory Agent\",\n",
    "            step=\"extract\",\n",
    "            input_data={\"notification\": f\"{app}: {title}\"},\n",
    "            output_data={\"extracted_fact\": classification_data.get('key_fact', '')},\n",
    "            duration_ms=memory_duration\n",
    "        )\n",
    "        \n",
    "        # The action agent already stored the memory, but we can use memory agent\n",
    "        # for additional processing if needed (consolidation, deduplication, etc.)\n",
    "        # For now, we'll skip this step as the action agent handles storage\n",
    "        print(\"âœ… Memory extraction handled by Action Agent\\n\")\n",
    "    \n",
    "    # End trace\n",
    "    obs_manager.end_trace()\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"âœ… Multi-agent processing complete\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Legacy helper function for backward compatibility (uses single agent approach)\n",
    "async def run_notification_test(runner_instance, session_service, user_id, session_id, message_text):\n",
    "    \"\"\"Helper function to test notification processing (legacy single-agent)\"\"\"\n",
    "    # Create or get session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=runner_instance.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=runner_instance.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    \n",
    "    # Convert message to Content format\n",
    "    message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=message_text)]\n",
    "    )\n",
    "    \n",
    "    # Process the notification\n",
    "    async for event in runner_instance.run_async(\n",
    "        user_id=user_id, session_id=session.id, new_message=message\n",
    "    ):\n",
    "        if event.content and event.content.parts:\n",
    "            if event.content.parts[0].text:\n",
    "                print(event.content.parts[0].text)\n",
    "\n",
    "print(\"âœ… Multi-agent orchestration layer initialized\")\n",
    "print(\"âœ… Sequential agent coordination ready\")\n",
    "print(\"âœ… Helper functions for async operations ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Agent\n",
    "\n",
    "Let's test the agent with sample notifications:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:25,704 - FocusFilter - INFO - ðŸ” Trace started: trace_6e5b9790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:26,293 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:23:27,289 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:27,301 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 1594.29ms\n",
      "2025-12-02 02:23:27,306 - FocusFilter - INFO - ðŸ·ï¸  Classification: URGENT - Security alert from a banking app indicating suspicious activity requires immediate attention.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: URGENT\n",
      "Reasoning: Security alert from a banking app indicating suspicious activity requires immediate attention.\n",
      "...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:27,782 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-12-02 02:23:28,489 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:28,492 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:23:28,518 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš¨ URGENT NOTIFICATION\n",
      "============================================================\n",
      "App: Banking App\n",
      "Title: Security Alert\n",
      "Body: Your bank flagged suspicious activity on your account. Please verify immediately.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:29,101 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:29,108 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1794.68ms\n",
      "2025-12-02 02:23:29,111 - FocusFilter - INFO - âš¡ Action: display_urgent - {\"app\": \"Banking App\", \"title\": \"Security Alert\", \"classification\": \"URGENT\"}\n",
      "2025-12-02 02:23:29,116 - FocusFilter - INFO - âœ… Trace completed: trace_6e5b9790 in 3412.48ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have displayed the urgent notification.\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 1 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 1: Urgent security alert\n",
    "USER_ID = \"test\"\n",
    "\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Banking App, Title: Security Alert, Body: Your bank flagged suspicious activity on your account. Please verify immediately.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_1\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 1 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:29,162 - FocusFilter - INFO - ðŸ” Trace started: trace_6ca673f5\n",
      "2025-12-02 02:23:29,189 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:29,769 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:29,777 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 602.60ms\n",
      "2025-12-02 02:23:29,780 - FocusFilter - INFO - ðŸ·ï¸  Classification: IRRELEVANT - Social media likes are generally not important and do not require immediate action.\n",
      "2025-12-02 02:23:29,801 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: IRRELEVANT\n",
      "Reasoning: Social media likes are generally not important and do not require immediate action.\n",
      "...\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:30,459 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:30,463 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:23:30,487 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš« Blocked: [Social Media] New Like - social media noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:31,073 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:31,083 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1298.48ms\n",
      "2025-12-02 02:23:31,088 - FocusFilter - INFO - âš¡ Action: block - {\"app\": \"Social Media\", \"title\": \"New Like\", \"classification\": \"IRRELEVANT\"}\n",
      "2025-12-02 02:23:31,092 - FocusFilter - INFO - âœ… Trace completed: trace_6ca673f5 in 1929.93ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have blocked the notification from Social Media with the reason \"social media noise\".\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 2 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 2: Irrelevant social media\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_2\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 2 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š OBSERVABILITY METRICS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Total Notifications Processed: 2\n",
      "ðŸ“ Total Traces Captured: 2\n",
      "\n",
      "ðŸ·ï¸  Classification Distribution:\n",
      "   URGENT: 1 (50.0%)\n",
      "   IRRELEVANT: 1 (50.0%)\n",
      "\n",
      "âš¡ Action Distribution:\n",
      "   display_urgent: 1 (50.0%)\n",
      "   block: 1 (50.0%)\n",
      "\n",
      "â±ï¸  Performance Metrics:\n",
      "   Classification Agent_classify:\n",
      "      Average: 1098.45ms\n",
      "      Min: 602.60ms\n",
      "      Max: 1594.29ms\n",
      "      Count: 2\n",
      "   Action Agent_execute:\n",
      "      Average: 1546.58ms\n",
      "      Min: 1298.48ms\n",
      "      Max: 1794.68ms\n",
      "      Count: 2\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display observability metrics\n",
    "obs_manager.print_metrics_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” DETAILED TRACE EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "Trace ID: trace_6ca673f5\n",
      "Notification ID: notif_901edadd\n",
      "Duration: 1929.93ms\n",
      "\n",
      "Notification Text: I received a notification: App: Social Media, Title: New Like, Body: 3 new people liked your photo....\n",
      "\n",
      "ðŸ“Š Classification:\n",
      "   Result: IRRELEVANT\n",
      "   Reasoning: Social media likes are generally not important and do not require immediate action....\n",
      "\n",
      "âš¡ Action:\n",
      "   Type: block\n",
      "   Details: {'app': 'Social Media', 'title': 'New Like', 'classification': 'IRRELEVANT'}\n",
      "\n",
      "ðŸ¤– Agent Steps:\n",
      "   Classification Agent - classify: 602.60ms\n",
      "   Action Agent - execute: 1298.48ms\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a detailed trace example\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ” DETAILED TRACE EXAMPLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recent_traces = obs_manager.get_recent_traces(limit=1)\n",
    "if recent_traces:\n",
    "    trace = recent_traces[0]\n",
    "    print(f\"\\nTrace ID: {trace['trace_id']}\")\n",
    "    print(f\"Notification ID: {trace['notification_id']}\")\n",
    "    print(f\"Duration: {trace['duration_ms']:.2f}ms\")\n",
    "    print(f\"\\nNotification Text: {trace['notification_text'][:100]}...\")\n",
    "    \n",
    "    if trace['classification']:\n",
    "        print(f\"\\nðŸ“Š Classification:\")\n",
    "        print(f\"   Result: {trace['classification']['result']}\")\n",
    "        print(f\"   Reasoning: {trace['classification']['reasoning'][:150]}...\")\n",
    "    \n",
    "    if trace['action']:\n",
    "        print(f\"\\nâš¡ Action:\")\n",
    "        print(f\"   Type: {trace['action']['type']}\")\n",
    "        print(f\"   Details: {trace['action']['details']}\")\n",
    "    \n",
    "    if trace['memory_operation']:\n",
    "        print(f\"\\nðŸ’¾ Memory Operation:\")\n",
    "        print(f\"   Operation: {trace['memory_operation']['operation']}\")\n",
    "        print(f\"   Details: {trace['memory_operation']['details']}\")\n",
    "    \n",
    "    if trace['agents']:\n",
    "        print(f\"\\nðŸ¤– Agent Steps:\")\n",
    "        for agent_step in trace['agents']:\n",
    "            print(f\"   {agent_step['agent']} - {agent_step['step']}: {agent_step['duration_ms']:.2f}ms\")\n",
    "    \n",
    "    if trace['errors']:\n",
    "        print(f\"\\nâŒ Errors: {len(trace['errors'])}\")\n",
    "        for error in trace['errors']:\n",
    "            print(f\"   [{error['type']}] {error['message']}\")\n",
    "else:\n",
    "    print(\"No traces available yet. Run some notifications first!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:31,273 - FocusFilter - INFO - ðŸ” Trace started: trace_c935a412\n",
      "2025-12-02 02:23:31,291 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” Processing notification with multi-agent system\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Step 1: Classification Agent analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:32,162 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:32,168 - FocusFilter - INFO - ðŸ“Š Classification Agent - classify completed in 887.51ms\n",
      "2025-12-02 02:23:32,171 - FocusFilter - INFO - ðŸ·ï¸  Classification: LESS_URGENT - This is an update that is good to know, but does not require immediate action.\n",
      "Key Fact (if LESS_URG\n",
      "2025-12-02 02:23:32,186 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification complete\n",
      "   Result: Classification: LESS_URGENT\n",
      "Reasoning: This is an update that is good to know, but does not require immediate action.\n",
      "Key Fact (if LESS_URGENT): Project deadline moved to Tuesday....\n",
      "\n",
      "âš¡ Step 2: Action Agent executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:32,886 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:32,889 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-02 02:23:32,915 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash-exp, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Stored memory: Project deadline moved to Tuesday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:23:33,473 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.\n",
      "2025-12-02 02:23:33,485 - FocusFilter - INFO - ðŸ“Š Action Agent - execute completed in 1309.18ms\n",
      "2025-12-02 02:23:33,488 - FocusFilter - INFO - âš¡ Action: save_memory - {\"app\": \"Project Manager\", \"title\": \"Deadline Update\", \"classification\": \"LESS_URGENT\"}\n",
      "2025-12-02 02:23:33,492 - FocusFilter - INFO - ðŸ’¾ Memory: store - {\"app\": \"Project Manager\", \"extracted_fact\": \"(if LESS_URGENT): Project deadline moved to Tuesday.\", \"title\": \"Deadline Update\"}\n",
      "2025-12-02 02:23:33,497 - FocusFilter - INFO - ðŸ“Š Memory Agent - extract completed in 5.21ms\n",
      "2025-12-02 02:23:33,505 - FocusFilter - INFO - âœ… Trace completed: trace_c935a412 in 2232.45ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I have saved this notification to memory.\n",
      "\n",
      "âœ… Action execution complete\n",
      "\n",
      "ðŸ’¾ Step 3: Memory Agent extracting fact...\n",
      "âœ… Memory extraction handled by Action Agent\n",
      "\n",
      "======================================================================\n",
      "âœ… Multi-agent processing complete\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 3 Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test notification 3: Less urgent project update\n",
    "await process_notification_multi_agent(\n",
    "    \"I received a notification: App: Project Manager, Title: Deadline Update, Body: Your project deadline has moved to Tuesday.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"test_session_3\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Test 3 Complete\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ’¾ Stored Memories:\n",
      "======================================================================\n",
      "\n",
      "1. Project deadline moved to Tuesday.\n",
      "   From: Project Manager (stored at 2025-12-02T02:23:32.903097)\n"
     ]
    }
   ],
   "source": [
    "# Display stored memories\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’¾ Stored Memories:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "memories = memory_store.get_all()\n",
    "if memories:\n",
    "    for i, memory in enumerate(memories, 1):\n",
    "        print(f\"\\n{i}. {memory['extracted_fact']}\")\n",
    "        print(f\"   From: {memory['app']} (stored at {memory['stored_at']})\")\n",
    "else:\n",
    "    print(\"No memories stored yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”§ Testing Enhanced Features\n",
      "======================================================================\n",
      "\n",
      "1. Testing retrieve_user_preferences() tool:\n",
      "   Current preferences: {'always_urgent_apps': [], 'always_block_apps': [], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "2. Testing preference learning:\n",
      "âœ… Added preference: always_urgent_apps = Banking App\n",
      "âœ… Added preference: always_block_apps = Social Media\n",
      "   Updated preferences: {'always_urgent_apps': ['Banking App'], 'always_block_apps': ['Social Media'], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "3. Testing memory consolidation:\n",
      "ðŸ’¾ Stored memory: Project deadline moved to Tuesday\n",
      "   Memories before consolidation: 2\n",
      "   Memories after consolidation: 2\n",
      "\n",
      "4. Testing context compaction:\n",
      "   Compacted context: 2 most relevant memories\n",
      "\n",
      "5. Testing preference learning from patterns:\n",
      "   Learned preferences: {'always_urgent_apps': ['Banking App'], 'always_block_apps': ['Social Media'], 'preferred_categories': [], 'blocked_keywords': []}\n",
      "\n",
      "======================================================================\n",
      "âœ… Enhanced features demonstration complete\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEMONSTRATION: Enhanced Memory and Tools Features\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”§ Testing Enhanced Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Retrieve user preferences\n",
    "print(\"\\n1. Testing retrieve_user_preferences() tool:\")\n",
    "prefs = retrieve_user_preferences()\n",
    "if prefs.get('status') == 'success' and 'preferences' in prefs:\n",
    "    print(f\"   Current preferences: {prefs['preferences']}\")\n",
    "else:\n",
    "    error_msg = prefs.get('error_message', 'Unknown error')\n",
    "    print(f\"   Error: {error_msg}\")\n",
    "    # Fallback: try direct access if method exists\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        try:\n",
    "            direct_prefs = memory_store.get_user_preferences()\n",
    "            print(f\"   Direct access preferences: {direct_prefs}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Direct access failed: {e}\")\n",
    "    else:\n",
    "        print(\"   Note: Enhanced methods not yet available (run enhancement cell first)\")\n",
    "\n",
    "# Test 2: Update preferences\n",
    "print(\"\\n2. Testing preference learning:\")\n",
    "if hasattr(memory_store, 'update_preference'):\n",
    "    memory_store.update_preference(\"always_urgent_apps\", \"Banking App\", \"add\")\n",
    "    memory_store.update_preference(\"always_block_apps\", \"Social Media\", \"add\")\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        print(f\"   Updated preferences: {memory_store.get_user_preferences()}\")\n",
    "    else:\n",
    "        print(\"   Preferences updated (get_user_preferences not available)\")\n",
    "else:\n",
    "    print(\"   Note: update_preference method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 3: Memory consolidation\n",
    "print(\"\\n3. Testing memory consolidation:\")\n",
    "if hasattr(memory_store, 'consolidate_memories'):\n",
    "    # Add a similar memory to test consolidation\n",
    "    if memory_store.memories:\n",
    "        test_notification = Notification(\n",
    "            id=str(uuid.uuid4()),\n",
    "            app=\"Project Manager\",\n",
    "            title=\"Deadline Update\",\n",
    "            body=\"Your project deadline has moved to Tuesday.\",\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        memory_store.store(test_notification, \"Project deadline moved to Tuesday\")\n",
    "        print(f\"   Memories before consolidation: {len(memory_store.memories)}\")\n",
    "        consolidated_count = memory_store.consolidate_memories()\n",
    "        print(f\"   Memories after consolidation: {consolidated_count}\")\n",
    "    else:\n",
    "        print(\"   No memories to consolidate\")\n",
    "else:\n",
    "    print(\"   Note: consolidate_memories method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 4: Context compaction\n",
    "print(\"\\n4. Testing context compaction:\")\n",
    "if hasattr(memory_store, 'compact_context'):\n",
    "    compacted = memory_store.compact_context(max_memories=5)\n",
    "    print(f\"   Compacted context: {len(compacted)} most relevant memories\")\n",
    "else:\n",
    "    print(\"   Note: compact_context method not available (run enhancement cell first)\")\n",
    "\n",
    "# Test 5: Preference learning from patterns\n",
    "print(\"\\n5. Testing preference learning from patterns:\")\n",
    "if hasattr(memory_store, 'learn_from_patterns'):\n",
    "    classification_history = [\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Banking App\", \"classification\": \"URGENT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "        {\"app\": \"Social Media\", \"classification\": \"IRRELEVANT\"},\n",
    "    ]\n",
    "    memory_store.learn_from_patterns(classification_history)\n",
    "    if hasattr(memory_store, 'get_user_preferences'):\n",
    "        print(f\"   Learned preferences: {memory_store.get_user_preferences()}\")\n",
    "    else:\n",
    "        print(\"   Pattern learning completed\")\n",
    "else:\n",
    "    print(\"   Note: learn_from_patterns method not available (run enhancement cell first)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Enhanced features demonstration complete\")\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "This implementation demonstrates:\n",
    "\n",
    "1. **Multi-Agent System**: Sequential agents (Classification â†’ Action â†’ Memory)\n",
    "   - **Classification Agent**: Analyzes and classifies notifications\n",
    "   - **Action Agent**: Executes actions based on classification\n",
    "   - **Memory Agent**: Handles memory extraction and consolidation\n",
    "2. **Custom Tools**: Three tools for notification management (display, block, save)\n",
    "3. **Memory Management**: Simple in-memory storage (can be extended to vector DB)\n",
    "4. **Orchestration Layer**: Coordinates sequential agent flow\n",
    "5. **Agentic Loop**: Get Mission â†’ Think â†’ Act â†’ Observe pattern\n",
    "\n",
    "## Multi-Agent Flow\n",
    "\n",
    "```\n",
    "Notification Input\n",
    "    â†“\n",
    "[Classification Agent] â†’ Classifies as URGENT/IRRELEVANT/LESS_URGENT\n",
    "    â†“\n",
    "[Action Agent] â†’ Executes appropriate action (display/block/save)\n",
    "    â†“\n",
    "[Memory Agent] â†’ (Optional) Refines memory extraction for LESS_URGENT items\n",
    "    â†“\n",
    "Result\n",
    "```\n",
    "\n",
    "## Next Steps for Full Implementation\n",
    "\n",
    "- âœ… Multi-agent architecture (COMPLETE)\n",
    "- Add vector database for semantic memory search\n",
    "- Add context engineering with few-shot examples\n",
    "- Implement full observability with tracing\n",
    "- Add agent evaluation framework with LLM-as-judge\n",
    "- Add user preference learning\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
